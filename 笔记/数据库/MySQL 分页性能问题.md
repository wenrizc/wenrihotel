
#### 核心问题

`SELECT * FROM table ORDER BY col LIMIT offset, size;` 这种分页查询方式，当 `offset` 的值非常大时，性能会急剧下降。查询第100页（`LIMIT 990, 10`）会比查询第1页（`LIMIT 0, 10`）慢得多。

#### `LIMIT` 执行过程详解

MySQL 分为 Server 层和存储引擎层（如 InnoDB）。执行器在 Server 层，负责与存储引擎交互获取数据。

1.  **基于主键索引的分页 (`ORDER BY id`)**
    *   **浅分页 (`LIMIT 0, 10`)**: Server 层调用 InnoDB 接口，从主键索引的 B+ 树叶子节点中，直接获取前 10 条完整的行数据，然后返回给客户端。效率很高。
    *   **深分页 (`LIMIT 6000000, 10`)**: Server 层会调用 InnoDB 接口，从主键索引中获取 0 到 6,000,010 条（offset + size）完整的行数据。数据返回到 Server 层后，Server 层会丢弃前面的 6,000,000 条数据，只保留最后的 10 条。这个过程中的瓶颈在于，InnoDB 需要扫描并向 Server 层传输大量最终会被丢弃的数据。

2.  **基于非主键索引的分页 (`ORDER BY user_name`)**
    *   **回表**: 非主键索引的叶子节点只存储主键值。因此，通过非主键索引找到数据后，需要再根据主键 ID 去主键索引中查找完整的行数据，这个过程称为“回表”。
    *   **浅分页**: 过程为主键索引分页多了一个回表操作，对每一条记录，都需要从非主键索引到主键索引进行一次回表。
    *   **深分页 (`LIMIT 6000000, 10`)**: 当 `offset` 巨大时，MySQL 的优化器会进行成本估算。它会认为“扫描非主键索引并进行 600 万次回表”的成本，比“直接扫描整张主表（全表扫描）”还要高。因此，优化器会放弃使用索引，转而执行全表扫描（`EXPLAIN` 结果中 `type` 会显示为 `ALL`），导致性能极差。

#### 深度分页的优化方案

深度分页问题目前在数据库层面没有根治的方法，只能通过各种手段进行“规避”或“减缓”。

1.  **优化方案一：子查询优化（适用于主键排序）**
    *   **SQL 语句**:
        `select * from page where id >= (select id from page order by id limit 6000000, 1) order by id limit 10;`
    *   **原理**:
        1.  先执行内部的子查询 `select id ...`。这个查询虽然也要扫描 600 万+ 条记录，但它在非主键索引上进行，且只返回 `id` 这一列到 Server 层，避免了传输完整的行数据，减少了 I/O 和网络开销。
        2.  Server 层拿到第 6,000,001 条记录的 `id` 值。
        3.  外部查询 `select * from page where id >= ? ...` 利用这个 `id` 值，在主键索引上进行高效的范围查找（index seek），快速定位到起点，然后获取 10 条数据。
    *   **效果**: 属于“没办法中的办法”，性能有提升（比如耗时减半），但未从根本上解决扫描大量数据的问题。

2.  **优化方案二：JOIN 优化（适用于非主键排序）**
    *   **SQL 语句**:
        `select * from page t1, (select id from page order by user_name limit 6000000, 10) t2 WHERE t1.id = t2.id;`
    *   **原理**:
        1.  先通过子查询在 `user_name` 索引上进行分页，只获取目标页的 10 个主键 `id`。这个过程避免了对前 600 万条数据进行回表。
        2.  然后将这 10 个 `id` 和原表 `page` 进行 `JOIN` 操作。因为是基于主键 `id` 的 `JOIN`，所以执行效率非常高。
    *   **效果**: 核心思想是延迟回表，将大量回表操作转换为一次性的、小范围的回表，但同样没有解决扫描大量索引数据的问题。

#### 从业务需求角度规避问题

遇到深度分页，首先应反思业务需求是否合理。

1.  **场景一：全量数据导出/同步**
    *   **错误做法**: 使用 `LIMIT offset, size` 循环获取。
    *   **正确做法 (游标/Keyset 分页)**: 根据有序的主键 `id` 分批获取，每次查询时都带上上一批次的最大 `id` 作为下一批次的查询条件。
    *   **优点**: 无论翻到多深，每次查询都是利用索引进行高效的范围查找，性能稳定且极高。

2.  **场景二：给用户做分页展示**
    *   **反思**: 现实中几乎没有用户会翻到几万页之后。这是一个不合理的需求。
    *   **解决方案 A：限制分页深度**
        *   和产品经理沟通，对可查看的总页数或总记录数做出限制。例如，只允许用户查看前 10000 条记录或前 100 页。
        *   对于搜索类场景，推荐使用 Elasticsearch (ES) 并同样限制分页深度。
    *   **解决方案 B：改变产品形态**
        *   **禁止跳页**：只提供“上一页”和“下一页”的按钮。这样就可以使用上面提到的游标分页法 (`WHERE id > last_id`)，保证查询性能。
        *   **包装成“瀑布流”**: 将只能“上一页/下一页”的交互模式包装成类似抖音、微博的无限滚动加载模式。用户体验现代，技术实现高效。
