
一个慢查询引发的思考

- 案例SQL: select count(*) from task where status=2 and operator_id=20839 and operate_time>1371169729 and operate_time<1371174603 and type=2;
    
- 错误认知: 认为给where条件中的每个字段都单独加上索引就能提高速度。
    
- 正确思路: 应该建立一个联合索引，并需要理解最左前缀匹配原则，综合评估所有相关查询来决定索引字段的顺序。
    

MySQL索引原理

索引目的

- 索引的核心目的是提高查询效率。
    
- 类似于字典的目录，通过索引可以快速定位到数据，避免全表扫描。
    

索引原理

- 核心思想: 通过不断缩小数据范围来筛选最终结果，将随机查找事件变为顺序查找事件。
    
- 数据库查询比查字典复杂，需要处理等值查询、范围查询(>、<、between、in)、模糊查询(like)、并集查询(or)等。
    
- 简单的分段不能满足海量数据的需求，需要更高效的数据结构，如搜索树。
    
- 考虑到数据库数据存储在磁盘上，而磁盘IO成本远高于内存访问，简单搜索树无法满足需求。
    

磁盘IO与预读

- 磁盘读取数据耗时主要包括寻道时间、旋转延迟和传输时间。一次磁盘IO大约需要9毫秒，相对于内存操作非常慢。
    
- 计算机硬件延迟对比显示，一次磁盘寻道的时间可以执行约40万条指令。
    
- 操作系统优化: 局部性预读原理。当进行一次IO时，系统不仅读取当前地址的数据，还会将相邻的数据一并读入内存缓冲区。
    
- 每次IO读取的数据单位称为一页(page)，通常为4k或8k。在一个页内读取数据实际上只发生了一次磁盘IO。
    

索引的数据结构: B+树

- 数据库索引结构的目标: 将每次查找的磁盘IO次数控制在一个很小的、最好是常数的数量级。
    
- B+树是一种高度可控的多路搜索树，非常适合做索引。
    
- B+树结构特点:
    
    - 每个节点是一个磁盘块(页)。
        
    - 非叶子节点不存储真实数据，只存储用于指引搜索方向的数据项和指针。
        
    - 真实的数据全部存储在叶子节点。
        
- B+树查找过程:
    
    - 从根节点开始，通过一次磁盘IO将根节点加载到内存。
        
    - 在内存中通过二分查找确定指针方向，定位到下一个磁盘块。
        
    - 重复此过程，直到到达叶子节点，发生第三次IO加载叶子节点到内存。
        
    - 在叶子节点中找到最终数据。
        
    - 结论: 一个3层的B+树可以支持百万级别的数据量，查找仅需3次IO，性能提升巨大。
        

B+树性质

1. IO次数取决于树的高度h。公式为 h = ㏒(m+1)N (N是数据总量，m是每页的数据项数量)。
    
    - 数据量N固定时，m越大，树的高度h越小。
        
    - m = 页大小 / 数据项大小。页大小固定，所以索引字段越小(如int比bigint小)，m就越大，树的高度就越低，IO次数越少。
        
    - B+树将真实数据放在叶子节点，使得非叶子节点可以存储更多的数据项(m更大)，从而降低树高。
        
2. 最左匹配特性(复合索引):
    
    - 对于(name, age, sex)这样的复合索引，B+树按从左到右的顺序建立搜索树。
        
    - 查询时，会优先比较name，name相同再比较age，以此类推。
        
    - 如果查询条件没有提供最左边的列(如name)，索引将无法使用。例如，用(20, F)查询无法使用该索引。
        
    - 如果查询条件跳过了中间的列(如(张三, F))，则只有第一列(name)的索引会生效，数据库会找到所有name为'张三'的记录，再从中过滤性别为'F'的数据。
        

慢查询优化

建索引的几大原则

1. 最左前缀匹配原则:
    
    - MySQL会一直向右匹配直到遇到范围查询(>、<、between、like)就停止。
        
    - 示例: a=1 and b=2 and c>3 and d=4，若索引是(a,b,c,d)，则d用不到索引。若索引是(a,b,d,c)，则a,b,d都能用到。
        
2. =和in可以乱序:
    
    - 对于 a=1 and b=2 and c=3，建立(a,b,c)索引，查询条件中a,b,c的顺序可以任意，MySQL查询优化器会自动调整。
        
3. 选择区分度高的列作索引:
    
    - 区分度公式: count(distinct col)/count(*)。比例越高，索引效果越好。唯一键的区分度是1。
        
    - 经验值: 对于需要join的字段，区分度建议在0.1以上。
        
4. 索引列不能参与计算:
    
    - 错误写法: from_unixtime(create_time) = ’2014-05-29’，这会导致索引失效，因为需要对B+树中所有值应用函数。
        
    - 正确写法: create_time = unix_timestamp(’2014-05-29’)。
        
5. 尽量扩展索引，不要新建索引:
    
    - 如果已有索引(a)，需要(a,b)的索引，应修改现有索引而不是新建一个。
        

回到开始的慢查询

- 针对 `status=2 and operator_id=20839 and type=2 and operate_time > ... and operate_time < ...`
    
- 根据最左匹配原则，`operate_time`是范围查询，应放在最后。
    
- 考虑其他查询，如 `status=0 and type=12` 和 `status=0`。
    
- 综合评估，建立联合索引 `(status, type, operator_id, operate_time)` 是一个很好的选择，可以覆盖所有情况。
    

查询优化神器 - explain命令

- `explain`用于查看SQL的执行计划。
    
- 核心指标: `rows`，表示MySQL预计要扫描的行数。rows越小，执行速度通常越快。优化目标基本就是优化`rows`。
    

慢查询优化基本步骤

0. 先运行确认是否慢，使用SQL_NO_CACHE避免缓存影响。

1. 分析where条件，找到在单表中过滤后返回记录最少的表，作为查询的起点。
    
2. 用`explain`查看执行计划，确认是否与预期一致。
    
3. 对于`order by limit`形式的查询，让排序的表优先查询。
    
4. 了解业务方的使用场景，这非常关键。
    
5. 遵循建索引的几大原则来添加或修改索引。
    
6. 观察优化结果，不符合预期则从头开始分析。
    

慢查询案例分析

案例一: 复杂语句写法

- 原始SQL: 使用`inner join`连接一个派生表(derived table)，派生表内部有`left join`，且最外层`join`条件中包含`OR`。
    
- 问题分析: `explain`显示，MySQL先生成了派生表，返回了6万多条记录，然后再与主表`cm_log`的379条记录进行连接，产生了大量不必要的中间数据。
    
- 优化方法: 拆分`OR`逻辑，将原SQL改写为两个`SELECT`语句，并用`UNION`连接。`UNION`会自动去重，效果等同于原SQL的`DISTINCT`。如果不需要去重，使用`UNION ALL`性能更好。
    
- 结果: 优化后查询时间从1.87秒降至0.01秒，性能提升近200倍。
    

案例二: 明确应用场景

- 原始SQL: `select * from stage_poi where accurate_result=1 and (sync_status=0 or sync_status=2 or sync_status=4);`
    
- 问题分析: `accurate_result`和`sync_status`两个字段的区分度都非常低，从理论上说不适合建索引。`explain`显示全表扫描。
    
- 优化方法: 与业务方沟通，了解到这是一个定时任务，每5分钟执行一次，符合条件的记录数不多(约1000条)，且处理后`sync_status`会被修改。这意味着数据分布在业务层面是极不均衡的，索引可以过滤掉绝大部分数据。
    
- 解决方案: 建立联合索引 `idx_acc_status(accurate_result, sync_status)`。
    
- 结果: 查询时间从6.22秒降至0.20秒，性能提升30多倍。
    
- 结论: 不能死板地套用索引理论，了解业务场景至关重要。
    

案例三: 无法优化的语句

- 原始SQL: 一个复杂的多表`join`查询，最后有`order by c.created_time desc limit 10`。
    
- 问题分析:
    
    - `explain`显示的执行计划看似很好，每步join的`rows`都很小。
        
    - 但去掉`order by`和`limit`后发现，整个`join`的结果集高达77万条。
        
    - 慢的原因是在77万条记录上进行文件排序(filesort)，然后取前10条。
        
- 优化尝试:
    
    - 改写SQL，先从`contact`表按`created_time`排序取数据，然后用`exists`子查询来过滤，试图先排序再`join`。
        
    - 在某些情况下，这个改写后的SQL速度极快(0.00秒)。
        
- 致命缺陷:
    
    - 这种改写依赖于`limit`。MySQL会先按索引从`contact`表取出10条记录，然后用`exists`子句验证。如果这10条记录都被过滤掉了，MySQL会再取10条，依此类推。
        
    - 在极端情况下(如`exists`子句中的条件几乎找不到匹配项)，这种方式会退化成对`contact`表的全表扫描，比原始SQL更慢(案例中耗时超过2分钟)。
        
- 结论:
    
    - MySQL的`nested loop`机制导致这种场景无法在SQL层面完美优化。
        
    - 并非所有SQL都能通过数据库层面优化，有时需要应用系统调整业务逻辑。
        
    - 优化时必须考虑所有情况，不能只针对特定case，否则可能造成更严重的后果。
        

