
## 1. 项目简述

Apache ShenYu 是一个高性能、开源的 API Gateway，其核心优势在于灵活的插件系统。通过开发新的插件，可以方便地扩展 Gateway 的功能。Apache ShenYu AI Plugin 是 ShenYu 对 AI 模型接口进行代理的插件，使得网关能够与公有云 AI 服务（如 OpenAI、DeepSeek 等）或私有化部署的 AI 模型集成。然而，当前插件功能较为简单，未集成主流的 Spring AI 框架，导致其在 AI 交互调用中的能力有限，难以满足复杂的应用场景。

本项目旨在通过集成 Spring AI 框架，增强 Apache ShenYu AI Plugin 的智能化水平，实现在一个插件内支持以下功能：AI 调用降级与重试、会话历史管理、代理 API Key 与调用限额、AI 模型调用语义缓存。这些功能将显著提升插件的健壮性、安全性及性能优化能力，满足用户对 AI 服务管理的精细化需求。

---

## 2. 项目需求分析

为应对日益复杂的 AI 应用场景和用户对服务管理的高要求，本项目需实现以下四个核心需求：

### 2.1 AI 调用降级与重试
- **现状**: 当前插件在 AI 调用失败时处理机制单一，缺乏智能降级能力。
- **需求**: 系统应支持配置模型优先级列表，当高级别模型因超时、速率限制或服务不可用等原因调用失败时，能够根据预设策略智能判断失败原因，执行重试或降级到未受限的低级别模型，确保服务连续性并优化成本。

### 2.2 支持会话历史管理
- **现状**: 插件缺乏对多轮对话上下文的管理能力。
- **需求**: 系统应为每个 AI 会话（通过唯一对话 ID 标识）记录完整的交互历史（用户提问和 AI 回答），支持将历史存储到向量数据库和内存中，并在后续调用时构建上下文，为 RAG（检索增强生成）等高级应用提供支持。

### 2.3 代理 API Key 与调用限额
- **现状**: 直接暴露真实 API Key 存在安全隐患，且无法对用户或应用进行差异化授权和用量控制。
- **需求**: 系统应基于真实 API Key 生成代理 API Key，管理员可在网关配置中为每个代理 Key 映射真实 Key 并设置调用限额（如每分钟请求数、每小时 Token 用量上限），网关负责校验代理 Key 有效性并执行限流策略。

### 2.4 AI 模型调用语义缓存
- **现状**: 相同或语义相似的请求重复调用 AI 模型，导致 Token 浪费和响应延迟增加。
- **需求**: 系统应根据请求内容的语义缓存 AI 模型返回的内容，通过生成语义向量并比对相似度，若命中缓存则直接返回结果，从而减少对 AI 模型的实际调用，降低 Token 消耗和响应时间。

---

## 3. 技术实现方案

### 3.1 Spring AI 集成
本方案旨在将 Spring AI 框架集成到 ShenYu AI 插件中，利用 Spring AI 强大的模型客户端管理与交互能力，作为后续所有高级 AI 功能的基石。目标是实现 ShenYu AI 插件通过 Spring AI 与各类 AI 模型进行高效、灵活的交互。
设计思路：
在shenyu ai插件中集成spring ai，由Spring AI负责 AI 模型客户端 (如 ChatClient, EmbeddingClient) 的生命周期管理、配置和实际的 AI 服务调用。
同时在ShenYu AI 插件**: 负责业务流程编排、动态路由与参数配置。通过 ShenYu 的配置中心 (PluginData, SelectorData, RuleData) 决定请求使用哪个 AI 模型、运行时参数 (如 temperature, model) 和 Prompt 模板等。


#### 3.1.2 关键组件
- **AiService**: 
  - 负责管理 Spring AI 的客户端池（`Map<String, ChatClient>` 和 `Map<String, EmbeddingClient>`），通过 ShenYu 配置动态定位客户端实例。
  - 提供标准化的调用方法（如 `chat()`、`embed()`）。
- **SpringAiModelAdapter**: 
  - 实现 `AiModel` 接口，将 ShenYu 的业务请求转换为 Spring AI 的标准调用格式。
- **ShenYuAIPlugin**: 
  - 主插件，集成所有功能逻辑，通过 `doExecute()` 方法处理请求和响应。

#### 3.1.3 配置与工作流程
- **PluginData**: 定义 AI 模型配置列表（`aiConfigurations`），包括模型名称、客户端 Bean 名称、优先级等。
- **工作流程**:
  1. 启动时加载 Spring AI 客户端及插件配置。
  2. 请求到达时，插件解析配置，调用 `SpringAiModelAdapter` 执行 AI 交互。
  3. 响应返回客户端。

---

### 3.2 AI 调用降级与重试
#### 3.2.1 核心设计
- **策略驱动**: 通过 `PluginData` 配置降级和重试策略。
- **状态感知**: 实时监控模型健康状态，动态选择可用模型。
- **熔断机制**: 对故障模型快速熔断，恢复后自动启用。

#### 3.2.2 实现细节
- **组件**:
  - **AIModelRegistryService**: 管理模型信息（优先级、状态）并推荐可用模型。
  - **CircuitBreaker**: 为每个模型维护熔断器，监控调用状态。
- **配置**:
  ```json
  {
    "aiModels": [
      {"modelId": "gpt-4", "priority": 1, "clientBeanName": "openAiChatClient"},
      {"modelId": "gpt-3.5", "priority": 2, "clientBeanName": "openAiChatClient"}
    ],
    "retryPolicy": {"maxAttempts": 3, "delay": "2s"},
    "fallbackPolicy": {"behavior": "NEXT_AVAILABLE"}
  }
  ```
- **流程**:
  1. 根据优先级选择最高级别模型。
  2. 调用失败时，分类错误（如 `RATE_LIMIT_ERROR`），执行重试。
  3. 重试失败后降级至次优模型。

---

### 3.3 会话历史管理
#### 3.3.1 核心设计
- **存储抽象**: 定义 `ChatMemoryStore` SPI，支持多后端存储。
- **上下文构建**: 通过会话 ID 获取历史并构造上下文。

#### 3.3.2 实现细节
- **组件**:
  - **ChatMemoryStore**: 接口定义 `add()`、`get()` 等方法。
  - **RedisStoreServiceImpl**: 使用 Redis List 存储历史，设置 TTL。
  - **InMemoryStoreServiceImpl**: 本地内存存储，适合测试或小规模场景。
- **配置**:
  ```json
  {
    "memoryStoreType": "redis",
    "redisKeyPrefix": "shenyu:ai:memory:",
    "ttlSeconds": 3600
  }
  ```
- **流程**:
  1. 客户端传入或生成 `conversationId`。
  2. 请求时从存储中获取历史，构建上下文。
  3. 响应后将新交互记录存入存储。

---

### 3.4 代理 API Key 与调用限额
#### 3.4.1 核心设计
- **安全性**: 隐藏真实 Key，仅暴露代理 Key。
- **限流**: 使用 Redis 实现分布式限额控制。

#### 3.4.2 实现细节
- **组件**:
  - **ShenYuAIPlugin**: 内部维护 Key 映射和限流逻辑。
- **数据结构**:
  ```json
  {
    "realApiKeys": [{"keyName": "real1", "keyValue": "xxx"}],
    "proxyApiKeys": [
      {"proxyKey": "proxy1", "realKeyName": "real1", "limit": {"requestsPerMinute": 10}}
    ]
  }
  ```
- **流程**:
  1. 请求携带 `proxyKey`，插件校验其有效性。
  2. 使用 Redis 计数（如 `INCR`），检查是否超限。
  3. 通过则用真实 Key 调用 AI 服务。

---

### 3.5 AI 模型调用语义缓存
#### 3.5.1 核心设计
- **语义匹配**: 使用向量相似度判断缓存命中。
- **存储分离**: 向量存向量数据库，响应存键值存储。

#### 3.5.2 实现细节
- **组件**:
  - **VectorStoreService**: SPI，管理向量存储（如 Redis）。
  - **KeyValueStoreService**: SPI，存储响应（如 Redis）。
- **配置**:
  ```json
  {
    "semanticCacheEnabled": true,
    "similarityThreshold": 0.9,
    "cacheTtlSeconds": 86400
  }
  ```
- **流程**:
  1. 请求前生成语义向量，搜索缓存。
  2. 命中则返回缓存响应，未命中则调用 AI。
  3. 成功响应后异步存入缓存。

---

## 4. 总结

通过上述方案，`ShenYuAIPlugin` 将在一个插件内实现 AI 调用降级与重试、会话历史管理、代理 API Key 与调用限额及语义缓存功能。插件利用 Spring AI 的能力，结合 ShenYu 的动态配置，确保功能的灵活性与可扩展性，同时提升用户体验和系统效率。