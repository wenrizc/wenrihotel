
## 完善方案与调用限额更新机制

在 WebFlux 异步流式处理模型下，操作的执行不是顺序阻塞的，而是通过反应式流（`Mono` 和 `Flux`）来编排。因此，调用限额的更新必须嵌入到这个异步链中，确保在正确的时间点执行，并且是非阻塞的。

**核心原则：**

1.  **先检查，后调用，成功后扣减。**
2.  **扣减操作需原子化，防止并发问题。**
3.  **流式响应特殊处理：** 对于流式响应，一旦AI服务开始成功返回数据流（例如，收到第一个chunk），就可以认为本次调用是“成功发起”的，此时应扣减限额。而不是等到整个流结束。

### 更新调用限额的详细方案 (结合 WebFlux)

**时间点：**

调用限额的**检查**发生在实际调用AI模型之前。
调用限额的**扣减**发生在AI模型调用**成功响应之后**（对于非流式调用，指收到完整响应；对于流式调用，指收到流的第一个成功信号或数据块）。

### 3.4. 代理 API Key 与调用限额 (细化)

**异步校验与扣减逻辑 (WebFlux):**

当请求进入 ShenYu AI 插件后：

1.  **提取标识与查询代理 Key (Reactive)**:
    *   从 `ServerHttpRequest` 中异步获取 `X-AI-Proxy-Key` Header。
    *   如果 Header 中是`flag`：
        *   异步查询网关配置，获取与`flag`关联的`real_api_key`和限额规则。
        *   异步生成 `proxy_api_key` (e.g., `proxy_<flag><uuid>`)。
        *   异步将代理 Key 信息存入 Redis（如果不存在或需要更新）。这包括 `real_api_key`, `quota_total`, `quota_remaining` (初始等于`quota_total`), `expires_at`。
    *   如果 Header 中直接是 `proxy_api_key`：
        *   直接使用此 Key。
    *   此步骤返回 `Mono<ProxyKeyDetails>`，其中 `ProxyKeyDetails` 包含从 Redis 读取或新生成的代理 Key 信息。

2.  **限额与有效期校验 (Reactive Chain)**:
    *   在上一步的 `Mono` 后使用 `flatMap` 或 `filterWhen`。
    *   异步从 Redis 读取该 `proxy_api_key` 的详细信息（特别是 `quota_remaining` 和 `expires_at`）。
    *   **检查1 (有效期)**: 如果 `expires_at` 已过期，返回 `Mono.error(new KeyExpiredException())`。
    *   **检查2 (剩余额度)**: 如果 `quota_remaining <= 0`，返回 `Mono.error(new QuotaExceededException())`。
    *   如果校验通过，则继续链式操作。

3.  **AI 模型调用 (Reactive)**:
    *   通过 `AiService.chat(request)` 发起AI调用。此方法应返回 `Mono<ChatResponse>` (非流式) 或 `Flux<ChatChunk>` (流式)。

4.  **调用限额扣减 (Reactive Chain - 关键点)**:
    *   **非流式响应 (`Mono<ChatResponse>`)**:
        *   在 `AiService.chat()` 返回的 `Mono` 上使用 `doOnSuccess(response -> ...)` 或 `flatMap(response -> ... .thenReturn(response))` 来触发扣减。
        *   在成功回调中，异步执行 Redis `DECR ai:proxy:key:<proxy_api_key>:quota_remaining`。
        *   `DECR` 命令是原子的。获取其返回值 (新的剩余额度)。
        *   **补偿逻辑 (重要)**: 如果 `DECR` 返回值 `< 0`，说明在并发情况下，虽然初始检查通过，但此请求是耗尽额度的那个（或之一）。此时，理论上此请求不应成功。
            *   **策略A (推荐)**: 即使AI调用成功，如果扣减后额度 `<0`，也应将此请求视为失败（返回特定错误给客户端），并异步执行 `INCR` 将额度“补回”到0。这是为了确保额度不为负。
            *   **策略B (简单)**: 允许这一次“超额”（额度变负），下次请求时由于初始检查 `quota_remaining <= 0` 会失败。但额度会显示为负数。
            *   **更好的原子检查与扣减 (使用Lua脚本)**: 为了避免先检查后扣减的竞态条件，可以使用Redis Lua脚本实现原子性的“检查并扣减”：
                ```lua
                -- KEYS[1]: the key for quota_remaining, e.g., "ai:proxy:key:mykey:quota_remaining"
                -- ARGV[1]: the amount to decrement (usually 1)
                local currentValue = redis.call('GET', KEYS[1])
                if currentValue == false then
                    return -2 -- Indicates key does not exist
                end
                currentValue = tonumber(currentValue)
                if currentValue < tonumber(ARGV[1]) then
                    return -1 -- Indicates not enough quota
                end
                return redis.call('DECRBY', KEYS[1], ARGV[1])
                ```
                在Java代码中，如果Lua脚本返回-1，则认为限额不足，即使AI调用已进行（这需要调整流程，理想情况下Lua脚本在AI调用前执行，但若AI调用失败，额度不应扣减）。
                **因此，更合理的做法是：AI调用成功后，执行 `DECR`。如果 `DECR` 后的值 `< 0`，则此请求成功，但标记用户超额，同时将Redis中的值通过 `INCR` 恢复到0（防止无限透支）。后续请求会因初始检查失败。**

    *   **流式响应 (`Flux<ChatChunk>`)**:
        *   在 `AiService.chat()` 返回的 `Flux` 上使用 `doOnSubscribe(subscription -> ...)` 或 `doOnNext(chunk -> ...)` (仅在第一个chunk时执行一次)。
        *   推荐在 `doOnNext` 中，设置一个 `AtomicBoolean once = new AtomicBoolean(false)`，确保只在收到第一个数据块时执行一次扣减逻辑。
            ```java
            // Inside AiService.chat() or where the Flux is returned
            AtomicBoolean quotaDecremented = new AtomicBoolean(false);
            return realAiModel.stream(chatRequest) // This returns Flux<ChatChunk>
                .doOnNext(chunk -> {
                    if (!quotaDecremented.getAndSet(true)) {
                        // Asynchronously decrement quota here using reactive Redis client
                        // redisReactiveCommands.decr("ai:proxy:key:" + proxyApiKey + ":quota_remaining")
                        //    .subscribe(newValue -> {
                        //        if (newValue < 0) {
                        //            // Log quota exceeded, potentially INCR back to 0
                        //            redisReactiveCommands.incr("ai:proxy:key:" + proxyApiKey + ":quota_remaining").subscribe();
                        //        }
                        //    });
                        // This decrement should be chained properly if further actions depend on it.
                        // For simplicity, it can be a "fire-and-forget" with logging if not critical for the current response flow.
                        // Or, more robustly:
                        Mono<Long> decrementMono = reactiveRedisClient.decr(quotaKey)
                            .doOnSuccess(newValue -> {
                                if (newValue < 0) {
                                    log.warn("Quota for {} exhausted by this request. Resetting to 0.", proxyApiKey);
                                    reactiveRedisClient.incr(quotaKey).subscribe(); // Bring back to 0
                                    // Depending on policy, you might even cancel the stream here,
                                    // but it's complex as data might have already been sent.
                                    // For now, we allow the stream to complete but log it.
                                }
                            })
                            .doOnError(err -> log.error("Failed to decrement quota for {}", proxyApiKey, err));
                        decrementMono.subscribe(); // Subscribe to trigger the decrement
                    }
                })
                .doOnError(error -> {
                    // If the AI call itself errors out *before* any chunk is received and quota is decremented,
                    // then no quota is consumed. If it errors *after* quota deduction, quota is already spent.
                    log.error("Error in AI stream for key {}: {}", proxyApiKey, error.getMessage());
                });
            ```
        *   **关键点**：扣减操作本身也应该是异步的，并且不能阻塞流的处理。通常使用 `subscribe()` 在一个“旁边”的流中执行，或者如果后续操作依赖扣减结果，则需更复杂的链式结构。对于流式，一旦开始，就认为消耗了一次。

5.  **错误处理 (Reactive)**:
    *   在整个链中使用 `onErrorResume` 或 `onErrorMap` 来捕获上游的错误 (如 `QuotaExceededException`, `KeyExpiredException`, AI调用错误等)，并转换成合适的 `ServerResponse`。
    *   **如果AI调用失败（非额度问题），则不应扣减限额。** 这通过将扣减操作放在 `doOnSuccess` (Mono) 或 `doOnNext` (Flux, 首次) 来保证。

### 3.6 一次AI调用的完整生命周期 (结合WebFlux和限额更新)

1.  **请求接入与路由**:
    *   用户请求通过 `ServerWebExchange` 到达 ShenYu 网关，路由至 AI 插件的 Handler (e.g., `ShenYuOpenAiPluginHandler.handle()`)。

2.  **代理Key与限额前置校验 (Reactive Chain)**:
    *   `exchange.getRequest()` 获取请求。
    *   从请求头异步提取 `X-AI-Proxy-Key` 标志位或完整代理Key。
    *   **IF** 标志位:
        *   异步查询网关配置生成/获取代理Key (`proxy_api_key`) 和 `real_api_key`。
        *   异步检查 Redis 中此 `proxy_api_key` 的元数据。
            *   **IF NOT EXISTS**: 初始化额度信息到 Redis (总额度、剩余额度、有效期等)。`Mono<ProxyDetails>`
            *   **ELSE**: 加载 Redis 中的额度信息。 `Mono<ProxyDetails>`
    *   **ELSE IF** 完整代理Key:
        *   异步加载 Redis 中此 `proxy_api_key` 的元数据。 `Mono<ProxyDetails>`
    *   **CHAIN WITH**: `flatMap(proxyDetails -> ...)`
        *   检查 `proxyDetails.isExpired()` -> `Mono.error(new KeyExpiredException())`
        *   检查 `proxyDetails.getQuotaRemaining() <= 0` -> `Mono.error(new QuotaExceededException())`
        *   若通过，`proxyDetails` (包含 `real_api_key` 和 `proxy_api_key`) 传递给下游。

3.  **语义缓存查询 (Reactive Chain)**:
    *   `flatMap(proxyDetails -> ...)`
    *   异步规范化用户查询文本、向量化。
    *   异步查询 Redis 精确缓存。`Mono<Optional<CachedResponse>>`
    *   `flatMap(cachedOpt -> cachedOpt.isPresent() ? Mono.just(cachedOpt.get()) : vectorDbSearchMono)`
    *   异步查询向量数据库（语义相似搜索）。若命中且相似度达标，直接构建 `ServerResponse` 返回缓存响应。`Mono<Optional<CachedResponse>>`
    *   若缓存未命中，将 `proxyDetails` 和原始请求传递给下游。

4.  **会话历史构建 (Reactive Chain, if applicable)**:
    *   `flatMap(detailsAndRequest -> ...)`
    *   若请求中包含 `conversationId`：
        *   异步从 `ChatMemoryStore` (如 PgVectorChatMemoryStore/RedisChatMemoryStore 的 reactive-wrapper) 获取历史消息。`Mono<List<Message>>`
        *   将历史消息与当前提问构造成上下文 Prompt。
    *   若无，则直接使用当前提问。

5.  **AI模型调用与核心限额处理 (Reactive Chain)**:
    *   `flatMap(promptData -> aiService.chat(promptData.getRequest(), promptData.getRealApiKey()))`
        *   `aiService.chat()` 内部使用 Spring AI 的 `ChatClient` (如 `OpenAiChatClient`)。这个调用本身是异步的，返回 `Mono<ChatResponse>` 或 `Flux<ChatChunk>`。
    *   **限额扣减 (关键环节)**:
        *   **For `Mono<ChatResponse>`**:
            ```java
            // aiServiceCallResult is Mono<ChatResponse>
            aiServiceCallResult.flatMap(response ->
                reactiveRedisCommands.decr("ai:proxy:key:" + proxyApiKeyFromContext + ":quota_remaining")
                    .flatMap(newQuota -> {
                        if (newQuota < 0) {
                            // Quota exhausted by this call.
                            // Increment back to 0 and potentially fail the request or log warning.
                            return reactiveRedisCommands.incr("ai:proxy:key:" + proxyApiKeyFromContext + ":quota_remaining")
                                .then(Mono.error(new QuotaExceededByThisRequestException("Quota used up by this request."))); // Or just log and return response
                        }
                        return Mono.just(response); // Return original AI response
                    })
                    .doOnError(QuotaExceededByThisRequestException.class, e -> { /* handle specific error */})
            )
            ```
        *   **For `Flux<ChatChunk>` (Streaming)**:
            ```java
            // aiServiceCallResult is Flux<ChatChunk>
            // proxyApiKeyFromContext needs to be accessible, e.g. final or effectively final from closure
            AtomicBoolean quotaDecremented = new AtomicBoolean(false);
            aiServiceCallResult.doOnNext(chatChunk -> {
                if (!quotaDecremented.getAndSet(true)) {
                    reactiveRedisCommands.decr("ai:proxy:key:" + proxyApiKeyFromContext + ":quota_remaining")
                        .subscribe(newQuota -> {
                            if (newQuota < 0) {
                                log.warn("Quota for {} exhausted by this streaming request. Resetting to 0.", proxyApiKeyFromContext);
                                reactiveRedisCommands.incr("ai:proxy:key:" + proxyApiKeyFromContext + ":quota_remaining").subscribe();
                            }
                        }, err -> log.error("Failed to decrement quota for streaming request {}", proxyApiKeyFromContext, err));
                }
            })
            // Note: doOnNext for quota is "fire-and-forget" style for streaming to not block the data flow.
            // Error handling for quota decrement itself needs careful consideration (logging, alerts).
            ```

6.  **响应与数据持久化 (Reactive Chain)**:
    *   `doOnSuccess(aiResponseOrFirstChunk -> ...)` / `flatMap(aiResponse -> ...)`
    *   异步将用户提问和AI回答（或流的元信息）存入 `ChatMemoryStore` (如果启用了会话历史)。
    *   异步将成功的AI响应（及查询向量）存入语义缓存 (Redis)。
    *   AI响应封装后，由ShenYu网关的`ServerResponse`异步返回给客户端。

7.  **全局错误处理**:
    *   在最外层的 `Mono`链上使用 `onErrorResume(throwable -> ...)` 将任何发生的异常 (自定义的 `QuotaExceededException`, `KeyExpiredException`, `QuotaExceededByThisRequestException` 或来自AI调用的其他异常) 映射为合适的 `ServerResponse` (e.g., HTTP 429, 401, 500)。

---

**总结限额更新方案：**

*   **检查点**：在实际调用AI模型前，异步从Redis获取代理Key的当前剩余额度和有效期。若额度不足或Key过期，则提前终止请求，返回错误。
*   **扣减点**：
    *   对于**非流式**请求：在AI模型调用成功返回完整响应后，异步执行`DECR`原子命令扣减Redis中的剩余额度。若`DECR`后额度小于0，记录此情况，并将额度`INCR`回0（避免负数透支），但本次请求仍算成功（或根据策略判定为因额度耗尽而失败）。
    *   对于**流式**请求：在AI模型调用成功并开始返回数据流（例如，`doOnNext`收到第一个数据块时，并确保只执行一次），异步执行`DECR`。同样，若`DECR`后额度小于0，记录并`INCR`回0。
*   **原子性**：Redis的`DECR`和`INCR`命令是原子的，保证了并发扣减的正确性。
*   **异步执行**：所有Redis操作和AI调用都应使用Reactive Redis客户端和Reactive HTTP客户端，确保整个流程非阻塞，符合WebFlux模型。
*   **失败回滚**：如果AI模型调用本身失败（例如网络错误、AI服务5xx错误），则不应扣减限额。这通过将扣减操作置于成功路径（`doOnSuccess`, `doOnNext`）来实现。

这个方案确保了在异步环境中，限额管理既高效又准确，同时考虑了流式与非流式调用的差异。关键在于将限额的检查和扣减逻辑正确地编织进反应式链条中。


对于返回单个完整响应的非流式AI调用，限额扣减发生在AI服务成功返回响应之后。当AI调用成功执行完成后，将在Redis中取锁并对该代理API Key执行一次扣减操作。 如果扣减后返回的值小于0，说明额度已耗尽，网关会在返回内容时同时返回一个警告。
    
对于AI流式调用的限额扣减，系统在接收到流的每一个数据块时都会进行一个相应的扣减操作。扣减采用Redis的原子DECR操作，若结果小于0表示额度耗尽，此时会主动的向相应ai服务商发出通知提前终止流，同时返回警告