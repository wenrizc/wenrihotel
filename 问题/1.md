好的，我们来详细探讨一下这些问题。

### **第一部分：实习经历 (Internship Experience)**

#### **模块一：用户权限管控 (RBAC & Sa-Token)**

*   **问题 1.1.1 & 追问 1.1.3：数据库表设计与“资源”的理解**

    在数据库设计上，我遵循了经典的 RBAC 模型，核心表包括：
    1.  **用户表 (sys_user):** 存储用户的基本信息，如用户名、密码、状态等。
    2.  **角色表 (sys_role):** 定义系统中的角色，如“管理员”、“运营”、“普通用户”。
    3.  **权限表 (sys_menu):** 这张表是权限的核心，我在这里存储了系统中所有需要被控制的“资源”。
    4.  **用户-角色关联表 (sys_user_role):** 存储用户和角色的多对多关系。
    5.  **角色-权限关联表 (sys_role_menu):** 存储角色和权限的多对多关系。

    关于**“资源”和“权限”**的区别与联系：
    *   **资源 (Resource):** 在我的设计中，“资源”是权限作用的对象，是具体化的、需要被保护的东西。它可以是一个菜单（如“用户管理”）、一个页面上的按钮（如“新增用户”按钮），甚至是一个后端的 API 接口（如 `POST /system/user`）。我将这些资源都抽象化并存储在 `sys_menu` 表中，通过类型字段（菜单、按钮等）来区分。
    *   **权限 (Permission):** “权限”则是一个更抽象的凭证，它通常表现为一个唯一的字符串标识，比如 `system:user:add`。这个标识与具体的“资源”（比如“新增用户”按钮和对应的 API）进行绑定。系统在进行鉴权时，判断的是当前用户是否拥有某个 `Permission` 字符串，而不是直接判断他能否访问某个 URL。

    **举例来说：** “编辑文章”这个功能，它对应一个前端的“编辑”按钮和一个后端的 `PUT /api/article/{id}` 接口，这两者都是“资源”。我为它们统一授予一个名为 `article:edit` 的“权限”标识。当一个角色被赋予了 `article:edit` 这个权限后，拥有该角色的用户就既能看到“编辑”按钮，也能成功调用对应的后端接口。这种设计将权限的定义与具体实现解耦，更加灵活。

*   **追问 1.1.4：多角色权限冲突处理**

    我的系统采用的是**权限并集**策略，这也是 RBAC 模型中最常见的处理方式。当一个用户拥有多个角色时，他的最终权限集合是所有角色所含权限的**总和 (Union)**。

    例如，用户同时拥有角色 A 和角色 B：
    *   角色 A 拥有“查看文章”、“编辑文章”权限。
    *   角色 B 拥有“查看文章”、“评论文章”权限。

    那么该用户的最终权限就是这三个权限的并集：“查看文章”、“编辑文章”、“评论文章”。对于你提到的场景（角色A有“编辑文章”，角色B没有），用户最终是**拥有**“编辑文章”权限的。我的系统设计中没有“禁止”或“冲突”的概念，权限是“增益”的，只要有一个角色赋予了某权限，用户就拥有该权限。

*   **追问 1.1.5：为何选择 Sa-Token**

    在技术选型时，我确实对比了 Spring Security、Shiro 和 Sa-Token：
    *   **Spring Security:** 功能最强大，与 Spring 生态结合最紧密，但配置相对复杂，学习曲线陡峭，对于我们当时快速迭代的需求来说显得有些重。
    *   **Shiro:** 相对轻量，API 设计直观，但社区活跃度近年来有所下降，且对 RESTful API 和微服务的支持需要一些额外的扩展。
    *   **Sa-Token:** 这是一个国产框架，非常轻量级，API 设计极其友好，文档是中文的，对新手上手非常快。它开箱即用地提供了很多实用的功能，比如：多端登录、会话管理、踢人下线、权限注解等，这些功能在 Shiro 或 Spring Security 中可能需要较多配置才能实现。考虑到项目敏捷开发的需求和框架本身提供的便利性，Sa-Token 是当时性价比最高的选择。

*   **追问 1.1.6：Sa-Token 集群部署问题与解决**

    Sa-Token 默认将 Token 数据（会话信息）存储在应用服务器的内存中，这在单体应用中没有问题。但在集群部署时，由于每个服务实例的内存是独立的，会导致以下问题：
    1.  **会话不共享：** 用户通过负载均衡访问到实例 A 登录，Token 存在 A 的内存里。下一次请求被转发到实例 B，B 的内存中没有这个 Token，就会判断用户未登录。
    2.  **功能失效：** 像“在线用户监控”、“强制下线”这类功能，在一个实例上操作，无法影响到其他实例上的用户。

    我的解决方案是**将会话数据外部化存储**。项目中引入了 Redis，我通过实现 Sa-Token 的 `SaTokenDao` 接口，将其底层的数据存取操作全部对接到 Redis。具体来说，我自定义了一个 `SaTokenDaoRedisImpl` 类，重写了 `setObject`、`getObject`、`deleteObject` 等方法，将原来操作内存 Map 的逻辑，改为调用 RedisTemplate 或 RedissonClient 来操作 Redis。这样，所有服务实例都通过 Redis 共享会话数据，上述的集群问题就迎刃而解了。

*   **追问 1.1.7：“在线用户实时监控”实现方案**

    这个功能的实现结合了 Sa-Token 的 API 和前端技术。
    1.  **后端：** Sa-Token 提供了 `StpUtil.searchSessionId("", 0, -1, true)` 这样的 API，可以从 Redis 中搜索出所有当前有效的会话 ID 列表。我基于此封装了一个接口，可以分页查询在线用户的会话信息（如登录账号、IP、登录时间等）。
    2.  **前端：** “实时”获取列表，我没有采用重量级的 WebSocket。考虑到在线用户列表的变化频率不是特别高，且对实时性要求不是极端严格（秒级延迟可以接受），我选择了**前端定时轮询**的方案。前端页面每隔 10 秒或 30 秒调用一次后端的查询接口，刷新在线用户列表。这种方式实现简单，资源消耗可控，满足了业务需求。如果未来对实时性要求更高，可以平滑升级到 WebSocket 或 SSE (Server-Sent Events)。

*   **追问 1.1.8：“强制下线”功能实现**

    这个功能的信令传递完全依赖于我们之前提到的 **Redis 共享会话机制**。
    1.  **服务端操作：** 当管理员在后台管理界面点击“强制下线”按钮并指定一个用户时，前端会调用一个后端 API，例如 `POST /auth/kickout/{userId}`。
    2.  **信令传递：** 后端服务接收到请求后，会调用 Sa-Token 提供的 `StpUtil.kickout(userId)` 方法。这个方法的核心作用，就是直接去 Redis 中找到该用户对应的会话数据，并将其**删除或标记为无效**。
    3.  **用户会话失效：** 由于所有服务实例共享 Redis，所以无论该用户后续的请求被负载均衡到哪个实例，当请求到达时，Sa-Token 的权限拦截器都会去 Redis 中校验 Token 的有效性。由于会话数据已被删除，校验会失败，系统会立即返回一个未授权的状态码（如 401），前端接收到后就会强制用户跳转到登录页面，从而实现了“强制下线”。

    **关于用户正在进行长 API 请求的情况：**
    权限校验通常发生在请求进入业务逻辑之前的 Filter 或 Interceptor 层面。如果用户在被“强制下线”的**那一刻**，正好有一个已经通过了权限校验、正在执行中的长耗时 API 请求，那么这个请求**会继续执行完毕**并返回结果。因为下线操作影响的是**之后**的请求。当这个长耗时请求结束后，用户再发起任何新的请求，都会因为 Redis 中的会话已失效而被拦截。

---

#### **模块二：多级缓存架构 (Redis + Caffeine)**

*   **问题 1.2.1：为何需要两级缓存**

    设计 Redis + Caffeine 的两级缓存架构，主要是为了在性能、成本和系统弹性之间取得平衡。
    *   **Caffeine (L1 缓存):** 它是一个基于 Java 的、高性能的**本地进程内缓存**。它的角色是“前哨”，负责缓存最热点的数据。由于数据直接存储在应用服务器的 JVM 堆内存中，访问速度极快（纳秒级别），没有任何网络开销。这能极大地降低请求延迟，并减轻后端 Redis 的压力。
    *   **Redis (L2 缓存):** 它是一个**分布式缓存**。它的角色是“主缓存”和“数据同步中心”。所有应用实例共享同一个 Redis，解决了本地缓存的数据一致性问题。当 L1 缓存未命中时，会查询 L2 缓存，避免了直接穿透到数据库。

    这个架构的优势是，用 Caffeine 挡住了大部分高频访问，用 Redis 保证了集群环境下数据的一致性和服务的弹性。我主要缓存了**权限数据（用户角色、权限列表）、字典数据、系统配置参数**等变化频率低但读取频率极高的数据。

*   **追问 1.2.2：缓存查询路径**

    当一个请求需要查询用户信息时，完整的流程如下：
    1.  **查询 L1 (Caffeine):** 应用首先根据用户 ID 在本地 Caffeine 缓存中查找。
    2.  **L1 命中:** 如果找到，直接从内存中返回数据，流程结束。这是最快的路径。
    3.  **L1 未命中，查询 L2 (Redis):** 如果本地缓存没有，应用会向 Redis 发起查询请求。
    4.  **L2 命中:** 如果 Redis 中有数据，应用会将数据取回，**并将其写入 L1 本地缓存**（为了下一次访问更快），然后返回给调用方。
    5.  **L2 未命中，查询数据库:** 如果 Redis 也没有数据（缓存穿透或首次加载），应用会执行最终的数据库查询。
    6.  **回填缓存:** 从数据库查到数据后，应用会**先将数据写入 L2 (Redis)，再写入 L1 (Caffeine)**，最后才将数据返回给调用方。
    7.  **数据库也未命中:** 如果数据库中也不存在该用户，为了防止缓存穿透，我会向缓存中写入一个**空值（null value）**并设置一个较短的过期时间。这样，后续对同一个不存在用户的查询就能被缓存挡住。

*   **追问 1.2.3：“事务感知机制”的实现**

    这个机制的核心是利用了 Spring 框架提供的 `TransactionSynchronizationManager`。在我的缓存管理器实现中（`PlusSpringCacheManager` 中 `transactionAware` 默认为 `true`），当一个业务方法被 `@Transactional` 注解标记时：
    1.  Spring 会开启一个数据库事务，并将事务状态注册到 `TransactionSynchronizationManager` 中。
    2.  当业务代码中执行缓存更新操作（如 `@CachePut` 或 `@CacheEvict`）时，被 `TransactionAwareCacheDecorator` 包装后的缓存管理器会检查当前是否存在一个活动的事务。
    3.  如果存在，它**不会立即执行** Redis 的写操作或删除操作，而是将这些缓存操作注册为一个 `TransactionSynchronization` 回调，并把它挂载到当前事务上。
    4.  这个回调的核心逻辑在 `afterCommit()` 方法中。只有当数据库事务**成功提交**后，Spring 的事务管理器才会触发所有注册的 `afterCommit()` 回调。这时，我的缓存操作（写 Redis、清除 Caffeine）才会被真正执行。
    5.  如果事务回滚，这些回调则不会被执行，从而保证了数据库和缓存操作的原子性。

*   **追问 1.2.4：双写失败的数据一致性问题**

    这是一个经典的分布式系统难题。我的系统主要通过以下几种方式来**缓解**而非完全根除这个问题：
    1.  **重试机制：** 对于写 Redis 失败的情况，我加入了一个简单的同步重试逻辑。例如，如果写入失败，会立即重试 1-2 次。这能处理掉大部分因网络瞬时抖动导致的问题。
    2.  **缓存设置较短的过期时间：** 这是最后的兜底方案。我为所有缓存数据都设置了合理的过期时间。即使出现了不一致，数据也只会在这个有限的时间窗口内是不一致的，过期后下一次查询会重新从数据库加载，实现最终一致性。
    3.  **更可靠的方案（规划中）：** 对于核心业务数据，更可靠的方案是引入**消息队列**。当数据库事务提交后，业务服务不直接写缓存，而是发送一条“数据已变更”的消息到 MQ (如 RocketMQ)。然后由一个专门的缓存同步服务来消费这条消息，并去可靠地更新 Redis。如果更新失败，MQ 的重试和死信队列机制能保证消息不丢失，最终完成缓存的更新。

*   **追问 1.2.5：同步双写 vs. 订阅变更日志 (Canal)**

    这两种方案我都有所了解，它们各有优劣：
    *   **事务后同步双写（我的方案）：**
        *   **优点：** 实现简单，与业务代码结合紧密，逻辑清晰。对于写操作不频繁的场景，延迟低，能提供较强的实时一致性。
        *   **缺点：** 对业务代码有侵入性；存在我们刚才讨论的“写缓存失败”导致的不一致风险；无法感知到通过数据库客户端直接修改数据等非应用层操作。
    *   **订阅数据库变更日志（如 Canal）：**
        *   **优点：** 实现了业务与缓存维护的**完全解耦**，业务代码无需关心缓存逻辑。可靠性高，任何对数据库的写入（无论来源）都能被捕获，是真正以数据库为准。
        *   **缺点：** 架构更复杂，需要额外部署和维护 Canal 服务及消费端应用。存在一定的**延迟**，是最终一致性而非实时一致性。

    当时选择同步双写，主要是因为项目初期架构追求简单、快速实现，且业务场景对短暂不一致的容忍度较高。对于金融等要求强一致性的场景，基于 Canal 的方案会是更好的选择。

*   **追问 1.2.6：其他需要主动清理缓存的场景**

    除了用户登出或被踢，还有很多场景需要主动清理缓存，确保数据最新：
    1.  **用户信息修改：** 当管理员修改了某个用户的部门、岗位或个人资料时，必须主动清除该用户的个人信息缓存。
    2.  **角色权限变更：** 当管理员修改了某个角色的权限配置（增删权限）时，必须清除**所有拥有该角色的在线用户**的权限缓存。这是一个一对多的清理，需要特别注意。
    3.  **用户角色关系变更：** 当给用户分配新角色或移除旧角色时，同样需要清除该用户的权限缓存。
    4.  **系统配置或字典数据更新：** 当后台更新了全局配置项或字典表时，需要清除对应的缓存，让所有后续请求都能加载到最新的配置。

    我的处理方式是，在执行这些更新操作的 Service 方法中，数据库操作成功后，通过 `@CacheEvict` 注解或编程式地调用缓存工具类，来精确地清除受影响的缓存 Key。

*   **追问 1.2.7：缓存穿透、击穿、雪崩的解决方案**

    在设计时，我对这三个问题都做了预案：
    *   **缓存穿透（查询不存在的数据）：**
        *   **缓存空值：** 我的主要解决方案。如前所述，当数据库查询不到数据时，我会在 Redis 中缓存一个特殊的空对象，并设置一个较短的 TTL（比如 1 分钟）。
        *   **布隆过滤器（可选）：** 对于某些key格式固定的场景（如商品ID），可以在服务启动时将所有合法的 Key 加载到布隆过滤器中。查询前先经过布隆过滤器，不存在的 Key 直接返回，避免了对后端缓存和数据库的请求。
    *   **缓存击穿（热点 Key 失效）：**
        *   **互斥锁/分布式锁：** 这是我的核心解决方案。当一个热点 Key 失效，多个并发请求过来时，我会尝试获取一个与该 Key 关联的分布式锁（比如用 Redisson 的 `RLock`）。只有第一个获取到锁的线程能去查询数据库并回填缓存，其他线程则会等待或短暂自旋，然后直接从重建好的缓存中获取数据。这避免了“狗桩效应”，保护了数据库。
        *   **热点数据永不过期（逻辑过期）：** 另一种思路是不给热点数据设置物理过期时间，而是在 value 中包含一个逻辑过期时间。查询时发现逻辑过期，由一个单独的线程去异步重建缓存，当前请求则暂时返回旧数据。
    *   **缓存雪崩（大量 Key 同时失效或 Redis 宕机）：**
        *   **针对大量 Key 同时失效：** 我在设置缓存的 TTL 时，会**增加一个随机值**（Jitter），比如 `TTL = base_ttl + random(300)` 秒。这样就把过期时间打散，避免了雪崩式的集中失效。
        *   **针对 Redis 宕机：**
            *   **服务降级与熔断：** 使用 Sentinel 或 Hystrix，当检测到 Redis 连接异常或超时次数过多时，可以进行熔断，后续请求不再访问 Redis，而是直接访问数据库或返回一个友好的默认值，避免整个系统崩溃。
            *   **本地缓存兜底：** 我的 L1 缓存 Caffeine 在这里就能发挥重要作用。即使 Redis 宕机，Caffeine 中仍然可能存在部分数据，可以作为降级方案，提供有限的服务。
            *   **高可用部署：** 在生产环境中，Redis 自身会部署成哨兵或集群模式，保证其高可用性，这是最根本的预防措施。

---

#### **模块三：心理量表测评系统**

*   **问题 1.3.1：多类型题目的数据库设计**

    为了兼容不同类型的题目，我采用了**“主表 + 扩展表”**的设计模式，并结合 JSON 字段来增加灵活性。
    1.  **题目主表 (question)：** 存储所有题目的共性信息，如 `id`, `questionnaire_id` (所属问卷ID), `title` (题干), `type` (题目类型：单选、多选、填空、量表), `order` (题目顺序)等。
    2.  **选项表 (question_option)：** 专门存储选择类题目的选项。包含 `id`, `question_id`, `option_text` (选项文字), `option_value` (选项分值), `order` 等字段。它与题目主表是一对多关系。
    3.  **使用 JSON 字段增强：** 对于像“量表题”（如 1-5 分非常不同意到非常同意）这种结构相对固定的题目，我没有再创建新表，而是在题目主表的 `extra_config` (JSON类型) 字段中存储其特有配置，例如 `{"min": 1, "max": 5, "min_label": "非常不同意", "max_label": "非常同意"}`。这样做既保持了核心表的整洁，又提供了很好的扩展性。

*   **追问 1.3.2 & 1.3.3：答题数据收集策略与数据保留**

    对于“每答一题自动保存”的需求，我权衡了两种方式：
    *   **每题提交一次请求：**
        *   优点：数据实时性最高，用户答完一题数据就落库了，即使浏览器崩溃也只丢失正在作答的当前题。
        *   缺点：对服务器的请求压力巨大。一张问卷 100 题，一个用户就会产生 100 次写请求，如果并发用户多，服务器和数据库会不堪重负。
    *   **前端暂存，定时/批量提交：**
        *   优点：极大减轻了服务器压力。
        *   缺点：存在数据丢失的风险。

    我最终选择了**折中的方案**，结合了前端暂存和后端接口优化：
    1.  **前端暂存：** 用户每答一题，答案会实时保存在浏览器的 `localStorage` 中。这是一个 `key-value` 存储，`key` 可以是 `questionnaireId-userId`，`value` 就是一个包含所有已答题目答案的对象。
    2.  **定时批量提交：** 前端设置一个定时器，比如每隔 1 分钟，或者每当用户作答了 5 道题，就将 `localStorage` 中暂存的所有答案**一次性**提交给后端。
    3.  **后端接口设计：** 后端提供一个批量保存答案的接口，可以接收一个答案数组，然后在一次数据库事务中完成多条答案的写入或更新，效率很高。
    4.  **离开页面时触发提交：** 我还监听了浏览器的 `beforeunload` 事件，当用户尝试关闭或刷新页面时，会触发最后一次数据同步提交。

    **如何最大化保留数据：** 通过上述方案，即使浏览器在第 99 题时崩溃，由于之前的答案已经通过定时器批量提交过，并且当前的答案也已存在于 `localStorage` 中，用户下次重新打开问卷时，系统可以从 `localStorage` 恢复他未提交的作答进度，最多只会丢失最后正在作答但未来得及触发定时保存的那一道题的数据，实现了数据的最大化保留。

*   **追问 1.3.4：大数据量导出处理**

    直接在主线程中处理上万份答卷的导出，确实会引发 OOM 和请求超时。我的解决方案是**异步处理 + 文件服务**：
    1.  **触发异步任务：** 用户在前端点击“导出”按钮时，后端接口并不立即开始生成文件。而是接收导出请求和筛选条件，然后创建一个“导出任务”记录到数据库（状态为“处理中”），并立即返回一个任务 ID 给前端。这个过程非常快。
    2.  **后台异步执行：** 我使用了项目的**任务调度框架 (SnailJob)** 或一个独立的线程池来处理这个任务。一个后台工作线程会根据任务 ID，去数据库查询需要导出的数据。
    3.  **流式读写：** 在查询和生成 Excel 时，我采用了**流式处理**来避免内存溢出。
        *   **数据库层面：** 使用 MyBatis 的 `Streaming` 查询（或游标 `Cursor`），避免一次性将几万条数据全部加载到内存。
        *   **Excel 生成层面：** 使用 EasyExcel 的 `write` 方法，它也是基于 SAX 的流式写入，每处理一部分数据就写入到文件流中，内存占用极低。
    4.  **文件存储与通知：** 生成的 Excel 文件会被上传到**阿里云 OSS**。任务完成后，更新数据库中的任务记录状态为“已完成”，并保存文件的 OSS 访问链接。
    5.  **用户获取文件：** 前端页面会通过任务 ID 定时轮询任务状态。当状态变为“已完成”时，前端会显示一个“下载”按钮，链接指向 OSS 的文件地址，用户即可下载。这样整个过程对用户来说是无感知的，并且对服务器非常友好。

*   **追问 1.3.5：统计分析功能**

    统计分析功能主要包括以下指标：
    *   **基础指标：** 问卷回收率、平均答题时长、各选项选择频次和百分比。
    *   **得分指标：** 每个用户的总分、各个维度的平均分（如果量表包含多个因子）。
    *   **交叉分析：** 例如，不同部门、不同性别的用户在某个维度得分上的差异分析。

    我的计算方式是**“预计算 + 实时计算”**相结合：
    *   **预计算（离线定时任务）：** 对于大部分统计指标，特别是那些计算量大、不需要绝对实时性的（如整体回收率、各维度平均分），我设置了**定时任务**（例如每天凌晨）来执行。任务会扫描前一天新增的答卷数据，增量更新一个预先设计好的“统计结果表”。前端查询时，直接从这个结果表中读取，速度极快。
    *   **实时计算：** 对于用户提交问卷后立即看到的个人得分报告，这部分是**实时计算**的。因为只涉及单个用户的数据，计算量很小，可以在提交成功后立即算出并返回。

    选择这种混合方式，是因为它兼顾了**系统性能**和**用户体验**。复杂的全局统计通过离线任务削峰填谷，保证了系统的整体稳定性；而用户最关心的个人即时反馈则通过实时计算来满足。

---

#### **模块四：文件上传与解析**

*   **问题 1.4.1 & 1.4.2 & 1.4.3：文件上传流程与安全**

    我选择了**前端直传 OSS** 的方案，因为它能极大减轻我们应用服务器的带宽和处理压力。完整流程如下：
    1.  **前端请求凭证：** 用户在前端选择文件后，前端并**不直接**上传文件。而是先向我们的应用服务器发起一个获取上传凭证的请求。
    2.  **后端生成临时凭证 (STS)：** 应用服务器收到请求后，并**不会**将自己的永久 Access Key 返回给前端（这是极不安全的）。它会调用阿里云的 **STS (Security Token Service)** 接口，动态申请一个**临时的、有时间限制、权限受限**的访问凭证。这个凭证通常只允许在指定的 Bucket 内执行上传操作，且几分钟内就会失效。后端将这个临时凭证（包括 AccessKeyId, AccessKeySecret, SecurityToken）和上传的目标地址返回给前端。
    3.  **前端直传 OSS：** 前端拿到这个临时凭证后，使用阿里云的 OSS JavaScript SDK，直接将文件以流的形式上传到 OSS。整个文件数据流**不经过**我们的应用服务器。
    4.  **上传回调通知：** 前端在成功将文件上传到 OSS 后，会调用我们应用服务器的另一个接口，比如 `/file/upload/callback`，将文件名、OSS 上的存储路径等信息告诉后端。
    5.  **后端记录元数据：** 后端在回调接口中，将文件的元数据保存到数据库，用于后续的管理和查询。

    这种方案的**区别和优势**在于，它将大文件传输的压力完全转移给了专业的对象存储服务，我们的服务器只负责轻量的业务逻辑和权限控制，扩展性更好，也更安全。

*   **追问 1.4.4：大文件上传优化**

    对于大文件上传，OSS 的 SDK 已经内置了很好的支持，我主要是在前端进行了配置和启用：
    1.  **分片上传 (Multipart Upload):** 这是核心优化。在前端初始化 OSS SDK 时，我会启用分片上传功能，并设置一个合理的分片大小（比如 5MB）。SDK 会自动将大文件切割成多个小分片，然后可以并发地上传这些分片，极大地提高了上传速度和成功率。
    2.  **断点续传 (Resumable Upload):** 分片上传天然支持断点续传。如果上传过程中网络中断，下次用户重新上传同一个文件时，SDK 会检测到之前已成功上传的分片，并只续传那些失败或未完成的分片，而无需从头开始。这对于大文件上传的用户体验至关重要。
    3.  **上传进度显示：** SDK 提供了上传进度的回调事件，我利用这个事件在前端实现了一个实时的进度条，让用户能够明确感知到上传状态，缓解等待的焦虑。

*   **追问 1.4.5：Excel 解析的异步处理**

    Excel 解析，特别是对于十万行级别的大文件，我坚决地采用了**异步任务**处理，而不是在文件上传的同步请求中完成。
    *   **同步处理的问题：**
        1.  **请求超时：** HTTP 请求有超时限制，一个耗时几分钟的解析任务，几乎必然会导致客户端或网关超时。
        2.  **阻塞线程：** 解析过程会长时间占用 Web 服务器的工作线程，如果并发上传的用户多了，会迅速耗尽线程池，导致服务器无法响应其他请求。
        3.  **内存溢出风险：** 如果解析库使用不当（如一次性加载整个文件到内存），很容易导致 OOM。

    *   **我的异步处理方案：**
        1.  **任务分发：** 在上面提到的 `/file/upload/callback` 接口中，当后端确认文件已上传到 OSS 并记录了元数据后，它不会立即解析，而是将一个“文件解析任务”丢入**消息队列 (MQ)** 或一个**后台任务池 (如 SnailJob)**。
        2.  **后台消费：** 一个或多个独立的消费者/工作线程监听队列，获取任务后，从 OSS 下载文件流，并使用 EasyExcel 的监听器模式（`AnalysisEventListener`）逐行读取和处理数据。这种方式内存占用非常低。
        3.  **通知用户：** 解析任务开始、处理中、完成或失败，都会更新数据库中的任务状态。如何通知用户呢？
            *   **主动轮询：** 前端可以有一个“我的任务”列表，定时刷新任务状态。
            *   **WebSocket/SSE：** 对于实时性要求高的场景，当后台任务完成时，可以通过 WebSocket 向指定用户的前端页面推送一条“解析完成”的消息。
            *   **站内信/通知中心：** 解析完成后，在系统的通知中心给用户发一条消息，用户登录后就能看到。

---

#### **模块五：项目整体与个人成长**

*   **问题 1.5.1：遇到的最困难的技术难题**

    在实习期间，我遇到的最有挑战性的难题是**解决一个由多租户缓存污染引发的数据查询错乱问题**。

    *   **问题背景：** 系统上线了多租户功能后，我们偶尔会接到反馈，A 公司的用户在某个页面上，偶尔会看到一两条属于 B 公司的数据。这个问题非常诡异，复现率低，但一旦出现就非常严重。
    *   **排查思路：**
        1.  **SQL 层面排查：** 我首先怀疑是 MyBatis-Plus 的多租户插件没生效。我开启了 SQL 日志，经过大量测试，发现所有执行的 SQL 语句都正确地带上了 `tenant_id` 条件。这排除了数据库查询层面的问题。
        2.  **缓存层面排查：** 既然数据库是隔离的，问题很可能出在缓存上。我开始审查缓存逻辑。我发现系统虽然引入了多租户，但缓存的 Key 设计还是沿用之前的 `cacheName::key` 格式，没有包含租户信息。
        3.  **定位根源：** 问题的根源在于，当 A 公司的用户查询某个数据（例如 `user:1`），如果缓存中没有，系统会从数据库查询并正确地将 A 公司的数据放入缓存，Key 是 `userCache::user:1`。之后，如果 B 公司的用户也来查询 `user:1`（假设他们的用户 ID 碰巧也为 1），系统会直接命中这个缓存，导致 B 用户看到了 A 用户的数据。这就是典型的**缓存污染**。
    *   **最终解决方案：**
        我重写了 Spring 的 `CacheManager`，创建了一个 `TenantSpringCacheManager` (`TenantSpringCacheManager.java`)。在这个自定义的管理器中，我重写了 `getCache` 方法。在获取或创建 Cache 实例时，我从 `TenantHelper` 中获取当前的 `tenant_id`，并将其作为前缀拼接到原始的 `cacheName` 上。例如，`userCache` 会被动态地变成 `tenant_A:userCache` 或 `tenant_B:userCache`。这样，每个租户在 Redis 中都有了自己独立的命名空间，从物理上隔离了缓存数据，彻底解决了污染问题。
    *   **反思：** 这次经历让我深刻理解到，在引入新的横切关注点（如多租户）时，必须系统性地审视所有相关的基础设施，包括数据库、缓存、日志、文件存储等，确保隔离策略在每一层都得到贯彻。一个微小的疏忽都可能导致严重的安全漏洞。

*   **追问 1.5.2：团队协作角色与沟通**

    在项目中，我主要承担的是**后端模块的独立开发者角色**，但整个过程是在一个紧密的团队协作环境中完成的。
    *   **与前端协作：** 我和前端同学的协作模式是“接口先行”。在开发一个新功能前，我们会一起开个短会，基于产品需求，共同定义好接口的 URL、请求方法、请求参数和返回的数据结构，并用 Swagger 或 OpenAPI 文档（项目中的 `senyor-common-doc` 模块就是为此服务的）记录下来。这份文档就成了我们之间开发的“契约”。这样，我们就可以并行开发，他 Mock 数据进行前端开发，我进行后端实现，联调时效率非常高。
    *   **与产品沟通：** 我会定期与产品经理沟通，确保我对业务需求的理解没有偏差。当遇到一些技术上难以实现或成本过高的需求时，我不会直接拒绝，而是会主动提出替代方案，解释不同方案的技术成本和优劣，帮助产品做出更合理的决策。
    *   **与其他后端同学：** 我们会通过 Code Review 来互相学习和保证代码质量。对于一些公共组件或核心模块的修改，我们会提前在小组内进行方案评审，确保设计是合理且可扩展的。

*   **追问 1.5.3：实习带来的成长**

    这段实习经历给我带来了全方位的成长：
    *   **技术深度：** 我不再是只会用框架的 API，而是开始深入理解其底层原理。比如，为了解决缓存问题，我深入研究了 Spring Cache 的工作机制和 Redisson 的源码；为了优化性能，我学习了 JVM 内存模型和并发编程。我从一个“框架使用者”向“技术原理探究者”转变。
    *   **工程化思维：** 我学会了如何从一个系统的角度去思考问题。比如，设计功能时会考虑可扩展性、可维护性；写代码时会考虑日志记录、异常处理、单元测试（如项目中的 `DemoUnitTest.java`）；解决问题时会系统性地排查，而不是头痛医头。
    *   **软技能：** 我的沟通协作能力和问题解决能力得到了极大的锻炼。我学会了如何清晰地表达技术方案，如何在团队中有效协作，以及如何独立地面对和解决一个复杂的技术难题。这是在学校里很难获得的宝贵经验。收获最大的，我认为是**工程化思维的建立**，它让我看待技术和软件开发的方式更加成熟和全面。

---

### **第三部分：技术栈与技能掌握**

*   **问题 3.1.1：Java 内存模型 (JMM) 与 `volatile`**

    *   **JMM 的理解：** Java 内存模型（JMM）是一个抽象的概念，它并非真实存在的硬件结构。它的核心目标是**定义一套规则，来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让 Java 程序在各种平台下都能达到一致的内存访问效果**。JMM 主要解决了并发编程中的两个关键问题：
        1.  **可见性 (Visibility):** 一个线程对共享变量的修改，何时能被其他线程看到。
        2.  **有序性 (Ordering):** 为了提高性能，编译器和处理器可能会对指令进行重排序，JMM 需要保证在特定情况下程序的执行顺序。
    *   **`volatile` 如何保证可见性：** 当一个变量被声明为 `volatile` 后，JMM 会确保两件事：
        1.  **写操作的刷新：** 当一个线程修改这个 `volatile` 变量时，JMM 会强制将该线程工作内存中的值**立即刷新**回主内存。
        2.  **读操作的失效：** 当一个线程读取这个 `volatile` 变量时，JMM 会强制让该线程工作内存中关于此变量的缓存**失效**，必须重新从主内存中读取最新值。
        通过这一写一读的强制规定，`volatile` 保证了不同线程对该变量的修改总是立即可见的。

*   **追问 3.1.2：`ConcurrentHashMap` (JDK 1.8) 原理**

    `ConcurrentHashMap` 在 JDK 1.8 中相比之前的版本有重大改进，它摒弃了分段锁，性能更好。其高性能主要得益于：
    1.  **数据结构：** 采用了 **`数组 + 链表/红黑树`** 的结构。
    2.  **锁粒度：** 锁的粒度非常细。它不是锁整个 Map，也不是锁一个段（Segment），而是**锁住哈希冲突的那个链表的头节点**。
    3.  **CAS 操作：** 在很多场景下，它甚至不用锁。比如，在向一个空桶（bucket）中放入第一个节点时，它使用的是**无锁的 CAS (Compare-And-Swap)** 操作，性能极高。
    4.  **`synchronized` 关键字：** 只有当发生哈希冲突，需要修改链表或红黑树的结构时，才会使用 `synchronized` 关键字锁住那个桶的头节点。由于 `synchronized` 在 JDK 1.6 之后有锁升级等优化，性能也非常好。

    **相比于 `Hashtable` 或 `Collections.synchronizedMap`：**
    *   `Hashtable` 和 `synchronizedMap` 都是通过 `synchronized` 锁住**整个 Map 对象**来实现线程安全的。这意味着在任何时刻，只有一个线程能对 Map 进行读或写操作，并发性能极差。
    *   `ConcurrentHashMap` 允许多个线程**同时**对 Map 的不同部分进行操作，只有当它们恰好要修改同一个哈希桶时才会产生竞争。因此，它的并发度要高出几个数量级。

*   **问题 3.2.1：Spring AOP 原理与代理选择**

    Spring AOP 的核心是**动态代理**。它在运行时，不修改原始类的代码，而是为目标对象创建一个代理对象。当调用代理对象的方法时，Spring AOP 会在方法执行前后插入预定义的增强逻辑（Advice）。它主要通过两种方式实现动态代理：
    1.  **JDK 动态代理：**
        *   **原理：** 利用 Java 反射机制，在运行时创建一个实现了目标对象所有接口的代理类。它要求**目标对象必须实现至少一个接口**。
        *   **工作方式：** 所有对代理对象方法的调用都会被转发到一个 `InvocationHandler` 处理器，我们可以在这个处理器中织入切面逻辑。
    2.  **CGLIB 动态代理：**
        *   **原理：** 通过字节码技术，在运行时创建一个继承了目标对象的子类作为代理类。它**不要求目标对象实现接口**。
        *   **工作方式：** 它会重写父类（即目标对象）的非 final 方法，在重写的方法中加入切面逻辑。

    **Spring 如何选择：**
    *   如果目标 Bean **实现了接口**，Spring AOP **默认使用 JDK 动态代理**。
    *   如果目标 Bean **没有实现任何接口**，Spring AOP 就会使用 **CGLIB**。
    *   我们也可以通过配置强制 Spring AOP 全部使用 CGLIB 代理。

*   **追问 3.2.2：Spring 解决循环依赖**

    Spring 只能解决**单例（Singleton）作用域下，通过“setter 注入”或“字段注入”产生的循环依赖**。它无法解决构造器注入的循环依赖。

    **解决原理：三级缓存**
    Spring 在创建 Bean 的过程中使用了三级缓存来“提前暴露”一个不完整的 Bean：
    1.  **一级缓存 (singletonObjects):** 存放完全初始化好的 Bean。
    2.  **二级缓存 (earlySingletonObjects):** 存放**提前暴露**的、不完整的 Bean 实例（属性可能还未填充）。
    3.  **三级缓存 (singletonFactories):** 存放能创建 Bean 的工厂，主要用于解决 AOP 代理下的循环依赖。

    **过程（A 依赖 B，B 依赖 A）：**
    4.  创建 A，实例化 A（但未注入属性），然后将一个能创建 A 的工厂放入**三级缓存**。
    5.  开始为 A 注入属性，发现它依赖 B。
    6.  去创建 B，实例化 B，也将 B 的工厂放入**三级缓存**。
    7.  为 B 注入属性，发现它依赖 A。
    8.  此时，Spring 会依次检查一、二、三级缓存中是否有 A。它会在**三级缓存**中找到 A 的工厂，通过工厂拿到一个**不完整的 A 的引用**（如果需要 AOP，此时会创建代理），并将这个引用放入**二级缓存**，然后注入给 B。
    9.  B 创建完成，成为一个完整的 Bean，被放入**一级缓存**。
    10.  回到 A 的创建流程，现在可以拿到完整的 B，将其注入给 A。A 也创建完成，被放入**一级缓存**。

    **为什么构造器注入无法解决？**
    因为构造器注入要求在**实例化对象的那一刻**，就必须提供所有的依赖。A 的实例化需要 B，B 的实例化需要 A，这就形成了一个无法解开的死锁，Spring 无法通过“提前暴露”一个不完整的对象来打破这个环。

*   **问题 3.3.1：Redis 的其他应用场景**

    除了缓存，Redis 凭借其丰富的数据结构，还有很多应用场景：
    *   **分布式锁：** 利用 `String` 类型的 `SETNX` 命令或 Redisson 这样的客户端库，可以实现高效的分布式锁。
    *   **计数器/限流器：** 利用 `String` 类型的 `INCR` 命令可以轻松实现原子性的计数器，非常适合做网站的 PV/UV 统计或接口的访问限流。
    *   **排行榜：** 利用 `Sorted Set` (ZSET) 数据结构，它会根据你给定的分数自动排序，非常适合实现各种排行榜，如游戏积分榜、热销商品榜。
    *   **消息队列：** 利用 `List` 结构的 `LPUSH` 和 `BRPOP` 可以实现一个简单的消息队列。而 Redis 5.0 之后新增的 `Stream` 类型则提供了更专业、功能更强大的消息队列实现，支持消费组、持久化等。
    *   **地理位置服务：** 利用 `Geo` 数据结构，可以存储地理坐标，并高效地进行附近的人/地点查询、计算两点间距离等。

*   **追问 3.3.2：用 Redis 设计分布式锁**

    设计一个可靠的 Redis 分布式锁，需要注意以下几个关键点，以避免各种陷阱：
    1.  **原子性加锁与设置超时：**
        *   **错误做法：** `SETNX lock_key 1` + `EXPIRE lock_key 30`。这是两步操作，非原子。如果在 `SETNX` 成功后，服务器崩溃，`EXPIRE` 未执行，锁将永远无法释放，造成死锁。
        *   **正确做法：** 使用一条命令完成加锁和设置超时，保证原子性。`SET lock_key random_value NX PX 30000`。`NX` 表示 key 不存在时才设置，`PX 30000` 表示设置 30 秒的过期时间。
    2.  **锁的唯一标识与安全释放：**
        *   **问题：** 线程 A 获取了锁，但因业务执行时间过长（超过了锁的超时时间），锁被 Redis 自动释放了。此时线程 B 获取了同一个锁。然后线程 A 执行完毕，执行 `DEL lock_key`，结果把线程 B 的锁给释放了。
        *   **解决方案：** 在加锁时，`value` 不能是简单的 `1`，而应该是一个**唯一的随机字符串**（比如 UUID）。在释放锁时，不能直接 `DEL`，而是要先 `GET` key 的值，判断是否与自己加锁时的随机字符串相等，如果相等才 `DEL`。
    3.  **原子性释放：**
        *   **问题：** 上述的“先 `GET` 再 `DEL`”是两步操作，非原子，仍有并发风险。
        *   **解决方案：** 使用 **Lua 脚本**来执行释放锁的逻辑。将“判断 value 是否相等”和“相等则 DEL”这两个操作写在一个 Lua 脚本里，然后通过 `EVAL` 命令让 Redis 原子地执行这个脚本。这是目前最安全可靠的释放锁方式。
    4.  **锁续期（看门狗机制）：**
        *   对于执行时间不确定的业务，可以设计一个“看门狗”（Watchdog）机制。加锁的客户端开启一个后台线程，定期检查锁是否存在，如果存在且业务仍在执行，就自动延长锁的过期时间。Redisson 客户端已经内置了这种机制。

*   **问题 3.4.1：MySQL InnoDB 事务隔离级别**

    InnoDB 存储引擎支持 SQL 标准的四种事务隔离级别：
    1.  **读未提交 (Read Uncommitted):** 最低的隔离级别。一个事务可以读取到另一个事务**尚未提交**的数据，会产生**脏读**。基本不会使用。
    2.  **读已提交 (Read Committed):** 一个事务只能读取到另一个事务**已经提交**的数据。解决了脏读，但会产生**不可重复读**（同一个事务内，两次读取同一行数据，结果可能不一样）。这是大多数数据库（如 Oracle, SQL Server）的默认级别。
    3.  **可重复读 (Repeatable Read):** 保证在同一个事务中，多次读取同一行数据的结果都是一致的。解决了不可重复读，但理论上仍可能产生**幻读**（同一个事务内，两次范围查询，结果集中的记录数可能不一样）。**这是 MySQL InnoDB 的默认隔离级别。**
    4.  **可串行化 (Serializable):** 最高的隔离级别。所有事务串行执行，完全避免了脏读、不可重复读和幻读。但性能最差。

    我们线上一般就使用 **MySQL 默认的可重复读 (Repeatable Read)** 级别。选择它的原因在于，它在性能和数据一致性之间取得了很好的平衡，并且 InnoDB 引擎通过 **MVCC 和间隙锁 (Gap Lock)** 机制，在很大程度上**避免了幻读**的发生，使得这个级别在大多数业务场景下都足够安全和高效。

*   **追问 3.4.2：MVCC 的理解**

    **MVCC (Multi-Version Concurrency Control)，即多版本并发控制**，是 InnoDB 存储引擎用来提高并发性能的一种核心机制。它的思想是**用空间换时间**，通过保存数据在某个时间点的快照，使得读写操作可以并发执行，互不干扰。

    **实现原理：**
    MVCC 的实现依赖于三个隐藏的东西：
    1.  **两个隐藏列：** InnoDB 会在每行数据后面增加两个隐藏列：`DB_TRX_ID`（创建或最后修改这行数据的事务 ID）和 `DB_ROLL_PTR`（回滚指针，指向这行数据的前一个版本）。
    2.  **Undo Log：** 当数据被修改时，InnoDB 不会直接覆盖旧数据，而是会将旧版本的数据存放到 Undo Log 中。`DB_ROLL_PTR` 就是指向这个 Undo Log 中的记录。这样就形成了一个版本的链条。
    3.  **ReadView (读视图):** 当一个事务开始时（在 RR 级别下），或者每条 `SELECT` 语句执行时（在 RC 级别下），InnoDB 会创建一个 ReadView。这个 ReadView 记录了当前系统中所有活跃的（未提交的）事务 ID。

    **如何工作：**
    当一个事务要去读取某行数据时，它会用自己的 ReadView 和这行数据的 `DB_TRX_ID` 进行比较：
    *   如果 `DB_TRX_ID` 小于 ReadView 中的最小活跃事务 ID，说明这个版本的数据在该事务启动前就已提交，**可见**。
    *   如果 `DB_TRX_ID` 大于 ReadView 中的最大活跃事务 ID，说明这个版本的数据是在该事务启动后才由新事务创建的，**不可见**。
    *   如果 `DB_TRX_ID` 在 ReadView 的活跃事务 ID 列表之间，就要看它是否在列表中。如果在，说明是和自己同一时刻启动的未提交事务修改的，**不可见**；如果不在，说明是已提交的事务，**可见**。

    如果当前版本不可见，InnoDB 就会通过 `DB_ROLL_PTR` 回滚指针，去 Undo Log 中查找上一个版本，然后重复上述的可见性判断，直到找到一个可见的版本为止。

    **与隔离级别的关系：**
    MVCC 是实现**读已提交 (RC)** 和 **可重复读 (RR)** 这两个隔离级别的核心机制。它们的区别就在于 **ReadView 的创建时机**：
    *   在 **RC** 级别下，**每次 `SELECT`** 都会创建一个新的 ReadView。
    *   在 **RR** 级别下，只有**事务中的第一个 `SELECT`** 会创建一个 ReadView，后续的所有 `SELECT` 都会复用这个 ReadView。
    这就是为什么 RR 能实现可重复读，而 RC 不行的原因。