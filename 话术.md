# **第一部分：江苏北斗心悦健康科技有限公司后端实习**

## **模块一：学生心理健康管理平台的RBAC权限系统**

### Situation (情境)

在我们的项目初期，我们面临着一个核心挑战：如何为学校和教育局这类组织构建一个既安全又合规的平台。这不仅要求用户只能访问其角色允许的功能，更重要的是，要杜绝数据越权访问，比如一个班主任不能看到其他班级学生的信息，或者一个校领导只能看到自己学校及下属部门的数据。我们需要一套能够同时满足“功能权限”和“数据权限”双重控制的权限体系。

### Task (任务)

我的任务是实现一个权限系统，实现两层控制：第一是功能权限，比如某个菜单或按钮能不能用；第二是数据权限的控制，确保不同角色的人查到的数据范围是不一样的，比如校长只能看自己学校的，班主任只能看自己班的。

### Action (行动)

1.  **权限模型选择：**
    * 考虑到学校和教育局这类组织层级结构相对稳定，角色职责非常清晰。我采用RBAC模型，即一个用户分配多个角色，每个角色会配置对应的权限。

2.  **功能权限的实现：**
    *   在功能权限的实现上，我采用了`Sa-Token`框架。在用户登录时，会将该用户所拥有的权限标识符缓存到Redis中。
    *   随后结合`Sa-Token`的注解（如`@SaCheckPermission`）和路由拦截器，对API接口进行了访问控制。当用户发起请求时，拦截器会检查用户是否拥有对应的权限标识，如果没有，就拒绝访问。

3.  **数据权限的实现：**
    *   数据权限这里我主要是实现了一个基于`MyBatis-Plus`的自定义SQL拦截器来处理的。
    *   **数据表设计是基础：**
        *   我在**角色表 (`sys_role`)** 中增加了一个关键字段 `data_scope` (数据范围类型)。它是一个枚举值，预定义了多种数据权限规则，例如：`1-全部数据`、`2-本部门数据`、`3-本部门及以下数据`、`4-仅本人数据`。
        *   在**部门表 (`sys_dept`)** 中，为了高效处理“本部门及以下”这种层级关系，我采用了“祖先路径”的设计。表中除了有`parent_id`，还增加了一个`ancestors`字段，它记录了从顶级部门到当前部门的完整ID路径，例如 `/1/10/101/`。这样设计的好处是，查询一个部门的所有子孙部门，只需要一条`LIKE`查询 (`SELECT * FROM sys_dept WHERE ancestors LIKE '/.../dept_id/%'`)，性能非常高。
    *   **工作流程详解：**
        *   当用户（例如一个`data_scope`为“本部门及以下”的校领导）调用一个查询接口时，自定义拦截器会捕获SQL执行。拦截器从当前用户登录的会话中获取其`data_scope`值和所在的`dept_id`。
        *   **关键步骤——生成SQL条件：** 拦截器会根据`data_scope`的值，动态生成SQL片段。
            *   如果`data_scope`是“本部门及以下”，它会利用部门表的`ancestors`字段，一次性查询出该校领导所在部门及所有下级部门的ID列表。然后生成SQL片段，如 `dept_id IN (10, 11, 12, ...)`。
            *   如果`data_scope`是“本部门”，则生成 `dept_id = 10`。
            *   如果`data_scope`是“仅本人”，则生成 `user_id = [当前用户ID]`。
        *   **安全拼接SQL：** 拦截器使用`JSQLParser`这个专业的SQL解析库，将生成的条件片段安全地、以`AND`逻辑拼接到原始SQL的`WHERE`子句之后。这样做可以智能处理各种复杂的SQL结构，并能有效防止SQL注入。
        *   最后，将这条被“增强”过的SQL交给数据库执行。

### Result (结果)

通过这套权限体系的建设，我们成功构建了一个既能满足“功能权限”控制，又能实现精细化“数据权限”隔离的平台。
*   **功能层面**，我们确保了用户只能访问其角色被授权的功能，显著提升了系统的安全性。
*   **数据层面**，我们彻底杜绝了数据越权访问的问题，确保了敏感信息的隔离，比如一个班主任无法查看其他班级学生的数据，校领导也只能看到其权限范围内的数据，极大地增强了平台的合规性。
*   同时，由于采用了RBAC模型和清晰的数据表设计，整个权限系统在管理上直观易懂，后续维护成本也得到了有效控制。

## **模块二：通用心理量表测评引擎**

### Situation (情境)

在我们负责的平台中，需要支持不同的心理量表，比如SCL-90、SDS等等。这些量表的计分规则各不相同。如果为每种量表都硬编码一套评分逻辑，不仅代码会变得非常庞杂，难以维护，而且每次上线新的量表都需要大量的开发和测试工作，效率非常低下。

### Task (任务)

我的任务就是设计并实现一个通用化、可配置的测评引擎，能够方便地快速配置新的量表，而不需要修改核心代码，同时能够准确、高效地处理各种复杂的计分规则。

### Action (行动)

1.  **规则拆解与抽象：**
    *   为了实现通用性，我首先对量表的计分规则进行了深入分析和抽象。我将计分规则拆分成了两个基本类型：
        *   第一类是基础的“**计分因子**”。这通常是由一组题目通过简单的计算（比如求和、求平均值、或特定题目的计分转换）直接得出的。
        *   第二类是“**维度评分**”。一个维度的最终分数往往更复杂，它可能依赖于其他一个或多个“计分因子”的计算结果，或者甚至依赖于其他维度评分。
    *   这些“计分因子”和“维度评分”之间，以及它们构成一个维度的关系解析式，我是基于**表达式解析**来实现的。这意味着我们可以用类似数学公式的字符串来定义这些计算逻辑，比如“`维度A = 因子1 + 因子2 * 0.5`”。

2.  **建模依赖关系（DAG）：**
    *   在抽象出这些因子和维度之间的依赖关系后，我发现它们天然形成了一种有向无环图（**DAG - Directed Acyclic Graph**）的结构。
    *   在这个图中，每一个节点，都代表一个独立的计算任务，比如一个基础的因子分计算，或者一个维度的最终分数计算。
    *   而节点之间的有向边，就清晰地代表了它们的计算依赖关系。例如，如果“维度A”的计算需要“因子1”和“因子2”的结果，那么就会有两条边分别从“因子1”和“因子2”指向“维度A”。

3.  **规划执行路径（拓扑排序）：**
    *   我利用了**拓扑排序**算法，为有向无环图生成一个线性序列，自动规划出一个正确、无依赖冲突的计算序列。引擎就会按照这个序列，一步步地执行各个节点所代表的计算任务，比如先计算所有基础因子分，然后根据因子分计算依赖维度分，最终得到所有维度的正确分数。

### Result (结果)

通过这套通用化、可配置的测评引擎，我们取得了非常好的效果：

*   **开发效率大幅提升：** 现在上线一个新的心理量表，我们不再需要编写大量定制化的代码，而是通过配置界面，以表达式的形式定义好计分因子、维度评分以及它们之间的依赖关系即可。这大大缩短了新量表的集成周期，从几天甚至几周缩短到了几个小时。
*   **代码维护成本降低：** 核心的计算逻辑是通用的，针对具体量表的规则都以配置文件的形式存在，避免了复杂的硬编码，使得代码更加清晰、易于维护。
*   **灵活性与扩展性增强：** 无论将来出现多复杂的计分规则，只要能抽象为因子和维度之间的计算关系，我们都可以通过配置来支持，极大地增强了平台的灵活性和未来的扩展性。
*   **准确性保障：** 拓扑排序确保了计算顺序的正确性，从而保障了所有量表计分结果的准确性。

总的来说，这个通用测评引擎的设计，使得我们的平台在支持复杂心理量表计分方面，变得更加高效、健壮和易于管理。

## **模块三：文件上传与异步解析模块**

### Situation (情境)

在我们的平台中，用户需要上传个人头像，同时还有一个非常重要的功能是批量导入学生名单
### Task (任务)

我的任务就是设计并实现一套高效、稳定且用户友好的文件上传和Excel解析落库方案，能够妥善处理个人头像和学生名单Excel的上传，并确保学生名单数据能被正确、快速地解析并存储到数据库中。

### Action (行动)

1.  **文件存储选择 - 阿里云OSS：**
    *   将用户上传的个人头像和学生名单的Excel文件等内容传至阿里云OSS。

2.  **Excel解析的异步化处理 - RabbitMQ：**
    *   通过RabbitMQ消息队列来做异步的解析落库。
    *   具体流程是：当用户上传完学生名单的Excel文件到OSS后，阿里云oss触发回调通知到达后端服务器，这条消息会被发送到RabbitMQ的一个队列中进行解析落库。

3.  **Excel解析与落库工具 - EasyExcel：**
    *   在消息队列的另一端，我们部署了一个独立的**消费者服务**。这个服务会实时监听RabbitMQ中的Excel解析队列。
    *   当消费者服务接收到一条消息后，它会根据消息中提供的OSS文件路径，从阿里云OSS下载对应的学生名单Excel表格。
    *   **关键一步是解析：** 我选择了使用**EasyExcel**这个开源库来解析Excel。之所以选择EasyExcel，是因为它在处理大文件时具有内存占用低、解析速度快的显著优势，非常适合我们批量导入学生名单的场景。
    *   我会提前定义好Excel对应的Java实体类，并利用EasyExcel的注解功能，可以非常方便地将Excel中的每一行数据映射成Java对象。

### Result (结果)

通过这套方案，我们取得了非常好的效果：

*   **提升用户体验：** 用户上传头像和Excel都能得到即时响应，无需长时间等待，大大提高了用户满意度。
*   **系统高并发和稳定性：** RabbitMQ作为缓冲层，有效地解耦了文件上传和解析落库的过程，即使面对大量并发上传，系统也能稳定运行，不会因为Excel解析的耗时操作而崩溃。
*   **高效的数据处理能力：** 结合EasyExcel的优秀性能，我们能够快速、准确地解析大量的学生名单数据，并顺利落库，满足了业务对数据处理效率的要求。
*   **可扩展性强：** 这套架构是高度模块化的，未来如果需要处理其他类型的文件或数据，我们可以很方便地扩展消费者服务，而不需要改动核心的上传逻辑。

# **第二部分：团剧共创

## 整体设计

### S (Situation - 情境)

我主要负责线上跑团剧本杀平台聊天通信模块的开发，它有很多核心功能，比如单聊、群聊、游戏邀请，还有用户状态同步等等。这些功能都对消息传递的**实时性、可靠性**有着非常高的要求。

但在实际开发中，我们很快就遇到了移动网络环境的复杂性带来的经典分布式通信挑战。您知道，用户可能在4G/5G和Wi-Fi之间频繁切换，信号也不稳定，这些都加剧了问题：

1.  **实时性与资源消耗的矛盾非常突出。** 我们当然希望客户端能和服务器保持长连接，这样消息能实时推送到用户手机上。但移动设备对后台的电量和流量消耗非常敏感，如果我们的连接维持策略不好，很快就会被用户投诉耗电、耗流量，严重影响用户体验。
2.  **消息传递的不可靠性。** 网络稍微抖动一下，或者用户设备短暂离线，消息就很容易丢失。重传又可能导致消息重复，更麻烦的是，并发请求和网络延迟还会导致消息乱序。这些问题，无论哪个出现，都会破坏用户沟通的完整性和我们业务逻辑的正确性。
3.  **极端负载下的系统稳定性也是个大挑战。** 想象一下，在一个大型活跃群组里，或者某个热门活动期间，系统可能会瞬间涌入“消息风暴”，海量消息并发推送。这对服务器的压力是巨大的，轻则导致关键消息延迟，重则可能直接服务拥塞甚至崩溃。

### T (Task - 任务)

一套完整的IM通信架构，需要实现**高效的实时通信**推送通道。其次，要**保障消息的可靠**，不丢不重。
以及要**保障消息的顺序**。同一个会话里的消息，对用户来说消息顺序应当是一致的。
 最后，我们还要**提升系统鲁棒性**。设计一套削峰填谷的机制，确保系统在遭遇“消息风暴”这种极端流量冲击时，依然能保持稳定，并且保障关键信令的优先触达。

### A (Action - 行动)


**第一层面：构建高效实时的长连接通道**

为了实现用户消息的实时推送，我基于Netty框架构建了长连接网关，管理与用户的WebSocket长连接，Netty采用NIO、事件驱动的架构同时具有零拷贝 (Zero-copy)内存池等机制也保证了IO的高性能，可以处理大量的并发连接。

*   我们摒弃了传统的固定周期心跳策略，因为它在多变的网络环境下效率很低。
*   同时我采用了一套基于二分探测”的智能算法来获得当前用户网络情况下适宜的心跳。避免了固定周期心跳策略。它会在一个预设的安全区间（比如30秒到300秒）内，通过不断尝试和调整，来寻找当前网络环境下最佳的心跳周期。如果心跳成功，就尝试更长的周期；如果失败，就缩短周期。通过几次探测，它能很快收敛到一个最优值。


**第二层面：实现“精确一次、顺序送达”的可靠消息机制**

有了稳定的长连接通道后，下一步就是在此之上构建消息的可靠性与一致性，实现“Exactly-Once-In-Order”：

1.  **针对“消息丢失”**：我们建立了“确认与重试”的闭环机制。客户端每发送一条消息，都会在本地缓存并启动一个超时计时器。服务器成功处理消息后，会返回一个ACK确认包。如果客户端在超时时间内没有收到ACK，就会自动重发这条消息。这保证了消息的“至少一次”送达。
2.  因为重试机制可能会带来消息重复到达服务端的副作用（比如ACK在网络中丢失），所以每条消息中发送时会加入了一个由客户端生成的**全局唯一ID（UUID）**。服务器端会使用Redis缓存已处理过的消息ID。当收到消息时，会先检查这个ID是否已存在，如果存在就直接丢弃，不再重复处理。这样就把“至少一次”送达升级为“精确一次”送达。
3.  **针对“消息乱序”**：为了解决会话内部消息一致性的问题，采用了基于**Redis的序列号方案**。每条消息在被处理前，都会先从Redis中通过incr指令获取一个针对该会话（比如某个聊天群）的**单调递增的序列号**。客户端和服务器都可以依据这个序列号对消息进行最终排序，彻底解决了乱序问题。

IM通信系统中的消息在信箱中的存储和读取方式，主要有两种实现模式：读扩散模式和写扩散模式。
#### 私聊（写扩散模式）

*   **工作原理**：在写扩散模式下，每个用户都拥有一个关联会话的信箱列表。当用户A向用户B发送单聊消息时，消息同时写入两者各自的信箱，这意味着发送消息的写请求被扩散为原来的2倍。
*   **优点**：对于点对点的私聊场景，用户接收消息时只需从自己的信箱列表中拉取即可，只需一次读消息请求，写请求仅被固定放大2倍，对于单聊来说是可接受的。
*   **缺点**：但如果应用于上千人群聊场景，写放大问题明显，消息会被冗余存储多份，写扩散的问题会非常严重。

#### 群聊（读扩散模式）

*   **工作原理**：在读扩散模式下，每个会话（包括群聊会话）占用一个共享信箱，所有会话成员共同对这个信箱进行读写。 当用户A在群聊中发送消息时，消息只会被投递到该群聊会话的信箱中存储一份。
*   **优点**：发送消息的逻辑非常轻量，只需要将消息写入信箱即可，无需关心是单聊还是群聊。 每条消息仅被存储一次，大大节省了存储空间。 对于大型群聊场景，读扩散的效率非常高。
*   **缺点**：用户读取消息时存在严重的读放大问题。 同时在线人数越多或者会话越多，读放大问题带来的流量越大。 客户端需要额外的逻辑去拉取和同步消息，可能比写扩散模式在逻辑上稍微复杂一点。

*   **因此针对私聊采用写扩散模式**：因为写请求只被固定放大2倍，没有不可控的高并发流量，保证了私聊的极致简单与实时性。
*   **群聊，我们选择读扩散模式**：虽然读操作存在放大，但对于成员人数较多的群聊，写扩散会带来严重的写放大和存储冗余问题。 读扩散模式能够更高效地处理群消息的发送和存储，有效应对高并发和资源效率问题。

**我们的选择是：私聊采用写扩散，而群聊，特别是大型群聊，我们选择了读扩散模式。** 这样既能保证私聊的极致简单与实时性，又能兼顾群聊的高并发和资源效率，尤其是为了应对后续的“消息风暴”。

**第三层面：设计应对“消息风暴”的推拉结合策略**

解决了单条消息的可靠性后，我们还需要面对极端高并发，也就是“消息风暴”场景。在大型群组里，瞬间涌入海量消息，如果全部通过WebSocket推送，很容易导致连接拥塞。

*   **核心策略**：我采取了“推拉结合”**的策略**。
    *   **控制面**：我们继续利用WebSocket长连接推送轻量级的**“通知信令”**。这些信令是低频的，用于告知客户端系统状态或重要事件。
    *   **数据面**：而在消息风暴发生时，我们会引导客户端通过HTTP短连接“主动拉取”批量、压缩后的消息数据。

*   **具体流程**：
    1.  **风暴检测**：我们在服务端为每个大群组实现了基于令牌桶的计数算法，实时监测群组消息速率。当检测到某个群组的消息速率在短时间内持续超过预设的高阈值时，系统就会判定它进入了**“消息风暴”模式**。
    2.  **模式切换**：服务器会立即通过WebSocket向该群组所有在线用户推送一条轻量级的信令。这个信令非常关键，它会包含一个用于拉取消息的HTTP接口地址，以及一个起始消息ID。
    3.  **旁路拉取**：客户端收到这个信令后，会立即**暂停通过WebSocket接收该群的普通消息**，转而根据信令中的信息，定时通过HTTP接口批量拉取消息。服务端接口也会对返回的数据进行Gzip等压缩，以节省流量。这样就避免了海量消息直接拥塞WebSocket长连接。
    4.  **模式恢复**：当服务端检测到消息速率回落到安全阈值以下时，会再次通过WebSocket推送`message_storm_end`信令。客户端收到后，会恢复到通过WebSocket接收实时消息的正常模式。

### R (Result - 结果)

综上所述，通过这套多层次、系统性的设计，我们成功构建了一个兼具**高实时性、高可靠性与高鲁棒性**的IM通信系统。

*   我们的自适应心跳机制，显著降低了移动端的电量和流量消耗，同时保证了弱网环境下的连接稳定性。
*   端到端的确认重试、幂等性保证和基于Redis的全局序列号，彻底解决了消息丢失、重复和乱序的问题，实现了“精确一次、顺序送达”。
*   而推拉结合的“消息风暴”应对策略，则有效地削峰填谷，保障了系统在极端流量冲击下的稳定运行，确保了关键信令的优先触达。

这套架构为我们应用的快速发展和卓越的用户体验，提供了坚如磐石的底层技术支持。
## **模块一：核心功能 - 虚拟局域网与P2P远程联机**

(背景 Situation) 我们平台服务于大量经典老游戏的玩家，比如魔兽争霸3、CS 1.6等。这些游戏的共同痛点是，它们的多人模式基于局域网IP直连，一旦玩家处于不同地区、不同运营商，特别是被复杂的NAT网络隔开时，就无法联机。

(任务 Task) 我的核心任务就是攻克这个网络壁垒，为分布在天南海北的玩家们，动态地构建一个虚拟的、统一的二层网络平面。要实现可靠的NAT穿透，让游戏程序误以为所有玩家都在同一个网吧里，从而实现无缝联机。

(行动 Action) 为了达成这个目标，我设计了一套以P2P为主、中继为辅的高可用方案：

首先，在核心组网方案上，我们没有重复造轮子，而是选择了业界顶尖的开源方案Tailscale。我在服务端部署了其开源控制端Headscale，作为平台的“中央协调器”。玩家登录客户端后，会向我的Headscale服务器注册，由Headscale来分发密钥、交换节点信息，并协调各个客户端之间进行NAT打洞，尝试建立基于WireGuard的端到端加密隧道。这种P2P直连模式，能为玩家提供最低的延迟。

其次，也是我们这个方案的核心亮点——为可靠性设计的“兜底保障”。我们都清楚，P2P打洞在面对某些极端网络环境，比如运营商级的对称型NAT时，仍然有失败的概率。为了保证任何情况下玩家都能100%连通，我额外在全球多个关键节点，比如香港、东京、法兰克福，部署了我们自己的DERP中继服务器。当任意两个客户端P2P隧道建立失败时，它们的流量会被自动、无感知地切换到延迟最低的DERP服务器上进行加密中继。

(结果 Result) 这套双轨并行的架构，最终取得了非常出色的效果：

1. 我们将玩家间的联机成功率，从单纯依赖P2P时的约80%-90%，提升到了接近100%的水平，实现了“一键虚拟局域网”的承诺。
    
2. DERP中继服务器作为“保险丝”，虽然只服务于少数网络极端的玩家，但它极大地提升了整个平台的稳定性和口碑，确保了没有任何一个用户会因为网络问题被拒之门外，为优秀的用户体验提供了坚实的底层保障。

## **模块二：高可靠消息系统的设计与实现**

(背景 Situation) 我们的平台有许多关键的信令交互，比如好友邀请、对战匹配、实时聊天等。这些信令在不稳定的移动网络环境下，会频繁遭遇分布式系统中最经典的三个问题：消息丢失、消息乱序，以及因重传导致的消息重复。任何一个问题都会直接破坏对战的公平性，严重影响用户体验。

(任务 Task) 我的任务是在应用层构建一套完整的可靠消息保障机制，确保每一条关键信令都能够不多、不少、不乱序地准确送达，实现“Exactly-Once-In-Order”（精确一次、顺序送达）的通信效果。

(行动 Action) 我将这个问题拆解为三个子目标，并设计了一套组合拳来逐个击破：

第一，**针对“消息丢失”，我建立了“确认与重试”的闭环机制**。这类似于TCP的ACK机制。客户端每发送一条消息，就在本地缓存该消息并启动一个超时计时器。服务器处理成功后，会回送一个ACK确认包。如果客户端在超时前未收到ACK，就会自动重发，直到确认为止，从而保证了消息的“至少一次”送达 (At-Least-Once Delivery)。

第二，**针对“消息乱序”，我设计了“全局时钟”序列号方案，这也是本次设计的核心**。并发和网络延迟会导致消息抵达服务器的顺序与发送顺序不一致。为了解决这个问题，我引入Redis作为全局的“发号器”。利用`Redis INCR`命令的原子性和高性能特性，每条需要排序的消息在被处理前，都会先从Redis获取一个全局唯一且单调递增的序列号。这样，无论消息物理上何时到达，我们都有了一个绝对的逻辑时钟，客户端和服务器都可以依据这个序列号对消息进行排序，彻底解决了乱序问题。

第三，**针对“消息重复”，我实现了端到端的“幂等性”保证**。在“确认与重试”机制下，消息重复是必然会发生的副作用（比如ACK包在返回途中丢失）。因此，我在客户端和服务器两端都增加了uuid的幂等性检查。通过一个小的redis缓存窗口来记录近期已处理的消息ID，可以快速识别并丢弃任何重复的消息，从而将“至少一次”送达升级为“精确一次”送达 (Exactly-Once Delivery)。

(结果 Result) 通过这套组合机制的实施，我们从应用层面彻底解决了信令在弱网环境下的不可靠问题。它保证了平台核心交互的100%可靠，为诸如“匹配撮合”、“游戏邀请”等对时序和一致性要求极高的业务场景提供了坚如磐石的底层保障。

## **模块三：基于Netty的实时通信与自适应心跳**

### **Situation (背景)**

在之前的项目中，我们开发一款移动端IM应用时面临一个核心挑战：如何在确保消息实时性的同时，最大限度地降低应用的后台电量和流量消耗。移动网络环境下的NAT超时机制，要求我们必须通过心跳来维持TCP长连接的活性。然而，采用传统的固定周期心跳策略，如果周期设得太短，会频繁唤醒设备，导致严重的电量问题；如果设得太长，又极易因超过NAT超时而导致连接“假死”，影响消息的可靠投递和用户体验。

### **Task (任务)**

我的任务是设计并实现一套智能、自适应的心跳算法，以取代原有的固定周期策略。这套算法需要达到以下几个关键目标：

1. **动态寻优**：能够自动探测并适应任何特定网络环境（如不同Wi-Fi、4G/5G网络）下的最佳心跳周期。
    
2. **极致省电**：在保证连接可靠的前提下，尽可能拉长心跳间隔，减少不必要的网络唤醒和数据传输。
    
3. **高鲁棒性**：能够优雅地处理网络环境的突变（如Wi-Fi与移动数据切换）和暂时的网络波动，快速恢复稳定连接。
    

### **Action (行动)**

为了实现这些目标，我设计并落地了一套基于“二分探测”思想的智能心跳方案。我的具体行动可以分为以下几个层面：

**1. 核心算法设计 - 二分探测机制：**  
我摒弃了从低到高线性增加的探测方式，而是采用了效率更高的二分法。算法在一个预设的[min, max]安全区间内工作：

- **当心跳成功时**：我将当前成功的周期视为新的**“安全下界”**，然后计算这个新下界与当前上界的中点，作为下一次的探测周期。这是一种积极的策略，旨在快速向上寻找更省电的长周期。
    
- **当心跳失败时**：我将这个失败的周期视为**“危险上界”**，并计算它与当前下界的中点，作为下一次的探测周期。这是一个保守的策略，旨在快速回退到安全的周期范围内。
    
- 这个探测过程会持续进行，直到上下界的差值收缩到一个很小的阈值（例如10秒），此时我们就认为找到了最佳心跳点，算法随即进入**“稳定心跳”**状态。
    

**2. 稳定状态下的动态微调与监控：**  
进入稳定状态后，为了应对网络环境的缓慢变化，我加入了基于计数器的微调逻辑：

- **连续成功后的上探**：我引入了一个稳定状态下的**成功计数器**。当心跳**连续成功达到一个阈值（例如20次）**后，算法会认为当前网络非常稳定，可能会支持更长的NAT超时。此时，它会主动**退出稳定状态**，尝试进行新一轮的向上探测，以寻找一个更优的、更省电的周期。
    
- **连续失败后的下调**：同样，我也引入了**连续失败计数器 heartbeatFailedCount**。当在稳定状态下，心跳**连续失败次数超过阈值（例如3次）**，算法会判定当前网络环境恶化，原有的稳定周期已不再安全。此时，它会立即触发下调机制。
    

**3. 提升算法鲁棒性的辅助设计：**

- **失败时的平滑回退**：为了避免因偶然的网络抖动导致心跳周期大幅下调，我设计了一个“成功心跳历史列表”。在触发下调时，算法会**优先**从这个列表中查找一个比当前周期稍小的、已知成功的周期进行回退，而不是直接进行激进的二分下调。这大大增强了算法的稳定性。
    
- **网络环境隔离**：为了快速适应网络切换，我将所有心跳相关的状态（如当前周期、计数器、历史列表等）都存储在一个以**“网络标识符”**（如Wi-Fi的SSID或运营商名称）为Key的Map中。当监听到系统网络切换的广播时，算法能立刻加载新网络对应的策略，实现无缝、快速的适应。
    

### **Result (结果)**

这套智能心跳算法上线后，取得了非常显著的效果：

1. **电量消耗大幅降低**：与之前采用的保守的60秒固定心跳相比，新算法在稳定的Wi-Fi和4G网络下，平均能将心跳周期延长至280秒以上，后台电量消耗**降低了约70%**，极大地提升了我们应用的市场竞争力。
    
2. **连接可靠性显著提升**：由于能够快速适应不同网络的NAT超时特性，因心跳问题导致的“假死连接”和消息延迟率**下降了超过90%**，用户反馈的消息收发体验得到了明显改善。
    
3. **实现了真正的网络自适应**：无论是用户在地铁里频繁切换基站，还是在家庭和公司之间切换Wi-Fi，该算法都能在几分钟内快速收敛到新的最佳心跳周期，表现出了极高的鲁棒性和智能性。


## **模块四：应对“消息风暴”的削峰填谷策略**

好的，面试官您好，我很乐意向您介绍我们如何设计并实施一套方案，以应对大型聊天群中的消息风暴问题。我将使用STAR法则来阐述。

### **S (Situation - 情境)**

在我们的即时通讯系统中，一些活跃的聊天大群（例如，数万人甚至数十万人的群组）在短时间内可能会产生海量的消息写入，这导致了典型的“消息风暴”问题。
*   **核心挑战：** 我们现有的架构主要依赖WebSocket长连接进行消息实时推送。在消息风暴期间，大量的消息涌入会导致：
    1.  **WebSocket连接拥塞：** 单个WebSocket连接承载过多数据，可能导致消息延迟、丢包甚至连接断开。
    2.  **关键消息实时性受损：** 重要的系统通知、@消息等可能被淹没在海量普通消息中，无法及时送达用户。
    3.  **服务器资源耗尽：** 大量消息的推送处理对服务器的CPU、网络带宽造成巨大压力。

### **T (Task - 任务)**

我的任务是设计并实现一套健壮的解决方案，能够：
1.  **有效应对消息风暴：** 确保系统在极端消息量下依然稳定运行。
2.  **保障关键消息的实时性：** 即使在风暴中，用户也能及时收到重要通知。
3.  **避免WebSocket长连接的拥塞：** 将大批量消息的传输从长连接中剥离。
4.  **提高系统整体的伸缩性和可靠性。**

### **A (Action - 行动)**

为了解决这个问题，我主导设计并推动实施了**推拉结合**的策略，具体行动如下：

1.  **核心策略设计：分离控制面与数据面**
    *   **控制面：** 利用WebSocket长连接推送轻量级的“通知信令”。
    *   **数据面：** 当风暴发生时，引导客户端通过HTTP短连接“主动拉取”批量、压缩后的消息数据。

2.  **消息风暴检测机制的构建：滑动窗口计数算法**
    *   我们为每个活跃大群实现了**基于令牌桶的滑动窗口计数算法**。
    *   **实现细节：** 我们设定了一个固定大小的滑动窗口（例如，60秒），并将其划分为更小的“时间桶”（例如，每秒一个桶）。每当消息流入消息队列时，会累加到当前秒对应的桶中。每秒，窗口会“滑动”，丢弃最旧的桶，并计算当前窗口内（过去60秒）的消息总量。
    *   **阈值设定：**
        *   **进入风暴阈值 (`T_enter`)：** 
        *   **退出风暴阈值 (`T_exit`)：** 

3.  **进入消息风暴状态的处理：**
    *   一旦检测到某个群组满足进入风暴的条件，我们的聊天业务逻辑服务器会立即更新该群组的状态，并触发向该群组内所有在线客户端推送**`message_storm_start`**通知信令。
    *   **信令内容 (`message_storm_start`):**
        ```json
        {
            "type": "message_storm_start",        // 标识信令类型
            "group_id": "chat_group_A",           // 发生风暴的群组ID
            "pull_url": "https://api.example.com/chat/pull_messages", // 客户端拉取消息的HTTP接口URL
            "pull_start_id": "unique_snowflake_id_X", // **关键信息：** 指示客户端从哪个消息ID之后开始拉取，确保不遗漏消息。此ID是风暴触发前一刻该群组已持久化的最新消息ID。
            "batch_size_hint": 100,               // 建议客户端每次拉取的批量消息数量
            "pull_interval_ms": 2000              // 建议客户端拉取消息的间隔时间（毫秒）
        }
        ```

4.  **HTTP 旁路拉取机制的实现（批量发送与客户端携带信息）：**
    *   **客户端行为：** 客户端收到`message_storm_start`信令后，立即暂停该群组通过WebSocket接收普通消息，并切换到HTTP拉取模式。
        *   它会记录信令中的 `pull_url` 和 `pull_start_id`。
        *   客户端定时（根据`pull_interval_ms`）向 `pull_url` 发送HTTP GET请求。
        *   **客户端拉取时要携带的信息 (HTTP Request Parameters):**
            *   `group_id`: 当前拉取消息的群组ID。
            *   `since_id`: **至关重要。** 客户端本地已成功处理并渲染的最新消息的全局唯一ID。服务器会返回比此ID更新的所有消息。
            *   `limit`: 期望拉取的消息数量，通常是`batch_size_hint`。
            *   `auth_token`: 用户身份认证令牌。
        *   **客户端处理：** 收到响应后，进行解压缩（支持Gzip/Brotli）、解析，根据`message_id`进行本地去重（避免重复消息），然后按顺序添加到聊天记录中，并更新`since_id`为这批消息中最新的那个。对网络错误采用指数退避重试。
    *   **服务器端 (HTTP Side-Channel Message Pull Service)：** 这是一个独立的、可水平扩展的服务。
        *   **批量发送逻辑：**
            1.  接收客户端请求，进行身份认证和权限校验。
            2.  根据客户端提供的`group_id`和`since_id`，从**消息存储数据库**（已为`group_id`和`message_id`创建联合索引）中高效地查询批量消息。我们通过`ORDER BY message_id ASC LIMIT :limit`确保返回的消息是按序且数量受控。
            3.  将查询到的消息列表封装成标准JSON数组或其他序列化格式。
            4.  根据客户端的`Accept-Encoding`请求头，对整个响应体进行高效压缩（如Brotli或Gzip），并设置`Content-Encoding`响应头。
            5.  返回压缩后的二进制数据流。
        *   我们还在此服务层实施了严格的**API限流**和**熔断机制**，防止单一客户端或恶意请求对服务造成冲击。

5.  **退出消息风暴状态的处理：**
    *   当群组的消息速率**连续5个滑动窗口周期**都低于`T_exit`阈值时，聊天业务逻辑服务器会判断风暴结束。
    *   此时，服务器会向该群组内所有在线客户端推送**`message_storm_end`**通知信令。
    *   **信令内容 (`message_storm_end`):**
        ```json
        {
            "type": "message_storm_end", // 标识信令类型
            "group_id": "chat_group_A"   // 结束风暴的群组ID
        }
        ```
    *   **客户端行为：** 客户端收到`message_storm_end`信令后，立即停止HTTP拉取循环。为确保平滑过渡，它会执行**最后一次HTTP拉取**以捕获可能遗漏的少量消息，然后恢复通过WebSocket接收该群组的实时消息。
    *   **健壮性考量：** 即使`message_storm_end`信令丢失，如果客户端发现长时间未收到新消息且HTTP拉取连续返回空列表，它也会有一个**超时回退机制**：自动停止HTTP拉取，并向服务器发起一次WebSocket同步请求，告知其最新的`message_id`，从而平稳地恢复WebSocket推送。

### **R (Result - 结果)**

通过这套推拉结合的方案，我们取得了显著的成效：
1.  **有效应对消息风暴：** 在高峰期，系统能够平稳处理高出数倍甚至数十倍的消息量，服务不再因消息风暴而中断或出现明显卡顿。
2.  **保障关键消息实时性：** 由于轻量级信令依然通过WebSocket推送，即使在风暴中，用户也能及时收到@提及、系统通知等关键信息。
3.  **WebSocket拥塞缓解：** 大批量消息通过HTTP旁路传输，极大地减轻了WebSocket长连接的压力，使其能够更专注于传输少量关键的实时数据。
4.  **系统伸缩性增强：** HTTP旁路拉取服务可以独立进行水平扩容，更好地应对突发流量。
5.  **用户体验提升：** 用户在消息风暴中的感知延迟显著降低，消息的接收体验更加流畅。

## **模块五：agent设计**

#### **S (Situation): 情境**

在当前的信息环境中，用户提出的问题日益复杂，常常包含特定的专有名词或需要跨领域的背景知识。如果直接将这些问题抛给单一的大型语言模型，会面临两大挑战：
1.  **知识盲点与“幻觉”**：模型的内部知识可能是过时或不全面的，对于非常专业或最新的术语，模型可能会“一本正经地胡说八道”，产生不可靠的回答。
2.  **理解偏差**：对于包含高度专业术语的问题，模型可能无法准确把握其核心意图，导致回答偏离主题。

因此，我们面临的情境是：需要一个既能精准理解问题中的关键概念，又能把握问题整体意图，并基于可靠信息源生成答案的智能系统。

#### **T (Task): 任务**

我的核心任务是：当接收到用户提出的任何问题时，我需要快速、准确地生成一个有据可查、逻辑清晰且内容详实的回答。具体来说，我的目标包括：
*   **精准拆解**：识别并理解问题中的每一个专有名词和关键概念。
*   **全面检索**：通过并行的方式，从知识库中获取最相关、最权威的信息。
*   **深度整合**：将不同来源、不同维度的信息进行有效融合与分析。
*   **优质生成**：最终输出一个高质量、结构化、易于理解的答案。

#### **A (Action): 行动**

为了完成这个任务，我设计了一套严谨、高效的内部工作流。这套流程可以分为以下几个关键步骤：

1.  **第一步：快速模型预处理与任务分派**
    当我收到一个问题，例如“请解释一下在微服务架构中，RAG模型如何利用全文检索技术优化知识库的响应效率”，我的前端“快速模型”会立刻启动。它的职责不是回答问题，而是对问题进行“扫描”和“拆解”，识别出其中的“特殊专有名词”，比如“微服务架构”、“RAG模型”和“全文检索技术”。

2.  **第二步：双通道并行检索**
    任务拆分后，我会启动两个并行的检索通道，这就像一个团队兵分两路，同时行动，以求最高效率：
    *   **通道一：专有名词的全文检索 (Full-text Search)**
        对于被识别出的专有名词，我会调用**全文检索引擎**（类似Lucene或Elasticsearch的机制）。这个通道的特点是“快、准、狠”，它会基于关键词匹配，迅速从我的知识库中找出包含这些术语的原始定义、技术文档或相关资料。 这种方式能确保我对问题中的核心概念有最精确、最原始的理解。
    *   **通道二：原始问题的RAG检索 (Retrieval-Augmented Generation)**
        与此同时，我会将未经修改的**原始问题**作为一个整体，交给我的**检索增强生成（RAG）模块**处理。 与全文检索不同，RAG利用向量化技术，在向量数据库中寻找与整个问题**语义相关**或**意图相近**的知识片段。 这样做的好处是能够捕捉到问题的深层含义和上下文，而不仅仅是字面上的关键词。 例如，它会找到讨论如何提升AI问答系统效率的案例，即便其中没有同时出现所有关键词。

3.  **第三步：信息整合与深度分析**
    来自两个通道的信息——全文检索提供的“点状”精确知识和RAG检索提供的“面状”上下文背景——会一同被提交给我的核心“大型语言模型”。这时，大模型不再是凭空创作，而是像一位拿到了详尽资料的专家，它会：
    *   利用全文检索的结果，确保对专有名词的定义准确无误。
    *   利用RAG检索的资料，理解这些概念是如何相互关联，以及在特定场景下如何应用的。

#### **R (Result): 结果**

通过上述一系列行动，我最终达成了以下成果：

*   **极高的准确性**：我的回答基于双重检索到的真实数据，有效避免了信息“幻觉”，保证了内容的可靠性。
*   **回答的深度与广度**：结合了精确的术语解释和丰富的上下文背景，使得我的回答既有深度，又能覆盖问题的各个方面，信息量远超单一模型。
*   **高效的响应速度**：通过并行处理和快速模型分流，整个流程虽然复杂，但在用户端却能实现高效响应。
*   **强大的适应性**：无论是面对高度专业的学术问题，还是需要综合分析的复杂场景，我的这套架构都能灵活应对，稳定地输出高质量的答案。

综上所述，我这个“跑团Agent”的设计，通过将问题拆解、双通道检索和大型模型分析相结合，成功地解决了传统大模型在处理复杂和专业问题时的痛点，能够稳定、高效地为用户提供精准、全面且可靠的知识服务。


## **第三部分：History Agent 助手 (个人项目)**

#### **模块一：面向复杂历史文献的RAG流程设计**

1. 在文档分块上，我采用了“父子文档”的分块策略来代替固定长度切分。目前上传的资料主要是一些史书：资治通鉴，史记等等，大多具有epub的电子书格式，epub即是被压缩的html包，每个html文件作为章节，天然具有章节的结果，对此我利用每个html内部最小的子标题切分出提供“父文档”，再按段落标签切分出用于精确检索的“子文档”。较好的保证了检索时上下文语义的准确性。
    
2. 在检索上，我设计了“多路召回”机制。用户的提问会同时触发关键词检索和向量检索，再将两路结果融合，这显著提升了召回全度。
    
3. 在排序上，我引入了轻量级的重排序模型模型进行精排。它能对召回块和问题的匹配度进行更精确的二次打分，只把最相关的Top-K内容喂给大模型。，系统的表现尤为出色，真正做到了让大模型能“读懂”和“用好”复杂的历史文献。

同时，我使用Ragas框架搭建了自动化评估流水线。围绕“忠实度”，即答案是否基于上下文，用以检测幻觉；二是“上下文精确率”，衡量召回内容的相关性，这是评判检索模块好坏的关键等检验rag策略的有效性以及优化zheng
#### **模块二：“历史穿越”功能的精巧设计**

*   **Situation (背景):** 我想让Agent不只是一个冰冷的问答工具，而是能模拟与特定历史人物进行深度对话的互动体验。
*   **Task (任务):** 设计一个**动态知识引擎**，让Agent能够融合**私有知识**、**对话历史**和**外部实时知识**，生成符合人物设定且忠于史实的对话。
*   **Action (行动):** 我将这个功能实现为一个**多源信息融合与动态提示词构建**的系统：
    1.  **动态上下文管理:** 我优化了上下文的存储方式，当对话轮次达到阈值时，会触发一次LLM调用，生成一个**结构化的对话摘要**，这个摘要会与原始对话片段一起，作为后续RAG检索的输入源。
    2.  **多源信息检索（核心亮点）:** 当用户开启“历史穿越”模式时，Agent的每一次回复都会触发一个并行的信息检索流程：
        *   **内部检索:** 从用户上传的文献和我的核心史料库中，进行向量检索，找出与当前话题最相关的内容。
        *   **外部API调用（Tool Use）:** 我赋予了Agent调用外部API的能力。它会主动向**CBDB（中国历代人物传记资料库）**、**维基百科**等外部知识库发起查询，获取关于人物关系、时间线的**结构化数据**。
    3.  **动态提示词工程:** Agent会将上述所有检索到的信息——**核心史料片段、结构化知识、对话历史摘要**——进行整合、提炼，构建成一个信息量极度丰富的**超级提示词（Mega Prompt）**，最后再提交给LLM生成回复。
*   **Result (结果):**
    *   Agent生成的对话内容不仅符合人物的口吻和性格，而且能引用具体的史料和精确的时间线，知识密度和趣味性远超简单的角色扮演Prompt。实现了从“问答”到“深度互动体验”的升级。

#### **模块三：对话系统性能优化与工程经验**

(背景 Situation) 我们发现，随着对话轮次的增加，不断变长的Prompt会导致两个严重问题：首先，LLM的推理成本和延迟会线性增长，这在生产环境中是难以接受的性能瓶颈；其次，模型在处理过长的上下文时，容易出现“注意力涣散”的问题，忘记最初的核心任务，导致对话偏离主线。

(任务 Task) 我的任务就是从系统工程的角度，设计并实施一套优化方案，以实现降低推理延迟、节约计算成本，并增强长对话连贯性的三重目标。

(行动 Action) 我采取了一套“计算复用”与“注意力引导”相结合的策略：

第一个，也是效果最显著的，是针对性的计算复用。我深入分析了我们的Prompt结构，发现其中有大量内容是固定不变的，比如Agent的角色设定、能力描述、JSON输出格式要求等系统级指令。针对这个特点，我实施了提示词前缀复用策略，后续内容追加式添加，保证缓存命中最大化。

第二个，在每一轮对话的最终Prompt结尾，我会根据当前的核心任务，动态地注入核心指令，例如：“请记住，你的核心任务是分析赤壁之战的兵力部署。能有效地将模型的注意力拉回到最重要的任务上。

#### **模块四：历史分析功能的ReAct架构**

(背景 Situation) 我们发现，标准的ReAct流程在应对“XX事件的原因是什么？”这类简单问题时表现尚可，但一旦遇到“如何全面评价王安石变法？”这种需要多元视角和深度逻辑的复杂问题，它的表现就像一个“初级研究员”，能找到零散的资料，但无法形成深刻、结构化的洞见，答案往往流于表面。

(任务 Task) 我的任务是突破这种“单兵作战”的局限性，设计一套能模拟人类专家团队进行“头脑风暴-分工研究-汇总思辨”这一完整认知过程的AI架构，以生成具备真正深度和逻辑性的分析报告。

(行动 Action) 我设计的这套“数字专家研讨会”架构，其核心工作流如下，先判断是史实检索类问题还是史实分析类问题，检索的话直接调用rag以及网络搜索进行检索，将相应内容输入给大模型返回结果，分析类会由大模型动态的调用的子agent给出分析报告最后统合，每个子agent采用ReAct架构，分析得到各个视角得报告，最后再交由大模型进行总结归纳。目前做的主要是政治史子 Agent 经济史子 Agent 社会史子 Agent 文化史子 Agent，以及通用agent，每个agent配备相应得领域内部得COT思维链和分析示例引导，以及对应的rag史料库

