
### 示例准备：员工信息表.xlsx

假设用户准备上传一个Excel文件，内容如下：

|   |   |   |   |   |
|---|---|---|---|---|
|姓名 (column_a)|部门 (column_b)|职位 (column_c)|入职日期 (column_d)|薪资 (column_e)|
|张三|技术部|软件工程师|2023-01-15|15000|
|李四|市场部|市场专员|2023-03-20|12000|
|王五|人事部|人事专员|2023-02-10|10000|

---

## 第一阶段：文件上传与消息触发

这个阶段的核心任务是：**接收文件、安全存储、并通知下游服务进行处理。**

#### **步骤 1：用户上传文件**

用户在前端界面，通过点击或拖拽的方式，选择了 员工信息表.xlsx 文件，并点击“上传”按钮。

#### **步骤 2：文件上传服务处理请求 (FileUploadController)**

1. **接收与校验**：后端控制器收到HTTP请求，包含文件 MultipartFile 和用户ID user123。系统首先进行安全校验，例如检查文件后缀是否为 .xlsx 或 .xls，以及文件大小是否在限制范围内。
    
2. **生成唯一标识**：为了防止文件名冲突和保证安全，系统使用UUID生成一个唯一的文件名，例如 a1b2c3d4-e5f6-4a7b-8c9d-1e2f3a4b5c6d.xlsx。
    
3. **上传至云存储**：系统调用阿里云OSS SDK，将文件上传到指定的存储桶（Bucket）中。
    
    - **原始文件名**: 员工信息表.xlsx
        
    - **存储文件名**: a1b2c3d4-e5f6-4a7b-8c9d-1e2f3a4b5c6d.xlsx
        
    - **OSS路径**: uploads/2024/05/a1b2c3d4-e5f6-4a7b-8c9d-1e2f3a4b5c6d.xlsx
        
4. **记录元数据**：将文件的基本信息存入 file_info 数据库表中，此时文件状态为 **UPLOADED (已上传)**。
    
    Generated sql
    
          `-- 在 file_info 表中插入一条新记录 INSERT INTO file_info (     id, original_filename, storage_filename, file_type, file_size,      oss_path, oss_url, status, user_id, upload_time ) VALUES (     1, '员工信息表.xlsx', 'a1b2c3d4-e5f6-4a7b-8c9d-1e2f3a4b5c6d.xlsx', 'xlsx', 12345,     'uploads/2024/05/a1b2c3d4-e5f6-4a7b-8c9d-1e2f3a4b5c6d.xlsx',      'https://your-bucket.oss-cn-hangzhou.aliyuncs.com/.../...xlsx',     'UPLOADED', 'user123', NOW() );`
        
    

#### **步骤 3：发送异步解析消息**

因为检测到这是一个Excel文件，文件上传服务会创建一个解析任务消息，并将其发送到RabbitMQ。

1. **构建消息体 (ExcelParseMessage)**：
    
    Generated json
    
          `{   "fileId": 1, // 对应数据库 file_info 表的ID   "ossFilePath": "uploads/2024/05/a1b2c3d4-e5f6-4a7b-8c9d-1e2f3a4b5c6d.xlsx",   "fileName": "员工信息表.xlsx",   "userId": "user123",   "uploadTimestamp": "2024-05-21T10:30:00Z" }`
        
    
    IGNORE_WHEN_COPYING_START
    
    content_copy download
    
    Use code [with caution](https://support.google.com/legal/answer/13505487). Json
    
    IGNORE_WHEN_COPYING_END
    
2. **发送到消息队列**：通过 RabbitTemplate 将这条JSON消息发送到名为 file_exchange 的交换机，路由键为 excel.parse。RabbitMQ会根据绑定规则，将消息路由到 excel_parse_queue 队列中，等待消费。
    

至此，文件上传的同步操作完成，前端收到“上传成功”的响应，用户无需等待漫长的解析过程。

---

## 第二阶段：异步解析与数据入库

这个阶段是系统的核心，完全在后台异步执行，不影响用户。

#### **步骤 4：Excel解析服务消费消息 (ExcelParseMessageListener)**

1. **监听并接收消息**：Excel解析服务中的监听器 @RabbitListener(queues = "excel_parse_queue") 一直在监听队列。一旦有新消息，它会立即获取并反序列化为 ExcelParseMessage 对象。
    
2. **更新文件状态为“解析中”**：为防止重复处理并方便前端展示进度，服务首先会更新 file_info 表中的文件状态。
    
    Generated sql
    
          `UPDATE file_info SET status = 'PARSING' WHERE id = 1;`
        
    
    IGNORE_WHEN_COPYING_START
    
    content_copy download
    
    Use code [with caution](https://support.google.com/legal/answer/13505487). SQL
    
    IGNORE_WHEN_COPYING_END
    

#### **步骤 5：执行核心解析任务 (ExcelParseService)**

1. **从OSS下载文件**：服务根据消息中的 ossFilePath，再次调用OSS SDK，将云端的Excel文件下载到服务的内存流（InputStream）中。
    
2. **使用EasyExcel解析**：这是最关键的一步。EasyExcel以流式处理的方式逐行读取Excel数据，内存占用极低。
    
    - 系统会定义一个与Excel列对应的Java实体类 ExcelData。
        
    - EasyExcel的 ReadListener 会被触发，每读取一行数据，就创建一个 ExcelData 对象，并填充从Excel单元格读取到的值。
        
    - 同时，为每条数据关联上文件ID（fileId=1）和行号。
        
3. **生成解析结果集**：解析完成后，内存中会形成一个 ExcelData 对象的列表。
    
    Generated java
    
          `// 解析结果示意 List<ExcelData> results = [     new ExcelData(fileId=1, rowNumber=1, columnA="张三", columnB="技术部", ...),     new ExcelData(fileId=1, rowNumber=2, columnA="李四", columnB="市场部", ...),     new ExcelData(fileId=1, rowNumber=3, columnA="王五", columnB="人事部", ...) ];`
        
    
    IGNORE_WHEN_COPYING_START
    
    content_copy download
    
    Use code [with caution](https://support.google.com/legal/answer/13505487). Java
    
    IGNORE_WHEN_COPYING_END
    

#### **步骤 6：数据持久化**

1. **批量存入数据库**：为了提升性能，系统会采用批量插入（Batch Insert）的方式，将解析出的 results 列表一次性存入 excel_data 表中。
    
    Generated sql
    
          `INSERT INTO excel_data (file_id, row_number, column_a, column_b, column_c, ...)  VALUES  (1, 1, '张三', '技术部', '软件工程师', ...), (1, 2, '李四', '市场部', '市场专员', ...), (1, 3, '王五', '人事部', '人事专员', ...);`
        
    
    IGNORE_WHEN_COPYING_START
    
    content_copy download
    
    Use code [with caution](https://support.google.com/legal/answer/13505487). SQL
    
    IGNORE_WHEN_COPYING_END
    

#### **步骤 7：更新最终状态**

1. **标记为“已解析”**：数据成功入库后，服务会最后一次更新 file_info 表，将文件状态更新为 **PARSED (已解析)**，并记录解析完成时间。
    
    Generated sql
    
          `UPDATE file_info  SET status = 'PARSED', parse_time = NOW()  WHERE id = 1;`
        
    
    IGNORE_WHEN_COPYING_START
    
    content_copy download
    
    Use code [with caution](https://support.google.com/legal/answer/13505487). SQL
    
    IGNORE_WHEN_COPYING_END
    
2. **（可选）发送确认**：消息处理器向RabbitMQ发送一个ACK（确认信号），表示该消息已成功处理，可以从队列中移除。
    

---

## 第三阶段：前端反馈与结果展示

这个阶段让用户能够感知到后台处理的结果。

#### **步骤 8：前端轮询或WebSocket更新状态**

前端界面会通过定时轮询（例如每隔5秒查询一次文件状态API）或WebSocket长连接，实时获取 file_info 表中文件的最新状态。

- 上传后，状态显示：已上传
    
- 解析服务接收任务后，状态变为：解析中...
    
- 解析完成后，状态变为：已解析 ✅
    

#### **步骤 9：查看解析结果**

当文件状态变为 已解析 后，前端会提供一个“查看详情”的按钮。用户点击后，前端会调用另一个API，该API会根据 fileId=1 从 excel_data 表中查询所有关联数据，并以表格形式清晰地展示给用户。

---

## 健壮性设计：异常处理流程

如果第二阶段的任何一步出错（例如Excel文件损坏、网络中断、数据库连接失败），系统会：

1. **捕获异常**：在 try-catch 块中捕获错误。
    
2. **记录错误信息**：将详细的错误日志记录下来，便于排查。
    
3. **更新状态为“失败”**：将 file_info 表的状态更新为 **FAILED (解析失败)**，并将错误原因存入 error_message 字段。
    
    Generated sql
    
          `UPDATE file_info  SET status = 'FAILED', error_message = '文件格式错误：第3行第E列非数字'  WHERE id = 1;`
        
    
    IGNORE_WHEN_COPYING_START
    
    content_copy download
    
    Use code [with caution](https://support.google.com/legal/answer/13505487). SQL
    
    IGNORE_WHEN_COPYING_END
    
4. **消息拒绝**：向RabbitMQ发送NACK（不确认信号），并根据配置决定是将消息重新入队重试，还是直接移入“死信队列”进行人工干预。
    

通过以上三个阶段的协作，本系统实现了一个高效、可靠、用户体验良好的Excel文件异步解析流程。