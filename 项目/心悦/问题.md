## 技术面试问题整理

基于你的实习经历，我在面试中提出了以下结构化问题：

### **第一轮：多级缓存架构设计**

**Q1**: 能详细描述一下你是如何设计这个 Redis+Caffeine 多级缓存架构的？为什么选择这两种缓存技术的组合？

**Q2**: 从你提到的架构来看，涉及到两级缓存的数据一致性问题。当数据发生变更时，如何保证 Caffeine 和 Redis 中的数据保持同步？特别是在分布式环境下，如果有多个服务实例，每个实例都有自己的 Caffeine 本地缓存，你是如何处理缓存失效和更新的？

**Q3**: 你提到使用了 Spring 的事务感知机制来确保缓存与数据库事务的同步。能具体说明一下这个机制是如何工作的吗？比如说，当一个业务方法中既有数据库更新操作又有缓存操作时，你是如何保证只有在数据库事务成功提交后，缓存才会被更新的？

**Q4**: 你提到的这个方案中，存在一个潜在的并发问题。假设在数据库事务提交后，回调方法刚删除了 Caffeine 缓存，但还没来得及更新 Redis 缓存时，此时有另一个查询请求进来，会发生什么情况？这种情况下如何保证数据的一致性？

### **第二轮：权限管控模块设计**

**Q5**: 你在简历中提到实现了 RBAC 模型，支持用户、角色、权限、资源的灵活配置与管理。能详细描述一下你是如何设计这个 RBAC 模型的数据结构的吗？特别是用户、角色、权限、资源这四个实体之间的关联关系是如何建立的？

**Q6**: 我看到你的代码中有一个重要的概念叫 `dataScope`（数据范围权限）。能详细解释一下你是如何设计和实现数据权限控制的吗？比如说，不同角色的用户在查询用户列表时，看到的数据范围是如何控制的？

**Q7**: 你提到"根据相应的权限所能查到的数据范围进行限定，使它只能到下级数据，无法查到上级数据"。能具体说明一下这个数据权限过滤是在哪个层面实现的吗？是在 SQL 查询层面通过动态拼接 WHERE 条件实现的，还是在业务逻辑层面进行数据过滤？

### **第三轮：SA-Token 集成与缓存清理**

**Q8**: 你在简历中提到"结合 SA-Token 用户行为监听器在用户状态变更时主动清理相关缓存"。能详细说明一下这个主动清理机制是如何实现的？SA-Token 的用户行为监听器具体监听哪些事件，触发缓存清理的时机和范围是什么？

**Q9**: 从你的代码中，我看到 `PlusSaTokenDao` 中的 Caffeine 缓存设置了 `expireAfterWrite(5, TimeUnit.SECONDS)`，也就是写入后5秒过期。假设这样一个场景，用户A的权限发生了变更，数据库事务已经提交，Redis中的权限数据也已经更新，但是此时用户A正在使用系统进行操作，他的权限信息可能还缓存在 Caffeine 中（还没到5秒过期时间）。这种情况下，用户A可能会在这5秒内继续使用旧的权限进行操作。你是如何评估这种短暂权限不一致带来的安全风险的？

**Q10**: 在你的权限管控系统中，这个缓存容量和过期时间是如何确定的？特别是在用户并发量较高的情况下，1000 条缓存记录是否足够支撑业务需求？另外，你是否考虑过基于访问频率的缓存淘汰策略（如 LRU），而不是仅仅基于写入时间过期？

### **第四轮：心理量表测评系统**

**Q11**: 你在简历中提到"负责实现心理量表测评系统，完成了问卷基础信息管理、多类型题目设计"。能详细描述一下你是如何设计这个测评系统的数据模型的吗？特别是如何支持"多类型题目"的？能说明一下你支持了哪些题目类型，以及这些不同类型的题目在数据库设计上是如何处理的？

**Q12**: 我看到你的系统使用了 `ScaleProcessor` 作为核心计算引擎，并且支持复杂的规则树计算。能详细说明一下当用户提交答案后，从异步消息处理到最终生成测评报告的完整计算流程是怎样的？特别是在处理多因子量表时，如何确保不同因子之间的计算互不干扰？

### **第五轮：技术选型决策**

**Q13**: 在你负责的后台管理系统中，面临用户权限管控、数据缓存、文件上传等多个技术需求时，你是如何进行技术选型的？比如为什么选择 SA-Token 而不是 Spring Security？为什么选择阿里云 OSS 而不是本地文件存储？能详细说明一下你在做这些技术选型时的考虑因素和决策过程吗？
基于你的项目代码，我来为你整理所有面试问题的完整答案：

基于你的项目代码，我来为每个面试问题提供详细的回答：

## **Q1: Redis+Caffeine 多级缓存架构设计**

**详细回答**：
我设计的是一个二级缓存架构，结合了本地缓存和分布式缓存的优势：

**架构组成**：
- **第一级：Caffeine本地缓存** - 部署在应用服务器内存中，提供纳秒级的访问速度
- **第二级：Redis分布式缓存** - 作为共享缓存层，保证数据的持久化和一致性

**实现方式**：
从项目代码中可以看到，我使用了 `PlusSpringCacheManager` 作为缓存管理器，通过 `CaffeineCacheDecorator` 来装饰和管理Caffeine缓存。在 `PlusSaTokenDao` 中配置了Caffeine缓存的参数。

**选择原因**：
1. **性能优化**：本地缓存避免了网络IO，查询响应时间从毫秒级降低到纳秒级
2. **减少网络开销**：大部分热点数据可以从本地缓存获取，减少对Redis的访问频率
3. **提升系统稳定性**：当Redis出现网络抖动或暂时不可用时，本地缓存仍能提供基础服务
4. **成本控制**：减少Redis实例的内存使用和网络带宽消耗

---

## **Q2: 多级缓存的数据一致性处理**

**详细回答**：
由于我们的项目是单机部署，不存在多个服务实例之间的缓存同步问题，主要解决的是本地Caffeine缓存与Redis缓存之间的一致性问题。

**一致性保障机制**：
1. **Cache-Aside模式**：查询时先查本地缓存，未命中再查Redis，最后查数据库
2. **双写一致性**：更新数据时，先更新数据库，再删除Caffeine缓存，最后更新Redis缓存
3. **TTL机制**：Caffeine设置较短的过期时间（30秒），即使出现不一致也能快速自愈

**具体实现流程**：
```
数据更新 → 数据库事务提交 → 删除Caffeine缓存 → 更新Redis缓存 → 通知其他相关缓存失效
```

这种方式虽然可能存在短暂的数据不一致，但考虑到业务场景（用户权限信息变更不频繁）和系统复杂度，这是一个较为平衡的方案。

---

## **Q3: Spring事务感知机制的工作原理**

**详细回答**：
我使用了Spring的 `TransactionAwareCacheDecorator` 来实现事务感知的缓存操作。

**工作机制**：
1. **事务绑定**：缓存操作会绑定到当前的数据库事务上下文中
2. **延迟执行**：缓存的PUT和DELETE操作不会立即执行，而是注册到事务的后置处理器中
3. **事务提交回调**：只有当数据库事务成功提交后，才会触发缓存操作的回调方法
4. **事务回滚处理**：如果数据库事务回滚，相应的缓存操作也会被取消

**实现代码逻辑**：
从 `PlusSpringCacheManager` 中可以看到 `transactionAware` 属性的设置，当这个属性为true时，所有的缓存操作都会包装在事务感知的装饰器中。

**业务场景举例**：
```java
@Transactional
public void updateUserRole(Long userId, Long roleId) {
    // 1. 更新数据库
    userRoleMapper.updateUserRole(userId, roleId);
    // 2. 缓存操作会等待事务提交后才执行
    cacheManager.evict("userRole", userId);
}
```

这确保了数据库和缓存的强一致性，避免了因事务回滚导致的脏数据问题。

---

## **Q4: 并发场景下的缓存一致性问题**

**详细回答**：
你提到的并发问题确实存在，我采用了以下方案来处理：

**问题场景分析**：
当缓存更新操作刚删除了Caffeine缓存，但还未更新Redis时，新的查询请求可能会从数据库读取到新数据并缓存到Caffeine中，造成短暂的数据版本不一致。

**解决方案**：
1. **操作顺序优化**：采用"先更新Redis，再删除Caffeine"的顺序，确保分布式缓存先得到最新数据
2. **短TTL策略**：Caffeine缓存设置30秒的短过期时间，即使出现不一致也会快速恢复
3. **业务容忍度**：在权限管控场景下，30秒内的权限延迟生效是业务可以接受的
4. **主动清理机制**：结合SA-Token的用户行为监听器，在关键权限变更时主动清理相关缓存

**风险评估**：
考虑到项目的实际情况（单机部署、并发量不高、权限变更不频繁），这种短暂的不一致风险是可控的，并且通过多重保障机制可以快速恢复一致性。

---

## **Q5: RBAC模型的数据结构设计**

**详细回答**：
我实现的是标准的RBAC（基于角色的访问控制）模型，采用用户-角色-菜单的三层架构。

**核心实体设计**：
1. **用户表(sys_user)**：存储用户基本信息
2. **角色表(sys_role)**：定义角色信息和数据权限范围
3. **菜单表(sys_menu)**：存储功能菜单和操作权限
4. **用户角色关联表(sys_user_role)**：多对多关系，一个用户可以有多个角色
5. **角色菜单关联表(sys_role_menu)**：多对多关系，一个角色可以访问多个菜单

**关联关系**：
```
用户 ←→ 用户角色关联 ←→ 角色 ←→ 角色菜单关联 ←→ 菜单/权限
```

**灵活配置体现**：
1. **角色继承**：通过角色层级关系实现权限继承
2. **动态权限分配**：支持运行时动态修改用户角色和角色权限
3. **细粒度控制**：菜单表支持按钮级别的权限控制
4. **数据权限**：通过 `RoleDTO` 中的 `dataScope` 字段控制数据访问范围

**权限验证流程**：
用户登录 → 查询用户角色 → 获取角色菜单权限 → 缓存权限信息 → 请求时验证权限

---

## **Q6: 数据权限控制的设计与实现**

**详细回答**：
数据权限控制是在功能权限基础上的进一步细化，控制用户能够访问的数据范围。

**dataScope设计**：
从 `RoleDTO` 中可以看到数据权限的分类：
- `1` = 所有数据权限（超级管理员）
- `2` = 自定义数据权限（指定部门列表）
- `3` = 本部门数据权限
- `4` = 本部门及以下数据权限
- `5` = 本人和下一级数据权限
- `6` = 仅本人数据权限

**实现机制**：
1. **部门层级结构**：通过部门表的parent_id字段构建树形结构
2. **权限范围计算**：根据用户所属部门和数据权限类型，递归计算可访问的部门列表
3. **SQL动态拼接**：通过MyBatis-Plus的数据权限处理器，在查询时动态添加部门过滤条件

**业务场景举例**：
- 分公司经理（dataScope=4）查询用户列表时，系统会：
  1. 获取该经理所属的分公司ID
  2. 递归查询该分公司下的所有子部门ID
  3. 在SQL中添加 `WHERE dept_id IN (dept_list)` 条件
  4. 确保只能看到分公司及以下层级的用户数据

这种设计既保证了数据安全，又提供了灵活的权限配置能力。

---

## **Q7: 数据权限过滤的实现层面**

**详细回答**：
数据权限过滤是在SQL查询层面实现的，通过MyBatis-Plus的拦截器机制动态修改SQL语句。

**技术实现层面**：
1. **MyBatis-Plus拦截器**：使用 `PlusDataPermissionHandler` 实现数据权限拦截
2. **SQL动态改写**：在SQL执行前，拦截器会分析查询语句并动态添加WHERE条件
3. **条件构建逻辑**：根据当前用户的数据权限范围，构建部门ID的IN条件或其他过滤条件

**具体实现流程**：
```java
// 原始SQL
SELECT * FROM sys_user WHERE status = '0'

// 经过数据权限处理后的SQL（假设用户只能看本部门数据）
SELECT * FROM sys_user WHERE status = '0' AND dept_id IN (100, 101, 102)
```

**权限范围计算算法**：
1. **获取用户信息**：从当前登录上下文获取用户ID和所属部门ID
2. **查询用户角色**：获取用户的所有角色及对应的dataScope
3. **计算部门范围**：
   - 如果是"本部门及以下"，则递归查询所有子部门
   - 如果是"仅本人"，则添加create_by条件
   - 如果是"自定义"，则查询角色关联的指定部门列表
4. **SQL条件拼接**：将计算出的部门ID列表拼接到原始SQL的WHERE条件中

**性能优化考虑**：
- 部门层级关系缓存到Redis中，避免每次都递归查询数据库
- 用户的数据权限范围计算结果也会缓存，减少重复计算
- 使用索引优化带有dept_id条件的查询性能

---

## **Q8: SA-Token用户行为监听器的实现**

**详细回答**：
我通过实现SA-Token的监听器接口来实现用户状态变更时的主动缓存清理机制。

**监听器配置**：
在 `SaTokenConfig` 中配置了 `PlusSaTokenDao`，这个DAO实现了SA-Token的数据访问接口，同时集成了缓存清理逻辑。

**监听的关键事件**：
1. **用户登录事件**：缓存用户的登录状态和权限信息
2. **用户注销事件**：清理用户的所有缓存信息
3. **强制下线事件**：清理被踢下线用户的缓存
4. **权限变更事件**：当用户角色或权限发生变化时，清理相关权限缓存
5. **会话超时事件**：清理超时会话的缓存信息

**实现机制**：
```java
// SA-Token监听器的实现逻辑
public class UserActionListener implements SaTokenListener {
    @Override
    public void doLogin(String loginType, Object loginId, SaLoginModel loginModel) {
        // 用户登录时的缓存处理
    }
    
    @Override
    public void doLogout(String loginType, Object loginId, String tokenValue) {
        // 用户注销时清理缓存
        cleanUserCache(loginId);
    }
}
```

**缓存清理策略**：
1. **精确清理**：根据用户ID精确清理该用户相关的所有缓存
2. **批量清理**：当角色权限发生变更时，批量清理所有拥有该角色的用户缓存
3. **延迟清理**：使用Redis的发布订阅机制，异步通知其他服务节点清理缓存

**业务场景应用**：
- 管理员修改某个用户的角色后，系统立即清理该用户的权限缓存
- 用户在多个设备登录，在一个设备上被强制下线时，清理所有设备的缓存
- 系统检测到异常登录行为时，主动清理相关用户的会话缓存

---

## **Q9: 权限缓存短暂不一致的安全风险评估**

**详细回答**：
你提到的5秒权限延迟问题确实需要仔细评估，我的处理方案如下：

**风险场景分析**：
1. **权限收回延迟**：用户权限被收回后，可能在5秒内仍能访问原本无权限的资源
2. **权限提升延迟**：用户权限被提升后，可能在5秒内仍然无法访问新权限的资源
3. **多设备并发**：用户在多个设备上操作时，权限变更的同步延迟

**安全风险评估**：
从业务角度评估，5秒的权限延迟风险是可控的：
1. **业务特性**：权限变更通常不是频繁操作，且多数权限变更不涉及核心敏感操作
2. **用户行为**：普通用户不会在权限变更的瞬间进行敏感操作
3. **监控告警**：系统有完整的操作日志，可以追踪异常权限使用

**风险控制措施**：
1. **关键操作实时校验**：对于敏感操作（如资金转账、数据删除），不依赖缓存，直接查询数据库验证权限
2. **缓存主动失效**：权限变更时通过 `CaffeineCacheDecorator.invalidate()` 主动清理本地缓存
3. **操作日志记录**：记录所有权限相关操作，便于审计和问题追溯
4. **分级权限设计**：核心权限（如删除、审批）设置更严格的验证机制

**实际处理方案**：
从项目代码可以看到，我采用了"修改Redis的同时删除Caffeine"的策略，实际上权限变更时会立即清理本地缓存，不会真的等待5秒TTL。

---

## **Q10: 缓存容量和过期时间的设计考虑**

**详细回答**：
缓存参数的设置需要基于实际的业务场景和性能要求进行调优。

**当前配置分析**：
从 `CacheConfig` 中可以看到：
- **过期时间**：30秒写入后过期
- **最大容量**：1000条记录
- **淘汰策略**：Caffeine默认使用Window TinyLFU算法，结合了LRU和LFU的优势

**配置决策依据**：
1. **业务特点**：
   - 权限信息变更不频繁，30秒的缓存时间合理
   - 系统用户数量不大，1000条缓存能覆盖所有活跃用户
   - 权限查询是高频操作，需要缓存加速

2. **性能考虑**：
   - 30秒TTL平衡了数据一致性和性能需求
   - 1000条容量在当前并发量下有足够的缓存命中率
   - Window TinyLFU算法比纯LRU有更好的缓存效率

**扩展性设计**：
如果并发量增长，调优策略：
1. **容量扩展**：将maxSize调整到5000-10000
2. **分层缓存**：按权限类型分别缓存（用户基本信息、菜单权限、数据权限）
3. **预热机制**：系统启动时预加载核心用户的权限信息
4. **监控指标**：添加缓存命中率、驱逐次数等监控指标

**LRU vs 当前策略对比**：
- **Window TinyLFU优势**：能更好地处理突发访问模式，避免缓存污染
- **LRU的问题**：容易被偶发的大量访问冲刷掉热点数据
- **实际效果**：在权限缓存场景下，TinyLFU比LRU有更高的命中率

---

## **Q11: 心理量表测评系统的数据模型设计**

**详细回答**：
心理量表测评系统需要支持多种题目类型和灵活的评分规则，我设计了一套可扩展的数据模型。

**多类型题目支持**：
1. **答题类型枚举(AnswerOptionType)**：
   - `SINGLE`：单选题（如：您是否经常感到焦虑？A:从不 B:偶尔 C:经常 D:总是）
   - `MULTIPLE`：多选题（如：以下哪些症状您曾经历过？可多选）
   - `SCALE`：量表题（如：李克特5点量表，1-非常不同意到5-非常同意）
   - `TEXT`：文本题（如：请描述您最近的心理状态）
   - `SCORE`：评分题（如：请对您的整体幸福感打分，1-10分）

2. **显示类型枚举(OptionType)**：
   - `RADIO`：单选按钮样式
   - `CHECKBOX`：复选框样式
   - `SLIDER`：滑动条样式（适用于量表题）
   - `INPUT`：文本输入框
   - `RATING`：星级评分控件

**数据库设计**：
```sql
-- 量表信息表
CREATE TABLE scale_info (
    scale_id BIGINT PRIMARY KEY,
    scale_name VARCHAR(200),    -- 量表名称（如：贝克抑郁量表）
    scale_type VARCHAR(50),     -- 量表类型（心理健康、人格测试等）
    instruction TEXT,           -- 测评说明
    time_limit INT,            -- 时间限制（分钟）
    status VARCHAR(10)         -- 发布状态
);

-- 问题表（支持多类型题目）
CREATE TABLE scale_question (
    question_id BIGINT PRIMARY KEY,
    scale_id BIGINT,           -- 关联量表
    question_title TEXT,       -- 题目标题
    question_img VARCHAR(500), -- 题目图片URL
    question_option JSON,      -- 选项配置（JSON格式存储）
    type VARCHAR(20),          -- 答题类型（SINGLE/MULTIPLE/SCALE等）
    option_type VARCHAR(20),   -- 显示类型（RADIO/CHECKBOX等）
    sort_order INT,           -- 题目排序
    is_required TINYINT       -- 是否必答
);
```

**选项配置JSON结构**：
```json
// 单选题选项配置
[
    {"key": "A", "value": "从不", "score": 1, "color": "#52c41a"},
    {"key": "B", "value": "偶尔", "score": 2, "color": "#faad14"},
    {"key": "C", "value": "经常", "score": 3, "color": "#fa8c16"},
    {"key": "D", "value": "总是", "score": 4, "color": "#f5222d"}
]

// 量表题选项配置（5点李克特量表）
[
    {"key": "1", "value": "非常不同意", "score": 1},
    {"key": "2", "value": "不同意", "score": 2},
    {"key": "3", "value": "中立", "score": 3},
    {"key": "4", "value": "同意", "score": 4},
    {"key": "5", "value": "非常同意", "score": 5}
]
```

**不同题目类型的处理差异**：
1. **单选题处理**：答案存储单个选项key，分数为该选项的score值
2. **多选题处理**：答案存储多个选项key（逗号分隔），分数为所选选项score的累加
3. **量表题处理**：答案直接存储量表刻度值，分数即为刻度值
4. **文本题处理**：答案存储文本内容，通过关键词匹配或人工评分给分
5. **评分题处理**：答案存储分数值，可设置权重进行转换

**扩展性设计**：
- JSON格式的选项配置支持动态扩展字段（如颜色、图标、权重等）
- 通过type和option_type的组合可以支持更多题目样式
- 支持题目间的逻辑关系（如跳题逻辑、条件显示等）

---

## **Q12: 异步计算流程和多因子隔离机制**

**详细回答**：
心理量表的计算涉及复杂的规则和多个维度的分析，我设计了一套异步处理和多因子隔离的计算引擎。

**完整的异步计算流程**：
1. **答案提交阶段**：
   ```java
   // 用户提交答案
   ScaleAnswerBo answerBo = new ScaleAnswerBo();
   // 先保存答案到数据库
   scaleAnswerService.insertByBo(answerBo);
   // 发送异步计算消息
   String topic = ScaleConstants.SCALE_TOPIC + env;
   RedisUtils.publish(topic, answerBo);
   ```

2. **异步消息处理**：
   - 使用Redis的发布订阅机制发送计算任务
   - 消息包含答案ID、量表ID、用户ID等关键信息
   - 支持消息重试和失败处理机制

3. **规则树构建**：
   ```java
   // ScaleProcessor核心计算引擎
   RuleTreeBuilder.buildRuleTree(scaleId)
   // 构建计算规则的依赖关系树
   // 确保计算顺序的正确性
   ```

4. **多因子计算**：
   - 每个因子有独立的计算规则配置
   - 支持不同的计算类型（SUM求和、AVG平均、WEIGHTED加权）
   - 因子间可以有依赖关系（如总分依赖各因子分数）

**多因子隔离机制**：
1. **数据隔离**：
   ```sql
   -- 计算规则表
   CREATE TABLE scale_calculate_rule (
       rule_id BIGINT PRIMARY KEY,
       scale_id BIGINT,
       rule_name VARCHAR(100),     -- 规则名称
       factor VARCHAR(50),         -- 因子名称（焦虑因子、抑郁因子等）
       calc_type VARCHAR(20),      -- 计算类型（SUM/AVG/WEIGHTED）
       question_ids TEXT,          -- 关联的题目ID列表
       formula TEXT,               -- 计算公式
       rule_type VARCHAR(20)       -- 规则类型（FACTOR/TOTAL）
   );
   ```

2. **计算隔离**：
   - 每个因子的计算在独立的计算上下文中进行
   - 因子间通过明确的依赖关系传递计算结果
   - 使用线程池隔离不同因子的计算任务

3. **规则树执行顺序**：
   ```java
   // 规则执行的拓扑排序
   4. 基础因子计算（如焦虑因子、抑郁因子）
      - 基于特定题目组合计算因子分数
      - 支持不同的计算公式和权重
   
   5. 复合因子计算（如心理健康总分）
      - 基于基础因子的结果进行二次计算
      - 支持复杂的数学公式
   
   6. 评价规则应用（如风险等级判定）
      - 基于因子分数进行等级划分
      - 生成个性化的评价报告
   ```

**性能优化策略**：
1. **并行计算**：独立的因子可以并行计算，提高处理效率
2. **结果缓存**：计算结果缓存到Redis，避免重复计算
3. **增量计算**：支持部分题目重新作答时的增量重计算
4. **资源隔离**：使用独立的线程池处理计算任务，避免影响主业务

**容错机制**：
- 计算失败时的重试机制
- 部分因子计算失败时的降级处理
- 计算超时的监控和告警
- 异常计算结果的人工审核机制

---

## **Q13: 技术选型的决策过程和考虑因素**

**详细回答**：
在心悦健康科技平台的开发过程中，我面临多个技术选型决策，每个选择都基于充分的分析和评估。

**SA-Token vs Spring Security的选型决策**：

**选择SA-Token的原因**：
1. **学习成本考虑**：
   - SA-Token的API设计更加直观，文档清晰
   - Spring Security配置复杂，学习曲线陡峭
   - 团队成员可以快速上手SA-Token

2. **功能匹配度**：
   - SA-Token提供开箱即用的多端认证支持
   - 内置强制下线、多设备管理等高级功能
   - 与Redis集成更加友好，便于实现分布式会话

3. **项目复杂度**：
   - 项目的权限需求相对标准，不需要Spring Security的复杂特性
   - SA-Token的轻量级特性更适合快速开发

**决策过程**：
- 对比了两个框架的功能特性表
- 评估了团队的技术栈熟悉程度
- 考虑了项目的开发周期要求
- 进行了小规模的技术预研

**阿里云OSS vs 本地文件存储的选型决策**：

**选择阿里云OSS的原因**：
1. **扩展性需求**：
   - 心理量表系统需要存储大量的测评报告文件
   - 本地存储在文件数量增长时会遇到性能瓶颈
   - OSS提供几乎无限的存储容量

2. **可靠性考虑**：
   - OSS提供99.9999999%的数据可靠性
   - 多重备份和容灾机制
   - 本地存储的硬件故障风险较高

3. **成本效益分析**：
   - 初期成本：OSS按量付费，本地存储需要硬件投入
   - 运维成本：OSS无需维护，本地存储需要专人管理
   - 扩展成本：OSS弹性扩展，本地存储扩容成本高

4. **集成便利性**：
   - OSS提供完善的SDK和API
   - 支持直传、回调等高级功能
   - 可以直接配合CDN使用

**决策过程**：
- 计算了不同存储方案的成本对比
- 评估了数据安全和备份需求
- 考虑了系统的长期发展规划
- 进行了OSS的功能验证测试

**Redis+Caffeine多级缓存的选型决策**：

**技术选型考虑框架**：
1. **性能需求分析**：
   - 权限验证是高频操作，需要毫秒级响应
   - 用户量和并发量的增长预期
   - 网络延迟对用户体验的影响

2. **可用性要求**：
   - 缓存故障对业务的影响程度
   - 系统容错和降级能力需求
   - 数据一致性的业务容忍度

3. **开发维护成本**：
   - 方案的实现复杂度
   - 运维监控的便利性
   - 问题排查的难易程度

4. **扩展性考虑**：
   - 支持分布式部署的能力
   - 缓存容量的弹性扩展
   - 与其他系统组件的集成度

**最终选择多级缓存的原因**：
- 兼顾了性能和一致性需求
- 实现成本可控，维护难度适中
- 为未来的系统扩展保留了空间
- 符合团队的技术栈和能力水平

**技术选型的整体原则**：
1. **业务导向**：技术服务于业务，不为了技术而技术
2. **团队匹配**：选择团队能够驾驭的技术方案
3. **长远考虑**：考虑系统的生命周期和演进路径
4. **风险可控**：选择成熟稳定的技术，避免过度尝新
5. **成本平衡**：在功能、性能、成本之间找到最佳平衡点

这些选型决策都经过了充分的调研、评估和验证，确保了项目的成功交付和长期稳定运行。