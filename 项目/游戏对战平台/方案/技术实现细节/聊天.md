
**核心设计思路：**

1.  **统一入口，分类处理**：所有聊天消息都通过WebSocket进入后端，经过初步处理后进入消息队列。消费者根据会话类型（私聊、普通群聊、游戏房间内聊、大厅聊）采取不同的分发和推送策略。
2.  **消息持久化优先**：无论何种聊天类型，消息在进行大规模分发前，都应先由一个核心消费者负责持久化到MySQL，并生成全局唯一的 `message_id` 和会话内有序的 `sequence`。
3.  **在线状态与路由是关键**：Redis维护用户在线状态 (`UserID -> InstanceID`)，用于精确地将消息路由到目标用户所在的后端应用实例。
4.  **动态策略调整**：特别是针对大厅，设计消息密度监测机制，动态切换推送策略。

---

**详细方案：**

### 1. 消息结构

所有聊天消息应包含以下基本字段：

```json
{
  "client_message_id": "uuid_generated_by_client", // 客户端生成，用于ACK
  "message_id": "snowflake_id_generated_by_server", // 服务端生成，全局唯一 (持久化后才有)
  "conversation_id": "string", // 会话ID (e.g., private_userA_userB, group_group123, room_room456, lobby_main)
  "conversation_type": "enum", // 会话类型 (PRIVATE, GROUP, ROOM, LOBBY) - 可由conversation_id推断或显式传递
  "sender_id": "user_id_of_sender",
  "receiver_id": "user_id_or_group_id", // 单聊时为对方UserID，群聊/房间/大厅时为群/房间/大厅ID
  "message_type": "enum", // (TEXT, IMAGE, FILE, SYSTEM_NOTIFICATION, LOBBY_SIGNAL)
  "content": "message_payload", // 消息内容 (文本，或媒体信息的JSON描述)
  "sequence": "long", // 会话内消息序列号 (持久化后才有)
  "timestamp": "long_epoch_millis" // 客户端发送时间戳
}
```

### 2. 消息流转与处理

#### 2.1. 客户端发送消息

1.  **构建消息体**：客户端根据聊天对象和内容，构建上述消息结构（此时无 `message_id`, `sequence`，但有 `client_message_id` 和 `conversation_id`）。
2.  **WebSocket发送**：通过已建立的WebSocket连接将消息发送给后端 `ChatWebSocketHandler`。
3.  **本地UI更新**：客户端可在本地UI上将消息展示为“发送中”状态。

#### 2.2. `ChatWebSocketHandler` (接收实例)

1.  **接收与初步校验**：接收来自客户端的WebSocket消息。
2.  **注入元数据**：补充 `sender_id` (从JWT或会话中获取)。
3.  **发布到RabbitMQ (入口交换机)**：
    *   将消息（此时仍是原始客户端消息，但带有 `sender_id`）发布到 `exchange.im.ingress`。
    *   **路由键(Routing Key)** 可以简单为 `message.new` 或根据 `conversation_type` 进行初步分类，如 `message.private.new`, `message.group.new`。

#### 2.3. `MessageIngestionConsumer` (核心处理与持久化)

这个消费者监听绑定到 `exchange.im.ingress` 的 `queue.im.pending_persist` 队列。

1.  **消费消息**：从队列中获取原始消息。
2.  **生成`message_id`**: 使用雪花算法生成全局唯一的 `message_id`。
3.  **生成`sequence`**:
    *   针对 `conversation_id`，使用Redis `INCR chat:seq:{conversation_id}` 命令获取该会话的下一个序列号。这个 `sequence` 对保证消息顺序、拉取历史消息至关重要。
4.  **敏感词过滤、内容审核**(如果需要)。
5.  **持久化到MySQL**: 将包含 `message_id`, `sequence` 及其他所有必要字段的消息异步存储到 `chat_messages` 表。
    *   **表结构关键索引**: `(conversation_id, sequence)` 联合唯一索引（或主键），`message_id` 唯一索引。
6.  **发送服务端ACK给发送者**:
    *   持久化成功后，需要通知发送方客户端消息已成功被服务器处理。
    *   查询Redis获取发送者 `sender_id` 的 `InstanceID_S`。
    *   将一个包含 `client_message_id`, `message_id`, `sequence`, `status: "SENT_TO_SERVER"` 的ACK消息，通过 `exchange.im.fanout` (路由键 `instance.{InstanceID_S}`) 发送给发送者所在的Spring Boot实例。
    *   发送者实例的 `ChatWebSocketHandler` 收到此内部ACK后，通过WebSocket将其转发给发送方客户端。
7.  **发布到扇出交换机**: 将**已持久化、带有 `message_id` 和 `sequence` 的完整消息**发布到另一个RabbitMQ交换机，例如 `exchange.im.routable` (Topic Exchange)。路由键可设计为 `message.{conversation_type}.{conversation_id}`，例如 `message.room.room_room456`。

#### 2.4. 消息分发与推送策略 (`MessageDistributionConsumer(s)`)

现在，我们根据会话类型设计不同的消费者来监听 `exchange.im.routable`。

##### 2.4.1. 单聊 (PRIVATE) 和 普通群聊 (GROUP) - “读放大”模式

*   **消费者**: `PrivateGroupMessageConsumer` 监听 `message.private.*` 和 `message.group.*` 的路由键。
*   **处理逻辑 (读放大)**:
    1.  从消息中获取 `conversation_id` 和 `sender_id`。
    2.  **确定接收者**:
        *   **单聊**: 接收者即为 `receiver_id` (对方 `UserID`)。
        *   **群聊**: 从Redis缓存（或MySQL）获取该 `conversation_id` (即 `group_id`) 的所有成员 `UserID` 列表。
    3.  **为每个接收者 (不包括发送者自己) 进行处理**:
        *   查询Redis `user:online:{UserID}` 获取其 `InstanceID`。
        *   **如果在线**: 将完整的消息体（或仅 `message_id` + `sequence`，让客户端根据需要再拉取完整消息，但通常直接推完整消息体验更好）发布到 `exchange.im.fanout`，路由键为 `instance.{InstanceID}`。对应实例的 `ChatWebSocketHandler` 会消费并推送给客户端。
        *   **如果离线**:
            *   在Redis中更新该用户的未读消息计数: `HINCRBY user:unread:{UserID} {conversation_id} 1`。
            *   （可选）将 `message_id` 或 `sequence` 存入用户的离线消息队列/列表中 (例如Redis List `user:offline_msgs:{UserID}:{conversation_id}` )，便于用户上线后拉取。
    4.  **消费者确认 (ACK)** RabbitMQ消息。

##### 2.4.2. 游戏房间内聊天 (ROOM) - “写放大”模式 (优化为快速扇出)

这里的“写放大”可以理解为：当一条消息产生后，系统会“放大”这次写入操作，尽快地、主动地将这条消息推送给房间内所有在线成员。相对于需要客户端主动拉取的模式，这是更积极的推送。

*   **消费者**: `RoomChatMessageConsumer` 监听 `message.room.*` 的路由键。
*   **处理逻辑 (快速扇出)**:
    1.  从消息中获取 `conversation_id` (即 `room_id`) 和 `sender_id`。
    2.  **获取房间成员**: 从Redis缓存（`room:members:{room_id}`，Set类型）或MySQL获取当前房间的所有成员 `UserID` 列表。这个缓存在用户加入/离开房间时由 `RoomService` 维护。
    3.  **为每个房间成员 (不包括发送者自己) 进行处理**:
        *   查询Redis `user:online:{UserID}` 获取其 `InstanceID`。
        *   **如果在线**: 将完整的消息体发布到 `exchange.im.fanout`，路由键为 `instance.{InstanceID}`。
        *   **如果离线**: 同普通群聊的离线处理。
    4.  **消费者确认 (ACK)** RabbitMQ消息。

    *对比普通群聊：* 房间聊天的成员列表通常更动态但可能也更小，对实时性要求可能更高。核心机制相似，但可以为房间聊天分配更高优先级的消费者或独立的消费者池。

##### 2.4.3. 大厅聊天 (LOBBY) - 动态策略：常规推送 / 信令+拉取

*   **消费者**: `LobbyChatMessageConsumer` 监听 `message.lobby.*` 的路由键。
*   **消息密度监测**:
    *   需要一个独立的组件或 `LobbyChatMessageConsumer` 内部逻辑来监测大厅消息密度。
    *   **方法**: 使用Redis记录特定时间窗口内（如过去1秒或5秒）大厅消息的数量。
        *   例如，每收到一条大厅消息，`INCR lobby:msg_count_window:{timestamp_bucket}` 并设置 `EXPIRE`。
        *   一个定时任务或每次消息来时检查 `SUM` 过去几个 `timestamp_bucket` 的计数值。
    *   **阈值**: 定义一个“低密度”阈值和一个“高密度”阈值 (用于实现滞后效应，防止频繁切换)。
        *   `lobby_density_threshold_high = 100 msg/sec`
        *   `lobby_density_threshold_low = 70 msg/sec`
    *   **状态存储**: 在Redis中存储当前大厅模式: `SET lobby:mode high_density` (值为 `normal` 或 `high_density`)。

*   **处理逻辑**:
    1.  获取当前大厅模式 (从Redis `lobby:mode`)。

    2.  **IF `lobby:mode == normal` (常规推送)**:
        *   获取大厅所有在线用户（这可能是一个非常大的列表，需要优化，见下方讨论）。
        *   为每个在线用户（不包括发送者）：
            *   查询其 `InstanceID`。
            *   将完整消息体发布到 `exchange.im.fanout`，路由键 `instance.{InstanceID}`。
        *   离线用户不处理大厅消息（通常大厅消息不存储离线，或只存少量）。
        *   *切换到高密度模式检查*：处理完消息后，检查当前消息速率。如果超过 `lobby_density_threshold_high`，则更新Redis `lobby:mode` 为 `high_density`。

    3.  **IF `lobby:mode == high_density` (信令 + 拉取)**:
        *   **不直接推送完整消息给所有用户。**
        *   **累积信令信息**:
            *   将当前消息的 `sequence` 记录到Redis的一个有序集合或列表中，用于标记一个“批次”的起止。例如，`ZADD lobby:signal_batch:{batch_id} {sequence} {message_id}`。
            *   或者，简单地维护一个 `lobby:latest_sequence`。
        *   **广播轻量级信令**:
            *   构建一个信令消息:
                ```json
                {
                  "conversation_id": "lobby_main",
                  "conversation_type": "LOBBY",
                  "message_type": "LOBBY_SIGNAL",
                  "content": {
                    "status": "new_messages_available", // 或 "new_batch_available"
                    // "batch_id": "current_batch_id", // 可选
                    "approx_new_count": 1, // 本次信令触发时的新消息数，可累加
                    "latest_sequence_in_batch": current_message_sequence
                  },
                  "timestamp": "now"
                }
                ```
            *   这个信令消息通过 `exchange.im.fanout` 广播给所有订阅了大厅消息的在线用户实例。
            *   **注意**：为了避免信令本身也形成风暴，信令的广播频率需要控制（例如，每秒最多1-2次，或者当累积了一定数量的新消息后再广播一次信令）。这可以通过Redis计数和时间戳来实现：仅当距离上次发送LOBBY_SIGNAL已超过X毫秒，或累积了Y条新消息时，才实际发送此信令。
        *   *切换到常规模式检查*：处理完消息后，检查当前消息速率。如果持续一段时间低于 `lobby_density_threshold_low`，则更新Redis `lobby:mode` 为 `normal`。

    4.  **消费者确认 (ACK)** RabbitMQ消息。

#### 2.5. 客户端处理 (大厅高密度模式)

1.  **接收WebSocket信令**: 客户端收到 `LOBBY_SIGNAL` 消息。
2.  **发起HTTP拉取**:
    *   客户端根据信令中的信息（例如 `latest_sequence_in_batch`）和自身已收到的最新消息的 `sequence`，确定需要拉取的范围。
    *   向 `MessageController.pullBatchLobbyMessages(last_seen_sequence, limit)` 发起HTTP GET请求。
3.  **`MessageController.pullBatchLobbyMessages`**:
    *   接收 `last_seen_sequence` 和 `limit` 参数。
    *   从MySQL `chat_messages` 表查询 `conversation_id = 'lobby_main'` 且 `sequence > last_seen_sequence` 的消息，按 `sequence` 排序，限制 `limit` 条。
    *   **优化**: 此查询可能压力较大。可以考虑：
        *   使用读写分离的从库。
        *   将近期的大厅消息也缓存一份到Redis Sorted Set (`ZSET lobby:recent_msgs score:sequence member:message_json`)，优先查缓存。
    *   对查询到的消息列表进行**压缩** (如Gzip)。
    *   返回压缩后的批量消息给客户端。
4.  **客户端处理**: 客户端解压消息，渲染到UI，并更新本地 `last_seen_sequence`。

### 3. `ChatWebSocketHandler` (推送端)

*   每个Spring Boot实例的 `ChatWebSocketHandler` 启动时，会为自己创建一个专属的队列（如 `queue.instance.{InstanceID}`），并将其绑定到 `exchange.im.fanout`，监听路由键 `instance.{InstanceID}`。
*   当从该队列消费到消息（无论是完整消息还是服务端内部ACK）时：
    *   如果是发给某个客户端的消息，则找到该客户端的WebSocket Session，推送消息。
    *   如果是服务端内部ACK，则找到发送方客户端的WebSocket Session，推送ACK。
*   **客户端ACK**: 客户端收到消息后，应向服务端发送一个简单的ACK (包含 `message_id` 或 `sequence`)，表明已收到。服务端 `ChatWebSocketHandler` 收到后可以记录日志，或用于实现“已读”回执等高级功能（如果需要）。

### 4. 关键点与优化

*   **大厅在线用户列表**:
    *   如果大厅在线用户非常多（例如几十万到百万），遍历所有在线用户并逐个查询 `InstanceID` 再推送，效率会很低。
    *   **优化方案1 (基于Topic的广播)**: 如果所有实例都处理大厅消息，可以让 `LobbyChatMessageConsumer` 在判断为“常规模式”时，将大厅消息发布到一个特殊的Topic `lobby.messages`，所有实例的 `ChatWebSocketHandler` 都订阅这个Topic。每个实例收到后，自行判断其连接的客户端中有哪些是在大厅的，然后推送。这要求 `ChatWebSocketHandler` 维护一个 `InstanceID -> Set<UserID_in_Lobby>` 的本地映射，或每个WebSocket Session都标记是否在Lobby。
    *   **优化方案2 (Redis Pub/Sub)**: `LobbyChatMessageConsumer` 可以直接通过 Redis Pub/Sub 发布大厅消息（或信令）。所有后端实例订阅该Redis Channel。收到后逻辑同上。这种方式绕过了RabbitMQ进行广播，可能更快，但可靠性方面不如RabbitMQ完善（如需持久化等）。
    *   **通常，对于超大规模大厅，信令+拉取是更稳妥的方案。**

*   **序列号 (Sequence)**: 它是实现消息保序、断线重连后拉取、历史消息分页的关键。
*   **消息去重**: 客户端基于 `message_id`（服务端生成后下发的）进行去重。服务端在持久化时依赖 `(conversation_id, sequence)` 的唯一性约束（或先查再插）。
*   **RabbitMQ**:
    *   确保生产者确认、消费者手动ACK、消息持久化、死信队列都配置妥当。
    *   合理设计Exchange和Queue，利用Topic Exchange的路由能力。
*   **Redis**:
    *   除了在线状态和序列号，还可以缓存：
        *   群/房间成员列表。
        *   近期热点会话的少量最新消息 (如每个会话最新的20条，用`ZSET`按`sequence`排序)。
        *   用户在各会话的最后已读`sequence`。
*   **数据库压力**: `chat_messages`表会是写入和读取热点。
    *   **写入**: 异步批量写入MySQL。
    *   **读取**: 历史消息拉取、大厅批量拉取，应充分利用缓存，并对DB查询进行优化（索引、读写分离）。长期看，`chat_messages` 表需要分库分表。

---

这个方案整合了您提出的不同场景下的消息处理模式，并通过引入消息密度监测和动态策略切换，旨在平衡实时性、系统负载和用户体验。实现细节会比较复杂，尤其是在状态同步、错误处理和各种边界条件方面需要仔细考虑。