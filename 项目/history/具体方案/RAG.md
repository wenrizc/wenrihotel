
### **“史料交叉验证”功能架构设计详解**

#### **1. 概述**

本文档旨在详细阐述“史料交叉验证”功能（以下简称“本功能”）的后端RAG（Retrieval-Augmented Generation）架构设计。本方案遵循先进的RAG理念，通过多阶段、精细化的处理流程，旨在为用户提供精准、全面、可溯源的历史事件分析报告。整体架构以Spring Boot为基础，深度整合Spring AI，并利用PostgreSQL与pgvector作为核心数据与向量存储。

**核心目标**: 解决传统RAG中检索信息不全面、上下文关联弱、最终答案与原始问题相关性漂移等问题，实现高质量的史料对比分析。

**整体流程**: 用户的查询请求将依次经过**查询预处理**、**知识库路由**、**多路混合检索**、**检索后处理（重排序）**、**上下文构建**与**CoT引导式生成**六个核心阶段。

#### **2. 核心组件与技术选型**

| 组件/阶段          | 技术选型/核心库                    | 模型/服务             | 作用                           |
| -------------- | --------------------------- | ----------------- | ---------------------------- |
| **应用框架**       | Spring Boot 3.x             | -                 | 提供应用基础环境和依赖管理                |
| **AI能力编排**     | Spring AI                   | -                 | 贯穿整个流程，简化AI模型和向量数据库的集成与调用    |
| **向量数据库**      | PostgreSQL + pgvector       | -                 | 存储文档向量，执行高效的相似度检索            |
| **文档数据库**      | PostgreSQL (JSONB)          | -                 | 存储原始文档、分片内容及元数据              |
| **嵌入模型**       | Spring AI `EmbeddingClient` | text-embedding-v4 | 将文本（查询、文档）转换为向量表示            |
| **查询预处理**      | Spring AI `ChatClient`      | qwen-turbo        | 对用户原始问题进行重写，生成多个子查询          |
| **重排序模型**      | 自定义服务/HTTP客户端               | gte-rerank-v2     | 对初步检索到的文档进行相关性精排序            |
| **大语言模型(LLM)** | Spring AI `ChatClient`      | qwen-max          | 基于提供的上下文，进行思考链（CoT）推理并生成最终报告 |
| **关键词检索**      | PostgreSQL FTS              | -                 | 实现基于关键词的精确匹配检索               |

#### **3. 阶段一：知识库构建 (离线处理)**

此阶段为所有在线查询的基础，其质量直接决定了RAG系统的上限。

- **3.1. 文档解析与结构化**:
    
    - **说明**: 系统接收用户上传的`.txt`, `.epub`, `.pdf`等格式的史料。使用如库进行内容提取，并尽可能保留原始的结构信息，例如章节标题、段落、出处等。    - 对于PDF格式的史书，使用pdfbox库进行解析对于`.epub`格式，使用`Epublib`库。
        
- **3.2. 父子文本分片 (Parent-Child Chunking)**:
    
    - **说明**: 这是保障检索精度与上下文完整的核心策略。
        
        - **父文档 (Parent Document)**:
            
        - **子文档 (Child Chunk)**
            
    - **实现要点**: 每个子文档必须在元数据中包含其`parent_id`，用于在检索后快速回溯到父文档。
        
- **3.3. 元数据丰富化与存储**:
    
    - **说明**: 为每个“父文档”和“子文档”附加丰富的元数据。包含从文档中提取出来的信息
        
                

#### **4. 阶段二：在线查询与生成 (实时处理)**

当用户提交一个查询时，系统启动以下实时处理流水线。

- **4.1. 查询预处理 (Query Pre-processing)**
    
    - **目标**: 克服用户输入的模糊性，将单一问题扩展为多个具有不同侧重点的、更适合检索的子问题。
        
    - **设计**:
        
        1. 接收用户原始查询，例如“赤壁之战的经过”。
            
        2. 调用模型。
            
        3. 使用一个特定的Prompt，指示模型从不同角度（如原因、过程、关键人物、不同记载）生成3-5个子查询。
            
        4. 例如，Prompt模板可以是：“你是一个历史问题分析助手，请将以下问题分解为多个不同角度的、更具体的子问题，用于在史料库中进行检索。请直接返回一个JSON列表。原始问题：{query}”。
            
        5. 模型返回一个查询列表，如 `["赤壁之战曹操方的准备情况", "周瑜和黄盖在赤壁之战中的计策", "赤壁之战火攻的具体过程"]`。
            
- **4.2. 知识库路由与混合检索 (Routing & Hybrid Search)**
    
    - **目标**: 召回所有可能相关的史料片段，最大化召回率。
        
    - **设计**:
        
        1. **知识库路由**: 根据用户在前端勾选的史料来源（如 "三国志", "三国演义"），生成一个元数据过滤器。这个过滤器将应用于后续的向量检索和关键词检索。例如，`metadata.source_book IN ('三国志', '三国演义')`。
            
        2. **并发混合检索**: `HistoryRetriever`服务将并行执行以下两种检索：
            
            - **向量检索**:
                
                - 将上一步生成的多个子查询分别通过`EmbeddingClient`（调用`text-embedding-v4`）转换为查询向量。
                    
                - 对每个查询向量在pgvector中执行相似度搜索。请求中会包含路由阶段生成的元数据过滤器，确保只在用户指定的史料范围内检索。
                    
                - 此步骤主要召回语义上相关的“子文档”。
                    
            - **关键词检索**:
                
                - 从原始查询和子查询中提取核心关键词（如人名、地名“曹操”、“周瑜”、“赤壁”）。
                    
                - 利用PostgreSQL的全文检索（FTS）功能，在文档库中对这些关键词进行精确匹配。
                    
                - 此步骤主要用于弥补向量检索在专有名词上的不足。
                    
        3. **结果合并**: 将向量检索和关键词检索返回的“子文档”ID列表进行合并，并去重，得到一个初步的候选集。
            
- **4.3. 检索后处理 (Post-processing)**
    
    - **目标**: 从初步候选集中筛选出与原始问题最相关、信息量最丰富的上下文，并过滤噪音。
        
    - **设计**:
        
        1. **父子关联**: 遍历上一步合并后的“子文档”ID列表。根据每个子文档元数据中的`parent_id`，从PostgreSQL中批量查询，获取完整的“父文档”内容。此时我们得到了一系列完整的史料章节或篇章。
            
        2. **重排序 (Rerank)**: 这是提升最终答案质量的关键一步。
            
            - 将获取到的“父文档”列表（例如15-20篇）和用户的**原始问题**（注意，不是子问题）作为输入。
                
            - 通过HTTP请求调用一个封装了**gte-rerank-v2**模型的服务。
                
            - 该服务会对每一对 `(原始问题, 父文档内容)` 计算一个精确的相关性分数。这个分数比向量余弦相似度更能反映文档对解答该问题的真实价值。
                
            - 根据返回的相关性分数，对所有“父文档”进行降序排列。
                
            - 选择分数最高的Top-K个文档（例如K=5）作为最终进入生成环节的上下文。
                
- **4.4. 结果生成优化 (Optimized Generation)**
    
    - **目标**: 利用高质量的上下文，通过强大的LLM生成结构化、逻辑清晰、有理有据的交叉验证报告。
        
    - **设计**:
        
        1. **上下文构建**:
            
            - 将上一步重排序后筛选出的Top-K个“父文档”的内容及其元数据（`source_book`, `author`, `chapter`等）格式化。
                
            - 格式化的形式应清晰易读，例如：
                
                ```
                [史料 1]
                来源: 《三国志》
                作者: 陈寿
                篇章: 周瑜鲁肃吕蒙传
                内容: ... (父文档的完整内容) ...
                
                [史料 2]
                来源: 《三国演义》
                作者: 罗贯中
                篇章: 第四十五回 三江口曹操折兵
                内容: ... (父文档的完整内容) ...
                ```
                
        2. **CoT引导式生成**:
            
            - 使用Spring AI的`ChatClient`（配置为使用**deepseek**模型）和`PromptTemplate`。
                
            - 将用户提供的CoT Prompt模板实例化。`{query}`占位符填入用户的**原始问题**，`{documents}`占位符填入上一步构建好的格式化史料上下文。
                
            - 这个精心设计的Prompt会引导`deepseek`模型：
                
                - **第一步 (分析)**: 逐一理解每份史料的核心观点。
                    
                - **第二步 (求同)**: 提炼所有史料都承认的共同事实。
                    
                - **第三步 (存异)**: 识别并阐述不同史料间的矛盾点和差异。
                    
                - **第四步 (综合)**: 按照预设的“综合摘要”、“共同记述”、“关键分歧”、“史料引用”的结构，生成最终报告。
                    
            - 模型生成的最终报告将直接返回给前端进行展示。
                

完成上述功能实现，注意遵循阿里java规范，保持良好的编码风格，复用已经实现的项目中的代码，暂时实现基本的rag工具，将相关实现放入rag文件夹中，同时提供对外暴露的rag相关方法，service层和controller层代码暂时不要实现