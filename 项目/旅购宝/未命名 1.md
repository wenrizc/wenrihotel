

**一、性能瓶颈与多级缓存架构（初步了解）**
1.  **具体性能瓶颈**：
    *   遇到的具体性能瓶颈是什么？
    *   哪些业务场景下的数据访问出现了问题？
    *   具体的性能指标是怎样的？
2.  **并发量级**：
    *   峰值QPS大概是多少？
    *   秒杀券或热门门票抢购时，系统承受的并发量是什么量级？
3.  **多级缓存设计**：
    *   如何设计Redis和Caffeine的多级缓存架构？
    *   Caffeine（本地缓存）和Redis（分布式缓存）之间的读取优先级是怎样的？
    *   缓存的命中率大概能达到多少？

**二、性能瓶颈定位与缓存细节（追问）**
1.  **性能瓶颈定位细节**：
    *   提到2-3千QPS就会报错，但并发量级却有1万，这个矛盾如何解释？
    *   具体是什么类型的错误（连接池满了、线程池耗尽、数据库连接超时）？
2.  **缓存命中率分析**：
    *   Caffeine本地缓存的命中率大概是多少？
    *   Redis缓存的命中率又是多少？
    *   最终40%的缓存miss都走到了数据库，这对数据库造成了多大压力？
3.  **缓存更新与数据一致性**：
    *   缓存更新策略是怎样的？
    *   当数据发生变更时，Caffeine和Redis之间的数据一致性是如何保证的？

**三、线程池、缓存穿透与数据一致性（深入追问）**
1.  **线程池配置与压测**：
    *   SentinelConfig中1600的并发阈值是如何确定的？
    *   是通过压测得出的吗？具体的测试过程是怎样的？
2.  **缓存命中率与数据库压力**：
    *   Caffeine和Redis都是60%的命中率，意味着40%的请求（如3000QPS中的1200QPS）会穿透到MySQL，数据库层面是如何应对这个压力的？
    *   有做分库分表或者读写分离吗？
3.  **数据一致性的时间窗口**：
    *   Canal监听binlog → RabbitMQ → 删除缓存这条链路的延迟大概是多少毫秒？
    *   在这个时间窗口内，用户可能读到脏数据，你们是如何处理的？

**四、压测过程细节**
1.  **压测工具和方法**：使用的是什么压测工具（JMeter、ab或其他）？具体测试方法？
2.  **压测场景设计**：是模拟真实的秒杀场景吗？测试数据是怎么准备的？
3.  **关键指标监控**：除了QPS，还监控了哪些指标（响应时间、CPU使用率、内存使用率等）？（面试官指出“并未监控其他指标”可能存在风险）
4.  **阈值确定逻辑**：为什么选择1600作为限流阈值，而不是更保守或更激进的值？

**五、个人贡献与代码实现**
1.  **核心代码编写范围**：
    *   在这个多级缓存架构的实现中，具体负责编写了哪些核心代码？
    *   例如：Caffeine和Redis的缓存逻辑、Sentinel的限流规则配置、Canal监听MySQL binlog的代码是否由你编写？
2.  **贡献占比**：
    *   在整个技术方案中的具体贡献和代码实现工作量占比大概是多少？

**六、缓存击穿与雪崩防护机制**
1.  **缓存击穿防护**：当热点数据过期时，有没有实现类似"互斥锁"的机制，确保只有一个线程去查数据库，其他线程等待？
2.  **过期策略**：Caffeine和Redis的过期时间是怎么设置的？有没有加随机值避免同时过期？
3.  **代码实现思路**：详细描述代码实现思路，比如用了什么锁机制，或者其他的防护策略？

**七、分布式锁设计与缓存重建（基于`UnifiedCache.java`）**
1.  **锁的粒度设计**：分布式锁key是怎么设计的？（例如商品ID=123的缓存重建，lockKey格式？每个缓存key对应一个锁，还是按业务类型加锁？）
2.  **等待策略**：获取不到锁的线程直接返回旧数据（如`getFromLogicalCache`方法所示），这种设计考虑是什么？为什么不让其他线程等待锁释放后读取新数据？

**八、业务场景考量（返回旧数据与数据一致性权衡）**
1.  **决策依据**：在秒杀券或热门门票抢购场景下，选择让用户看到"旧数据"而不是"最新数据"，这个决策是基于什么考虑的？
    *   **数据时效性要求**：对于商品价格、库存这类敏感数据，旧价格信息是否会导致下单时价格不一致？
    *   **用户体验**：用户看到的过期库存数量是否会影响购买决策？
2.  **权衡与策略**：在设计时是如何权衡数据一致性和系统性能的？有没有针对不同类型的数据采用不同的策略？

**九、下单流程中的数据一致性与库存超卖（基于`DistributedLock`和Lua脚本）**
1.  **库存超卖防护**：在秒杀券抢购场景下，当用户点击"立即购买"按钮时，系统是如何防止库存超卖的？
    *   **库存检查时机**：是在生成订单之前检查库存，还是在支付完成后再检查？
    *   **库存扣减方式**：使用的是Redis扣减库存，还是数据库扣减，还是两者结合？
    *   **原子性保证**：如果同时有1000个用户抢购最后10张券，是怎么保证只有10个用户能成功下单的？
2.  **库存扣减流程**：库存扣减的具体流程是怎样的？

**十、预扣减机制与库存回滚**
1.  **预扣减时机与占用**：用户点击"立即购买"到实际支付完成有时间差，如果用户下单后不支付，库存会一直被占用吗？
2.  **库存回滚机制**：假设用户下单占用了库存，但是15分钟后订单超时未支付，这个预扣减的库存是如何释放回去的？
3.  **Redis与数据库同步**：Redis中的限量数据和MySQL中的真实库存是如何保持同步的？
4.  **订单超时库存回滚实现**：订单超时库存回滚是怎么实现的？

**十一、库存回滚机制缺陷（深入追问）**
1.  **库存回滚流程细节**：如果用户下单预扣减库存后，15分钟内订单超时未支付，库存回滚流程是怎样的（Redis限量如何加回，数据库库存如何回滚）？
2.  **超时处理机制**：有没有实现定时任务或延迟队列（如XXL-Job、RabbitMQ）来处理超时订单的库存释放？
3.  **高并发下库存占用问题**：如果大量用户同时下单但不支付，导致库存占用，有没有考虑过这个问题的解决方案？
4.  **超时订单库存回滚机制具体实现**：（再次确认具体实现方式）

**十二、项目整体情况与技术选型**
1.  **项目性质与规模**：
    *   这个旅购宝项目是个人项目还是团队项目？
    *   如果是团队项目，团队规模大概多大？你在其中主要负责哪些模块？
    *   项目的代码量级（整个项目行数、个人贡献代码量比例）？
    *   项目开发周期多长？
2.  **技术选型思考**：
    *   在项目初期是如何确定这个技术架构的？
    *   为什么选择 Redis + Caffeine 的二级缓存架构，而不是单纯使用 Redis 或其他缓存方案？
    *   为什么选择 RabbitMQ 而不是 Kafka 或 RocketMQ 作为消息队列？
    *   Elasticsearch + IK分词器的搜索方案，有没有考虑过其他的搜索技术（Solr、MySQL全文索引）？
    *   技术选型思路：是基于性能考虑、学习目的、还是实际业务需求驱动的？

**十三、分布式部署下的本地缓存一致性问题**
1.  **问题识别**：在多级缓存架构中，通过Canal → RabbitMQ → 删除缓存来保证一致性。在分布式部署场景下（多个应用实例），本地缓存（Caffeine）可能会导致不同实例间的数据不一致，设计时有没有考虑过这个问题？
2.  **解决方案**：如果有考虑，解决方案是什么？如果没有考虑，现在让你设计的话，你会怎么处理？

**十四、策略模式设计**
1.  **具体设计**：能具体说说策略模式设计吗？
2.  **业务逻辑差异**：比如普通商品和门票在订单处理流程中具体有哪些不同的业务逻辑？
3.  **接口抽象**：是如何抽象出策略接口的？

**十五、核销码生成的并发安全与事务设计（基于`TicketProductHandler`）**
1.  **并发安全设计**：在高并发场景下（如用户一次买5张票，生成5个不同核销码），并发安全设计是怎样的？
    *   **核销码唯一性保证**：使用UUID生成核销码，在极高并发下，如何确保即使是UUID也不会重复？有没有考虑过数据库层面的唯一约束？
    *   **事务边界设计**：如果生成5张票的过程中，第4张票失败，前3张票的核销码是否会回滚？事务设计是怎样的？
2.  **并发安全机制保证**：核销码生成的并发安全机制是如何保证的？

**十六、核销码事务边界缺陷与原子性问题**
1.  **部分成功/失败场景**：既然每张票都是独立事务，那么当订单支付失败时，已经生成的核销码如何处理？有没有考虑过这种部分成功、部分失败的场景？
2.  **数据清理机制**：如果支付失败，但已经有几张票的核销码生成了，是如何清理这些"孤儿数据"的？
3.  **用户体验影响与业务风险**：用户可能会拿到一些有效的核销码，但订单实际上是失败的，这会造成什么业务风险？
4.  **原子性问题与生产环境解决方案**：这个设计看起来存在比较明显的原子性问题。在生产环境中，是如何解决这个问题的？还是说这个问题在项目中确实存在？

**十七、Elasticsearch搜索方案**
1.  **搜索业务场景**：
    *   **搜索数据量级**：商品总数大概有多少？景点、门票、商品各占多少比例？
    *   **搜索复杂度**：用户可以按什么维度搜索（简单关键词、多维度筛选如价格区间、地理位置、评分）？
    *   **搜索效果对比**：从MySQL全文索引切换到ES后，搜索性能具体提升了多少？有没有做过性能对比测试？
2.  **搜索数据规模和业务场景**：（再次确认）
3.  **索引结构设计**：在ES中为商品设计了什么样的索引结构（字段如何mapping）？
4.  **数据同步策略**：MySQL中的商品数据是如何同步到ES的（全量/增量同步、同步频率、是否使用Canal）？
5.  **中文分词效果**：使用IK分词器，能举个具体例子说明分词效果（如搜索"北京故宫门票"）？
6.  **搜索性能**：相比之前的MySQL LIKE查询，ES的查询响应时间大概是多少？
7.  **ES索引结构具体设计**：ES索引结构是怎么设计的？包含哪些字段？（若前面未回答，再次追问）

**十八、分布式锁实现细节（基于`DistributedLock.java`）**
1.  **锁的底层实现**：使用的是基于Redis的分布式锁吗？还是基于数据库、Zookeeper或其他方案？具体是Redis的SET EX NX命令、Redisson，还是其他方案？
2.  **锁超时机制**：如果缓存重建过程比较耗时，锁超时时间是如何设置的？
3.  **锁释放策略**：如果在finally块中释放锁，但获取锁的线程突然宕机了，这个锁会一直占着吗？有没有自动释放机制？
4.  **死锁预防**：在高并发场景下，有没有考虑过分布式死锁的问题？
5.  **unlock操作的原子性**：get和delete之间非原子性操作可能导致误删锁，有没有考虑过使用Lua脚本来保证unlock操作的原子性？项目中的`unlock.lua`文件是在哪里使用的？

**十九、Lua脚本细节（分布式锁）**
1.  **Lua脚本核心逻辑**：`unlock.lua`脚本的核心逻辑是怎样的（接收参数、如何判断当前线程是否是锁的持有者、返回值设计）？
2.  **加锁操作**：除了unlock操作，在加锁操作时有没有也使用Lua脚本？还是只是简单的SET EX NX？

**二十、XXL-Job定时任务设计（基于`BloomFilterRebuildJob`和`TicketHeatEvaluationJob`）**
1.  **布隆过滤器重建任务**：
    *   **任务调度频率设计**：多久执行一次？
    *   **触发条件**：是根据什么指标来触发重建的？
2.  **分片执行策略** (`TicketHeatEvaluationJob`)：
    *   为什么选择分片执行？
    *   数据量有多大需要分片处理？
3.  **失败重试机制**：如果布隆过滤器重建任务执行失败，是如何处理的？

**二十一、项目总结与个人成长**
1.  **技术收获**：除了“多实例部署下的缓存一致性问题”这个技术难点，这2个月的项目开发让你在哪个技术领域收获最大（比如对分布式系统的理解、高并发处理的经验、还是其他方面）？

这些问题覆盖了从项目背景、架构设计、技术细节实现、并发处理、数据一致性、性能优化、压测、个人贡献到技术选型思考等多个方面，体现了面试官深入挖掘技术深度和广度的意图。