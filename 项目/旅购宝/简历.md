## 一、多级缓存架构（Redis + Caffeine）

项目设计了一套完整的多级缓存方案，主要通过以下方式实现：

1. **本地缓存层（Caffeine）**
   - 在`UnifiedCache`类中配置Caffeine作为本地内存缓存，减少Redis访问频率
   - 设置了最大容量和过期时间，避免内存溢出
   - 访问数据时优先查询本地缓存，命中则直接返回，提升响应速度

2. **分布式缓存层（Redis）**
   - 使用StringRedisTemplate操作Redis缓存
   - 实现差异化缓存策略：
     - 随机过期策略：为缓存添加随机过期时间偏移，防止缓存雪崩
     - 逻辑过期策略：针对热点数据，即使过期也返回旧数据，异步更新，避免缓存击穿

3. **缓存一致性保障**
   - 基于mq发布订阅机制实现分布式缓存同步
   - 当一个节点更新缓存时，发布缓存变更消息
   - 其他节点接收消息后，清除本地缓存相应数据
   - 通过Canal监听数据库变更，自动同步到缓存

## 二、布隆过滤器防止缓存穿透

1. **实现框架**
   - 基于Redisson的RBloomFilter实现分布式布隆过滤器
   - 按业务类型维护不同的布隆过滤器实例，针对性优化

2. **防穿透机制**
   - 缓存查询前先通过布隆过滤器判断key是否存在
   - 如果布隆过滤器判定key不存在，直接返回null，避免查询Redis和数据库
   - 新增数据时同步添加到布隆过滤器中，保证数据一致性

3. **动态优化机制**
   - 定时任务重建布隆过滤器，保持准确性
   - 根据业务类型设置不同的误判率，热门业务使用更低的误判率
   - 监控误判数据，当误判率超过阈值时触发重建

4. **分片处理**
   - 通过XXL-Job实现布隆过滤器的分片重建，降低单次重建对系统的影响
   - 支持按业务类型分批重建，灵活配置

## 三、Sentinel精细化流量控制

1. **多维度流量控制策略**
   - **限流规则**：针对高并发接口如秒杀、下单设置不同的QPS和并发线程阈值
   - **熔断降级规则**：基于响应时间和异常比例进行熔断，避免故障扩散
   - **系统保护规则**：设置CPU使用率阈值和最大线程数，防止系统崩溃

2. **针对并发塌陷点的保护**
   - 特别关注1600并发塌陷点问题，设置系统级线程数限制
   - 高峰期请求采用预热模式，平滑处理突发流量
   - 核心接口使用线程数限流，防止资源耗尽

3. **自适应流量调节**
   - 通过`SystemMonitor`实时监控系统资源使用情况
   - 分析CPU、内存使用率趋势，预测系统压力变化
   - 系统负载增加时，主动降低请求处理速度

4. **资源隔离与柔性处理**
   - 对限流请求返回友好提示，而非简单拒绝
   - 通过自定义`BlockExceptionHandler`返回标准响应

## 四、热点数据智能处理

1. **热点识别机制**
   - 通过`TicketHeatManager`记录和分析数据访问频率
   - 当访问量超过阈值时，自动标记为热点数据

2. **差异化缓存策略**
   - 热点数据使用更长的缓存时间和逻辑过期策略
   - 普通数据使用物理过期，确保数据及时更新
   - 热点数据变更时主动推送到各节点

3. **定期预热任务**
   - 通过`CacheMaintenanceJob`定期预热热点数据
   - 使用分片处理方式，避免单次预热对系统造成压力

通过上述多层次的缓存架构和精细化的流量控制策略，系统能够有效应对高并发场景，保持稳定的响应时间和较高的吞吐量，同时保障数据的一致性和可用性。

# 策略模式与工厂模式在商品订单处理中的应用

## 一、整体架构设计

项目采用了策略模式与工厂模式相结合的方式处理不同商品类型的订单流程，主要架构包括：

1. **抽象策略层**：定义了商品处理的通用接口
2. **具体策略实现**：针对不同商品类型的特定处理逻辑
3. **策略工厂**：负责创建和管理各类策略实例
4. **上下文环境**：调用具体策略并完成订单处理

## 二、核心组件设计

### 1. 策略接口设计

项目定义了统一的商品处理策略接口，包含订单生命周期的核心方法：
- 库存检查和锁定
- 价格计算（含各类折扣规则）
- 订单创建
- 支付处理
- 订单完成后的操作（如门票生成凭证）
- 退款处理

### 2. 策略实现分类

针对不同商品类型，实现了对应的策略类：
- 普通商品策略：关注库存管理和物流信息
- 门票策略：关注日期场次和电子凭证生成
- 会员商品策略：关注会员权益和特殊折扣
- 虚拟商品策略：关注激活码和使用期限

### 3. 策略工厂实现

工厂设计采用了分层结构：
- 使用单例模式实现的策略工厂，确保全局唯一
- 通过枚举或配置表维护商品类型与策略实现的映射关系
- 提供策略缓存机制，避免重复创建策略实例
- 支持策略的动态注册和发现，便于扩展

## 三、实现机制

### 1. 策略识别与选择

- 在订单创建时，通过商品的type属性识别商品类型
- 调用策略工厂的getStrategy方法，传入商品类型获取对应策略
- 使用Spring的依赖注入，将各策略实现注册到容器中

### 2. 上下文环境交互

- 订单服务作为上下文环境，负责调用策略
- 将订单数据和商品信息封装为统一的上下文对象
- 策略实现类通过上下文获取必要信息，执行处理逻辑
- 处理结果通过上下文对象返回给调用方

### 3. 动态扩展机制

- 利用注解与反射机制实现策略的自动注册
- 每个策略实现类通过注解声明支持的商品类型
- 应用启动时扫描并加载所有策略，建立商品类型与策略的映射

## 四、提升的可扩展性和可维护性

### 1. 可扩展性提升

- 新增商品类型只需实现对应策略接口，无需修改原有代码
- 策略工厂自动发现和管理新策略，符合开闭原则
- 支持同一商品类型的多种策略实现，通过优先级进行选择

### 2. 可维护性提升

- 单一职责原则：每个策略类只关注特定商品类型的逻辑
- 业务逻辑内聚：相关的处理逻辑集中在一个策略类中
- 消除条件分支：替代了传统的if-else或switch结构
- 便于测试：每个策略实现可单独测试，降低测试复杂度

### 3. 灵活性提升

- 支持策略的运行时切换，适应业务规则变更
- 可配置的策略选择逻辑，支持A/B测试或灰度发布
- 策略组合使用，处理复杂商品（如组合商品、限定商品）

通过策略模式和工厂模式的结合应用，项目成功实现了不同商品类型订单流程的差异化处理，同时保持了系统的灵活性和可维护性，为未来商品类型的扩展提供了坚实基础。

为解决数据库在商品搜索场景下的性能和中文模糊匹配效果不佳问题，引入 Elasticsearch 构建搜索引擎，并结合 IK 分词器优化中文分词，大幅提升了搜索效率和用户体验。
# Elasticsearch 与 IK 分词器在商品搜索中的应用

## 一、整体架构设计

项目采用了Elasticsearch作为搜索引擎，结合IK分词器优化中文搜索，主要架构包括：

1. **数据模型层**：定义ES文档结构与索引策略
2. **数据同步层**：实现MySQL与ES数据一致性
3. **搜索服务层**：提供高效率的搜索功能实现
4. **API接口层**：对外提供RESTful搜索接口

## 二、核心组件与实现

### 1. ES文档模型设计

项目设计了专用于搜索的ProductDocument文档模型：

- 使用`@Document`注解定义索引名称为"product"
- 针对不同字段采用差异化索引策略：
  - 商品名称和描述：使用Text类型，配置IK分词器
  - 分类ID、店铺ID：使用Long类型，便于精确过滤
  - 价格：使用Double类型，支持范围查询
  - 商品状态：使用Integer类型，便于筛选上架商品

- 关键字段优化：
  - 名称字段：配置`analyzer="ik_max_word"`(索引时)和`searchAnalyzer="ik_smart"`(搜索时)
  - 描述字段：同样应用IK分词器，但权重低于名称字段

### 2. 数据同步机制

项目实现了多层次数据同步机制，确保ES与MySQL数据一致：

- **全量同步**：
  - 通过ESDataInitializer在系统启动时执行一次全量同步
  - 基于分批处理策略，避免资源占用过多

- **增量同步**：
  - 利用Canal监听MySQL binlog实现实时数据同步
  - 针对不同操作类型(INSERT/UPDATE/DELETE)执行相应ES操作

- **数据变更同步**：
  - 当商品信息发生变更时，自动触发ES数据更新
  - CanalClient解析binlog并检测商品表变更，调用相应方法同步到ES

### 3. 搜索功能实现

搜索服务层通过ProductSearchServiceImpl实现：

- **高效查询构建**：
  - 使用CriteriaQuery构建复杂查询条件
  - 支持关键词、分类、价格范围等多维度查询
  - 针对不同条件动态组合查询策略

- **中文分词优化**：
  - 利用IK分词器的两种模式优化匹配效果：
    - ik_max_word：索引时使用，实现最细粒度分词
    - ik_smart：搜索时使用，提升查询智能性

- **结果排序与优化**：
  - 实现基于相关度的默认排序
  - 支持价格、销量等条件的自定义排序
  - 结果高亮显示匹配关键词

### 4. 缓存与性能优化

- **搜索结果缓存**：
  - 对热门搜索词的结果实现Redis缓存
  - 设置适当的过期时间(15分钟)
  
- **查询性能优化**：
  - 只返回必要字段，减少网络传输
  - 实现分页查询，避免大量数据传输
  - 配置合理的ES索引刷新间隔

## 三、业务流程

1. **用户发起搜索请求**：
   - 通过ProductController提供的搜索接口
   - 传入关键词、分类ID、页码等参数

2. **查询处理流程**：
   - 检查Redis是否有缓存结果
   - 构建ES查询条件(关键词、分类、状态等)
   - 执行ES查询，获取匹配商品

3. **结果处理与返回**：
   - 处理查询结果，转换为前端需要的格式
   - 缓存热门搜索结果
   - 返回给用户

## 四、效果与优势

1. **查询性能提升**：
   - 相比MySQL的LIKE查询，ES查询速度提升10倍以上
   - 大数据量下仍保持毫秒级响应

2. **搜索体验优化**：
   - 中文分词准确度大幅提升，支持多种搜索方式
   - 同义词、近义词匹配，提高搜索命中率

3. **系统架构优化**：
   - 降低数据库负载，实现搜索与交易分离
   - 支持后续的搜索个性化、智能推荐等功能扩展

针对数据库与缓存、Elasticsearch 间数据不一致的情况，采用 Canal 监听 MySQL 的 binlog，实现数据库变更实时捕获，并通过 RabbitMQ 实现变更数据的异步解耦和消息分发，驱动下游更新数据。

# Canal + RabbitMQ 实现数据变更同步架构

## 一、整体架构设计

项目采用了基于Canal监听MySQL binlog的方式，结合RabbitMQ消息队列实现数据同步的分布式架构，主要包含以下几个核心部分：

1. **数据变更捕获层**：Canal 客户端监听 MySQL binlog 
2. **消息传输层**：RabbitMQ 实现消息的异步分发
3. **消息消费层**：专用监听器处理不同类型数据更新
4. **数据同步层**：根据业务类型更新缓存或搜索引擎

## 二、核心组件实现

### 1. Canal 监听实现

项目通过 `CanalClient` 类实现 MySQL binlog 的监听：

- 基于 Canal 提供的 Java 客户端创建连接
- 订阅指定表的变更：`tb_shop`, `tb_blog`, `tb_voucher`, `tb_product` 等
- 在独立线程中持续获取 binlog 事件
- 针对不同表的变更采取不同处理策略

### 2. 变更数据分类处理

项目对捕获的数据变更进行分类处理：

- **商品数据变更**：直接通过 `ProductSearchService` 同步到 Elasticsearch
- **其他业务数据**：封装成标准消息格式发送至 RabbitMQ，实现解耦

### 3. RabbitMQ 消息架构

项目设计了专用的消息通道：

- **交换机**：`db.change.exchange`（直连交换机）
- **队列**：`db.change.queue`
- **路由键**：`db.change`

消息内容采用统一格式：
- `table`: 变更的表名
- `operation`: 操作类型（INSERT/UPDATE/DELETE）
- `data`: 变更的数据内容

### 4. 消息消费与处理

通过 `CacheMessageListener` 类实现消息的消费和处理：

- 使用 `@RabbitListener` 注解监听队列消息
- 基于表名映射到不同业务类型（BusinessType）
- 针对不同业务类型调用相应缓存更新策略

## 三、数据一致性保障机制

### 1. 消息幂等处理

- 为每条消息生成唯一 ID（表名+操作+数据ID+UUID）
- 使用 Redis 记录已处理消息 ID，设置合理过期时间
- 处理前检查消息是否已处理，避免重复处理

### 2. 异步更新与失败重试

- 缓存和 Elasticsearch 的更新采用异步方式
- 使用 Spring Retry 机制处理临时失败情况
- 设置重试策略（退避时间、最大重试次数）

### 3. 错误处理与监控

- 完善的异常捕获和日志记录
- 系统启动时确保 Canal 连接正确建立
- 系统关闭时安全释放 Canal 资源（实现 DisposableBean）

## 四、特殊场景处理

### 1. 商品数据直接同步

项目针对商品数据（`tb_product`）做了特殊处理：
- 检测到商品数据变更时直接更新 Elasticsearch
- 对于新增/修改操作调用 `syncProductToES`
- 对于删除操作调用 `deleteProductFromES`

### 2. 热点数据处理

对于高频访问的数据：
- 基于变更类型设置不同的缓存策略
- 缓存穿透、缓存雪崩防护措施
- 敏感操作（如删除）的预警机制

## 五、实现优势

1. **低耦合**：数据库、缓存、搜索引擎之间实现了解耦
2. **实时性**：基于 binlog 实现数据变更的准实时捕获
3. **可靠性**：消息队列提供了数据缓冲和失败重试机制
4. **扩展性**：可以方便地添加新的数据消费方（如统计系统）
5. **低侵入性**：无需修改现有业务代码，对业务层完全透明

通过这套架构，项目成功解决了数据库与缓存、Elasticsearch之间的数据一致性问题，保证了用户在高并发场景下能够获取到一致且最新的数据。


面对系统维护任务（如布隆过滤器重建、缓存清理、热点数据预热）分散且管理困难的问题，引入
XXL-Job 构建任务调度平台，实现了任务的可视化管理和失败告警，提升了系统运维效率。
# XXL-Job分布式任务调度在系统维护中的应用

## 一、整体架构设计

项目通过集成XXL-Job分布式任务调度框架，构建了一套完整的系统维护任务管理平台，主要架构包括：

1. **XXL-Job调度中心**：负责任务调度、执行监控和告警
2. **执行器注册**：将系统作为执行器注册到调度中心
3. **任务定义**：各类维护任务的具体实现
4. **执行日志与监控**：任务执行情况的记录与状态监控

## 二、核心组件实现

### 1. 调度中心与执行器配置

项目通过`XxlJobConfig`类进行XXL-Job的核心配置：

- 配置调度中心地址与访问令牌，实现与调度中心的通信
- 注册应用为XXL-Job执行器，设置执行器名称、IP和端口
- 配置日志路径和保留天数，方便排查问题
- 通过Spring Boot自动装配机制，在应用启动时完成XXL-Job初始化

### 2. 任务分类与组织

项目将系统维护任务按功能领域划分为多个任务组：

- **布隆过滤器维护任务组**：
  - 全量重建任务：`rebuildAllBloomFiltersJob`
  - 分批重建任务：`rebuildBusinessBloomFiltersJob`
  - 性能监控任务：`bloomFilterMonitorJob`

- **缓存维护任务组**：
  - 过期缓存清理：`cacheCleanupJob`
  - 热点数据预热：`cachePrewarmJob`

- **订单状态管理任务组**：
  - 超时订单取消：`autoCancelUnpaidOrdersJob`
  - 长期退款订单关闭：`autoCloseStaleRefundOrdersJob`

- **商品数据维护任务组**：
  - 门票热度评估：`ticketHeatEvaluationJob`

### 3. 任务执行机制

项目通过`@XxlJob`注解声明任务，实现与调度中心的自动对接：

- **定时调度**：通过调度中心配置Cron表达式，实现任务的定时执行
- **手动触发**：支持在调度中心手动触发任务，适用于突发维护需求
- **失败重试**：配置重试次数和策略，保障任务最终执行成功
- **路由策略**：支持分片广播、轮询、故障转移等多种路由策略

### 4. 分片执行策略

针对大量数据处理，项目设计了精细的分片处理机制：

- **基于业务类型分片**：如`BloomFilterRebuildJob`根据不同业务类型进行分片
- **基于数据ID分片**：如订单任务使用`MOD(id, {0}) = {1}`实现基于订单ID的分片
- **分片参数获取**：通过`XxlJobHelper.getShardIndex()`和`XxlJobHelper.getShardTotal()`获取分片信息

### 5. 参数化配置

项目支持任务的动态参数配置：

- **参数传递**：通过`XxlJobHelper.getJobParam()`获取调度中心配置的参数
- **参数解析**：支持解析复杂参数格式，如`key1=value1,key2=value2`
- **默认值机制**：参数缺失时提供合理默认值，增强健壮性

## 三、实现效果

### 1. 布隆过滤器维护任务

- **全量重建**：凌晨低峰期执行，一次性重建所有布隆过滤器
- **分批重建**：根据业务类型分批次重建，降低系统压力
- **监控预警**：定期检测误判率，超过阈值(10%)时发出预警
- **执行反馈**：记录各业务重建结果，便于运维人员跟进

### 2. 缓存维护任务

- **过期缓存清理**：定期清理逻辑过期的缓存键，避免内存占用
- **热点预热**：提前将热门商品、门票等数据加载到缓存，防止缓存冷启动问题
- **分类预热**：支持指定特定业务类型进行预热，提高灵活性

### 3. 订单状态管理任务

- **超时订单取消**：自动取消30分钟未支付的订单，释放库存
- **退款订单关闭**：处理30天未完成退款的订单，避免订单状态悬而未决
- **分片处理**：大量订单根据ID取模分片处理，提高处理效率

### 4. 热点数据评估任务

- **门票热度评估**：根据访问频率判定热门门票，支持热门数据的升级和降级
- **自适应预热**：根据热度评估结果，自动预热新晋热点数据
- **降级处理**：热度下降时执行降级处理，调整缓存策略

## 四、运维管理优势

1. **可视化管理**：
   - 通过XXL-Job控制台统一查看所有任务状态
   - 直观展示任务执行历史和运行时长
   - 支持任务的在线开启/关闭/触发

2. **执行日志跟踪**：
   - 任务执行过程实时记录关键日志
   - 处理结果统计（成功/失败数量）
   - 异常情况详细记录，便于问题排查

3. **告警机制**：
   - 任务执行失败时自动告警
   - 执行超时预警
   - 支持多种告警方式（邮件、企业微信等）

4. **动态调度**：
   - 支持调整任务执行时间
   - 灵活配置执行参数
   - 临时暂停/恢复任务

5. **资源协调**：
   - 通过分片机制合理分配执行资源
   - 避免任务并发执行引起的资源竞争
   - 高峰期限流，保障核心业务

通过以上设计与实现，项目成功将原本分散的系统维护任务整合到统一的XXL-Job平台，大幅提升了运维效率，确保了系统的稳定性和数据一致性。

为解决高并发下重复请求（如重复下单/支付）和资源竞争（如库存超卖）问题，构建了幂等性保障
体系：接口层利用 Token+Redis 防重；服务层通过 Redisson 分布式锁确保关键操作互斥，并利用 Lua
脚本保证 Redis 操作原子性；数据层结合数据库索引唯一约束和乐观锁机制，防止并发冲突。

# 高并发下幂等性保障体系实现方案

## 一、整体架构设计

项目采用了三层防护机制实现幂等性保障，形成了一套完整的防重复请求和资源竞争保护策略：

1. **接口层**：使用Token+Redis机制防止客户端重复提交
2. **服务层**：通过Redisson分布式锁确保并发操作的互斥性，并利用Lua脚本保证复合操作的原子性
3. **数据层**：结合数据库唯一约束和乐观锁机制，确保数据一致性

## 二、接口层防重复提交

### 1. Token令牌机制

项目实现了基于Token的防重机制：

- **令牌生成与分发**：
  - 用户发起敏感操作（如下单）前，先请求获取一个操作令牌
  - 服务端生成全局唯一的Token并存储在Redis中，键格式为`operation:token:{业务类型}:{用户ID}`
  - 设置合理的短期过期时间（例如60秒）

- **令牌验证与销毁**：
  - 用户提交请求时必须携带之前获取的Token
  - 服务端验证Token的有效性，使用Redis的SETNX+DEL原子操作确保Token只能被消费一次
  - 无效Token或已使用Token的请求将被拒绝

### 2. 防刷接口设计

- **频率限制**：
  - 针对获取令牌的接口进行限流保护
  - 同一用户在短时间内多次获取令牌的行为将被拒绝
  - 基于Redis的滑动窗口算法实现限频

- **业务隔离**：
  - 不同业务场景使用不同的Token命名空间
  - 确保一个业务场景的Token不能用于其他场景

## 三、服务层互斥与原子性保障

### 1. Redisson分布式锁实现

- **粒度控制**：
  - 基于业务实体的ID设置锁的粒度（如商品ID、订单ID）
  - 避免全局锁导致的性能瓶颈

- **锁获取策略**：
  - 采用尝试获取锁（tryLock）策略，避免长时间等待
  - 设置合理的等待时间和过期时间，防止死锁

- **看门狗机制**：
  - 利用Redisson的自动续期功能，防止长时间操作导致锁过期
  - 保障长时间运行的任务不会因锁释放导致并发问题

### 2. Lua脚本保障原子性

- **复合操作封装**：
  - 将多步Redis操作封装到单个Lua脚本中
  - 秒杀场景中，检查库存、扣减库存、记录用户下单在一个脚本中完成

- **原子性保障**：
  - Redis保证Lua脚本的原子性执行
  - 避免多步操作中的竞态条件

- **结果处理**：
  - 根据Lua脚本的返回值区分不同的业务结果
  - 统一的错误码机制，便于客户端理解操作结果

## 四、数据层并发保护

### 1. 唯一约束实现

- **唯一索引设计**：
  - 在关键业务表上设置唯一索引
  - 如订单表上的外部订单号、支付流水号设置唯一约束

- **插入冲突处理**：
  - 使用`INSERT IGNORE`或`ON DUPLICATE KEY UPDATE`处理可能的重复插入
  - 借助数据库的唯一约束机制实现幂等

### 2. 乐观锁机制

- **版本号控制**：
  - 在核心业务表增加version字段
  - 更新时检查version值，确保数据未被其他事务修改

- **条件更新**：
  - 库存更新使用`stock = stock - #{count} WHERE stock >= #{count}`确保库存充足
  - 秒杀券扣减使用`stock = stock - 1 WHERE voucher_id = #{id} AND stock > 0`防止超卖

## 五、典型业务场景实现

### 1. 秒杀下单场景

- **分布式锁+Lua脚本**：
  - 获取基于用户ID和商品ID的分布式锁，确保同一用户对同一商品的操作互斥
  - 使用Lua脚本原子性检查库存、记录用户购买记录、扣减库存

- **消息队列异步处理**：
  - 验证通过后，发送创建订单消息到队列
  - 后端异步处理，减轻系统压力

### 2. 支付回调处理

- **幂等设计**：
  - 根据支付平台回调的交易ID检查订单状态
  - 使用状态机模式，确保订单状态变更合法

- **防重设计**：
  - 将已处理的交易ID记录到Redis，设置合适的过期时间
  - 收到重复回调时快速识别并返回成功，避免重复处理

### 3. 库存操作保障

- **预扣库存**：
  - 下单时先预扣库存，设置过期时间
  - 支付成功或超时未支付分别处理库存

- **库存恢复**：
  - 订单取消时使用乐观锁恢复库存
  - 记录库存变动日志，便于问题排查

通过这种多层次的幂等性保障体系，项目有效解决了高并发场景下的重复请求和资源竞争问题，确保了业务的正确性和数据的一致性。