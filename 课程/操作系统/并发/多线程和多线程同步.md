
## 1. 多线程

### 1.1 线程的概念

*   **定义**：线程是一个执行上下文（Context of Execution, COE），包含执行流、调用栈、错误码、信号掩码、私有数据等状态。Linux 内核使用“任务”（Task）来表示一个执行流。
*   **执行流**：指令序列，受代码分支、跳转以及编译器指令重排、处理器乱序执行的影响，实际执行顺序可能与代码顺序不完全一致。
*   **逻辑线程 vs 硬件线程**：
    *   **逻辑线程**：程序上的概念，描述执行逻辑，如一个函数。
    *   **硬件线程**：执行逻辑线程的物理基础，一个 CPU 可能有多个核心，每个核心可能支持超线程，从软件视角看是独立的逻辑 CPU。操作系统负责调度逻辑线程到硬件线程执行。

### 1.2 线程、核心、函数的关系

*   线程从入口函数开始执行，形成函数调用链。
*   多线程可以提升处理速度，通过对数据（例如大数组分段求和）或逻辑（不同任务）进行拆分，让多个线程并发执行。
*   线程是动态概念，可能因资源不足、中断、抢占、条件依赖等原因被阻塞或挂起。
*   多线程是一种编程模型，不一定需要多 CPU/多核，单 CPU/单核系统也能通过时间分片技术运行多线程程序。CPU 亲和性和绑核可以将任务分配给特定核心。

### 1.3 程序、进程、线程、协程

*   **可执行程序**：静态概念，由源文件编译链接生成。
*   **进程**：动态概念，可执行程序在操作系统上的一次执行，是资源分配的基本单位。
*   **线程**：进程内的多个执行流，最小的调度单位。同一进程内的多个线程共享地址空间（代码、全局变量、堆、栈）和文件描述符。
*   **进程和线程的关系**：Linus 认为两者都是执行上下文（COE），Linux 内核没有严格区分，只看作共享不同状态的“任务”（轻量级进程 LWP）。
*   **协程**：用户态的多执行流，上下文切换成本比线程低，可提高吞吐能力和稳定性。C++20 已纳入协程库。

### 1.4 为什么需要多线程

*   **定义**：一个进程内多个线程并发执行，是一种编程模型。
*   **原因**：
    *   **并行计算**：充分利用多核处理器，提升整体吞吐量和执行速度（例如，统计多个文本文件的单词出现次数，可使用线程池并发处理）。
    *   **后台任务处理**：将阻塞或耗时任务分离到后台线程，避免阻塞主线程，提升程序响应能力（例如，在执行密集计算时同时监控键盘输入）。

### 1.5 线程相关概念

*   **时间分片**：操作系统将 CPU 时间切分为短时间片，轮流分配给不同线程执行。
*   **上下文切换**：操作系统保存当前 CPU 上运行线程的状态，并恢复即将执行线程的状态，需要占用 CPU 时间。
*   **线程安全函数与可重入**：
    *   **线程安全**：多线程并发执行结果与单线程依次执行结果一致。
    *   **可重入**：不访问共享数据（全局变量、静态局部变量、类成员变量），只操作参数和局部变量的函数，是线程安全的。
    *   C 标准库提供了带 `_r` 后缀的线程安全版本接口（例如 `ctime_r`）。
*   **线程私有数据（TSD）**：为每个线程提供一份独立的“全局变量”，只能在该线程内访问。Posix 线程库提供了相关接口，C/C++ 语言通过 `thread_local` 关键字支持。
*   **阻塞和非阻塞**：
    *   **阻塞**：线程因等待某个条件（如获取锁失败、阻塞 I/O）而无法继续执行。
    *   **非阻塞**：调用后立即返回，并通过返回值或错误码报告结果，不会导致线程等待。

---

## 2. 多线程同步

### 2.1 什么是多线程同步

*   协调多个线程对共享数据的访问，避免数据不一致（竞争条件）。
*   协调各个事件的发生顺序，使多线程在特定点交汇并按预期推进。

### 2.2 为什么需要同步

*   **示例 1 (数据不完整)**：一个线程写入长消息，另一个线程并发读取，可能读到不完整的中间状态。
*   **示例 2 (指针域不一致)**：修改二叉搜索树节点时，多个指针域的修改非原子性，并发读取可能读到部分更新的节点。
*   **示例 3 (自增操作竞争)**：`int x = 0; ++x;` 两个线程并发执行，可能因加载、更新、保存三步非原子性导致最终 `x` 为 1 而非 2。
*   **示例 4 (逻辑操作非原子性)**：`if (!q.empty()) { q.pop(); }` 在 `empty()` 和 `pop()` 之间可能被其他线程打断，导致逻辑错误（例如多个线程弹出同一个元素）。
*   **示例 5 (整型变量读写)**：多线程并发读写 `int32_t` 变量，若读写操作非原子性，可能导致读到中间值。
*   **示例 6 (FIFO 环形队列)**：`in` 和 `out` 游标以及 `buffer` 的并发读写，若不加同步，可能导致数据混乱。

### 2.3 保护什么

*   在多线程程序中，需要保护的是**数据**，而非代码本身（尽管同步机制通常作用于代码段）。

### 2.4 串行化

*   确保在任意时刻，只有一个线程可以访问某个共享（临界）资源的代码段（临界代码），其他线程必须等待。

### 2.5 原子操作和原子变量

*   **原子性**：一个操作是不可分割的整体，要么未开始，要么已完成，不会出现中间状态。
*   通过 CPU 提供的原子指令实现。
*   原子变量（如 C++ 的 `std::atomic`）提供了原子性的自增、自减等操作，可解决像示例 3 中的竞争问题。
*   适用于计数、生成序列号等场景。

### 2.6 锁

*   **互斥锁（Mutex）**：
    *   确保同一时间只有一个线程访问共享资源。
    *   状态：已加锁、未加锁。
    *   操作：`lock()`（阻塞式获取）、`unlock()`（释放），`try_lock()`（非阻塞尝试获取）。
    *   使用模式：`加锁 -> 访问共享资源 -> 解锁`。这是一种编程契约。
*   **读写锁（Read-Write Lock）**：
    *   提升并行度。允许多个读线程同时访问共享资源。
    *   写线程访问时，独占资源，其他读写线程均被阻塞。
    *   状态：已加读锁、已加写锁、未加锁。
    *   适用于“读多写少”的场景。通常会给写线程优先权，避免饿死。
*   **自旋锁（Spinlock）**：
    *   获取失败时，不让出 CPU，而是忙等（紧密循环测试和设置指令），直到成功。
    *   适用于临界区代码执行时间极短的场景，假设自旋成本低于上下文切换。
    *   内核态线程常用（可关闭调度避免抢占）。用户态应用程序通常不推荐，因其可能在持有锁时被调度走，导致其他线程空耗 CPU。
    *   需要多 CPU/多核支持。
*   **锁的粒度**：合理选择锁保护的范围，过大降低性能，过小增加复杂度。
*   **锁的范围**：最小化持有锁的时间。
*   **死锁**：
    *   **ABBA 锁**：两个线程分别持有不同锁，并试图获取对方持有的锁，导致相互等待。可通过 `try_lock` 或锁排序（规定统一的加锁顺序）解决。
    *   **自死锁**：线程试图再次获取已被自己持有的、不支持重复加锁的锁。

### 2.7 条件变量（Condition Variables）

*   通常与互斥锁配合使用，用于生产者-消费者模式，协调线程在某个条件满足时进行操作。
*   **问题**：轮询检查条件（例如消息队列是否非空）会浪费 CPU 资源。
*   **机制**：
    *   等待线程：获取互斥锁，检查条件。若不满足，调用 `wait()` 睡眠并释放锁。被唤醒后，重新获取锁，再次检查条件。
    *   通知线程（改变条件者）：获取互斥锁，改变条件状态，释放互斥锁，调用 `notify_one()` 或 `notify_all()` 唤醒等待线程。
*   `wait` 函数通常带有谓词（lambda 表达式），以处理虚假唤醒。

### 2.8 Lock-free 和无锁数据结构

*   **锁同步的问题**：阻塞型同步机制可能导致程序挂起（如持有锁的线程崩溃）、优先级倒转等。
*   **Lock-free 的定义**：允许单个线程饥饿，但保证系统级吞吐量。如果一个线程被暂停，lock-free 算法保证其他线程依然能够往前推进。所有基于互斥锁或自旋锁的并发实现都不是 lock-free 的。
*   **CAS Loop 实现 Lock-free**：
    *   依赖 CPU 提供的 **读-改-写（Read-Modify-Write）** 原语，最著名的是 **比较和交换（Compare And Swap, CAS）**。
    *   **CAS(ptr, expect_value, new_value)**：原子地比较 `*ptr` 和 `expect_value`，若相等则将 `new_value` 写入 `*ptr` 并返回 true，否则返回 false。
    *   Lock-free 代码通常使用 CAS 循环：`do { expect_value = *ptr; } while (!CAS(ptr, expect_value, new_value));`。
    *   即使加载 `expect_value` 和 `CAS` 之间 `*ptr` 被其他线程修改，CAS 会失败，循环会重试，直到成功。
*   **无锁数据结构**：通过非阻塞算法（如 CAS）而非锁来保护共享数据，保证无论调度如何，系统都能取得整体进展。
    *   **示例：Lock-free 栈**：使用 `std::atomic<node<T>*> head` 和 `compare_exchange_weak` 来实现 `push` 操作，确保即使有线程在任意步骤暂停，其他线程也能继续执行并最终完成操作。

### 2.9 程序序（Program Order）

*   单线程程序中，代码按照编写的顺序一行行执行。

### 2.10 内存序（Memory Order）

*   从某个角度观察到的内存读写实际发生顺序。
*   可能与程序序不一致，原因包括编译器指令重排和 CPU 乱序执行。
*   单核系统会保证乱序执行不影响程序结果。
*   多核系统不提供这种保证，不同核心观察到的内存序可能不同，导致多线程同步失败。

### 2.11 乱序执行（Out-of-order Execution）

*   导致内存顺序与程序顺序不同的现象，目的是为了提升性能。
*   **原因**：
    *   **编译期**：编译器指令重排（在不破坏程序逻辑的前提下）。
    *   **运行期**：CPU 的超标量流水线、预测执行、Cache-Miss 等。
*   **Store Buffer**：为掩盖 Store 操作延迟而引入，Core 将 Store 操作先写入 Store Buffer，然后继续执行其他指令。
    *   **问题**：可能导致单核程序出现违背程序序的现象（例如 `a=1; assert(a==1);` 断言失败）。Store Forwarding 机制可解决。
    *   **多核问题**：导致一个核心的 Store 操作顺序可能不匹配全局内存顺序，且其他核心可能读到旧值（参见 2.12 多核内存序问题）。
*   **Invalidate Queue**：为减少 CPU 在 Cache 一致性协议（如 MESI）中等待其他核心响应 Invalidate 消息而引入。
    *   **问题**：Invalidate 消息可能被延迟处理，导致核心读取到其本地 Cache 中的旧数据，从而观察到与全局内存序不一致的 Load 顺序。

### 2.12 内存屏障（Memory Barrier）

*   一类同步屏障指令，用于解决乱序执行和 Store Buffer/Invalidate Queue 导致的内存序问题。
*   **作用**：确保屏障之前的所有读写操作都完成后，才能执行屏障之后的操作。
    *   `wmb()` (write memory barrier)：确保屏障前的所有写操作写入内存（或对其他核心可见），再执行屏障后的写操作。解决 Store Buffer 导致的写乱序问题。
    *   `rmb()` (read memory barrier)：确保屏障前所有 Invalidate Queue 中的消息被处理，再执行屏障后的读操作。解决 Invalidate Queue 导致的读乱序问题。
    *   `mb()`：全功能屏障，同时保证读写操作有序。
*   GCC 提供了 `barrier()` 作为编译器屏障，阻止编译器重排。

---

## 3. 伪共享（False Sharing）

*   **定义**：多个线程同时读写位于**同一个 Cache Line** 中的不同变量，导致 CPU Cache 频繁失效，从而降低程序性能的现象。
*   **Cache Line**：CPU 缓存的最小数据传输单位，通常为 64 字节。当一个字节被访问时，整个 Cache Line 都会被加载到缓存。
*   **示例分析**：
    *   `f()` 函数中，两个线程交错地对 `shm` 数组中相邻的 `long` 元素进行赋值，每次 `shm_offset` 增加 8 字节。
    *   由于相邻元素很可能位于同一个 Cache Line，当线程 1 修改 `shm[offset]` 时，会使该 Cache Line 在线程 2 的本地缓存中失效。当线程 2 接着修改 `shm[offset+8]` 时，它发现自己的 Cache Line 已失效，必须从内存重新加载，并且在写入前，线程 1 可能需要将该 Cache Line 刷回内存。
    *   这种频繁的缓存行失效、重新加载和刷新导致了性能急剧下降（相当于每次都直接访问内存，Cache 的优势丧失）。
*   **改进版 `f_fast()`**：
    *   每次 `shm_offset` 增加 128 字节（16 个 `long` 元素），并在内部循环中连续赋值这 16 个元素。
    *   这样，每次原子操作后，一个线程会独占一个 Cache Line 范围的数据进行操作，减少了不同线程之间对同一个 Cache Line 的竞争，从而显著提升性能。
*   **规避方法（空间换时间）**：在结构体中通过添加填充（Padding）来确保不同线程访问的变量位于不同的 Cache Line，避免伪共享。
    *   例如：`struct Data { int a; int padding[60]; int b; };`
    *   Linux 内核提供了 `__cacheline_aligned_in_smp` 宏来解决此问题。

---

## 4. 小结

*   **pthread 同步原语**：互斥量、条件变量、读写锁、信号量、自旋锁。
*   **IPC 机制**（管道、FIFO、消息队列、信号量）也可以用于线程间通信，但因资源清理问题不建议使用。
*   **非锁/部分线程安全实践**：
    *   **Copy-on-Write (COW)**：写时复制。
    *   **Thread-Specific Data (TSD)**：线程私有数据。
    *   **Atomic Variables (CAS)**：原子变量（比较和交换）。
    *   **Lock-Free Data Structures**：无锁数据结构。
    *   **Read-Copy-Update (RCU)**：读-拷贝-更新。
*   **核心理念**：“最快的同步是不进行同步”，即“不共享任何东西是最好的”（Share nothing is best），尽量避免线程间共享数据。