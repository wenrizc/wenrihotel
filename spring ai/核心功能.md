

### 一、 核心抽象与 API

- 统一的模型接口：提供 `ChatModel`（聊天）、`ImageModel`（文生图）、`EmbeddingModel`（向量化）、`Audio Transcription`（音频转录）和 `Text to Speech`（文本转语音）等标准 API，屏蔽底层不同 AI 提供商的差异。
    
- 流畅的交互客户端 (`ChatClient`)：一个高级、链式调用的 API，简化了与聊天模型的交互，是集成各种高级功能的入口。
    
- 标准化的提示工程 (`Prompt` & `Message`)：通过 `System`、`User`、`Assistant` 等角色消息构建与 AI 的交互，并支持使用 `PromptTemplate` 动态生成提示。
    

### 二、 核心功能与模式

- 工具调用 (Tool Calling)：允许 AI 模型请求调用 Java 应用程序中定义的函数（工具），以查询实时数据或执行具体操作，极大地扩展了模型的能力。
    
- 检索增强生成 (RAG)：通过“加载数据 -> 向量化存储 -> 检索 -> 增强提示 -> 生成”的流程，将外部私有知识库与 LLM 结合，解决模型知识过时和幻觉问题。
    
- 聊天记忆 (Chat Memory)：为无状态的 LLM 提供持久化对话历史的能力，支持内存、JDBC、NoSQL 等多种存储方案，以实现有上下文的多轮对话。
    
- 结构化输出：强制模型按预定义的结构（如 JSON）生成响应，并自动将其转换为 Java 对象，便于程序直接处理。
    
- 多模态支持：允许在用户消息中同时包含文本和图像等多种类型的数据，与支持多模态的 LLM 进行交互。
    

### 三、 数据、存储与集成

- 向量数据库 API (`VectorStore`)：提供统一的接口来操作超过 14 种主流向量数据库（如 PgVector, Chroma, Milvus），是实现 RAG 的基石，并支持元数据过滤。
    
- Advisors (AOP 扩展点)：提供类似 AOP 的机制，用于拦截和增强 AI 调用，是实现 RAG、聊天记忆等可重用功能的关键。
    
- 可观测性 (Observability)：与 Spring Boot 体系深度集成，为 AI 相关的操作（如模型调用、令牌使用、向量检索）提供开箱即用的 Metrics（指标）和 Tracing（分布式追踪）。
    
- 模型评估：内置工具用于评估模型响应的相关性和事实准确性，以检测和控制幻觉。
    
- 自动化测试环境：与 Testcontainers 和 Docker Compose 无缝集成，可在开发和测试时自动启动和配置所需的 AI 服务容器（如 Ollama），实现零配置开发。